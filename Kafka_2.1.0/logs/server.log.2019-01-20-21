[2019-01-20 10:14:24,331] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-20 10:14:24,337] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-20 10:14:24,338] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-20 10:14:24,338] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-20 10:14:24,338] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-20 10:14:24,359] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-20 10:14:24,360] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-20 10:14:24,374] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,375] INFO Server environment:host.name=ITdif.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,375] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,375] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,375] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,375] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,377] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,384] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,384] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,385] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,385] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,386] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,386] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,387] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,387] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,403] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,403] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,403] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:24,434] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-20 10:14:24,438] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 10:14:32,237] INFO Expiring session 0x100000c6ed30000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:32,240] INFO Processed session termination for sessionid: 0x100000c6ed30000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:32,245] INFO Creating new log file: log.d9 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-20 10:14:41,286] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-20 10:14:42,060] INFO starting (kafka.server.KafkaServer)
[2019-01-20 10:14:42,061] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-20 10:14:42,090] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:14:42,099] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,099] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,099] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,099] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,099] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,100] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,101] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,101] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,102] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,102] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,103] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,103] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,104] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,104] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,105] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,107] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:42,131] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:14:42,132] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:14:42,135] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51003 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 10:14:42,135] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:14:42,144] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51003 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:42,150] INFO Established session 0x100048300d50000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51003 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:42,152] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100048300d50000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:14:42,159] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:14:42,240] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x1 zxid:0xdb txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,259] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x2 zxid:0xdc txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,262] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x3 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,265] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x4 zxid:0xde txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,268] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x5 zxid:0xdf txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,272] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x6 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,276] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x7 zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,279] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x8 zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,282] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0x9 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,285] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0xa zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,288] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0xb zxid:0xe5 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,291] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0xc zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,295] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:create cxid:0xd zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:42,565] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-20 10:14:42,658] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-20 10:14:42,670] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-20 10:14:42,710] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:14:42,710] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:14:42,712] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:14:42,766] INFO Loading logs. (kafka.log.LogManager)
[2019-01-20 10:14:42,881] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:42,884] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:42,951] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-20 10:14:42,997] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,002] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:14:43,016] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 189 ms (kafka.log.Log)
[2019-01-20 10:14:43,049] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,050] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,067] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-20 10:14:43,085] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,089] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:14:43,090] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 57 ms (kafka.log.Log)
[2019-01-20 10:14:43,115] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,115] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,140] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,143] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-01-20 10:14:43,166] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,167] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,193] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,196] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-01-20 10:14:43,220] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,221] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,248] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,252] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-01-20 10:14:43,277] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,277] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,303] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,307] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-01-20 10:14:43,331] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,332] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,356] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,359] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-01-20 10:14:43,384] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,385] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,410] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,414] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-01-20 10:14:43,438] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,439] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,466] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,468] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-01-20 10:14:43,493] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,494] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,519] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,522] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-01-20 10:14:43,547] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,547] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,575] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,578] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-01-20 10:14:43,602] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,603] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,629] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,631] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-01-20 10:14:43,656] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,656] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,683] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,685] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-01-20 10:14:43,710] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,711] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,730] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 25 (kafka.log.ProducerStateManager)
[2019-01-20 10:14:43,750] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 25 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,753] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-39\00000000000000000025.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:14:43,756] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 25 in 64 ms (kafka.log.Log)
[2019-01-20 10:14:43,780] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,781] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,806] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,809] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-01-20 10:14:43,833] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,834] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,859] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,862] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-01-20 10:14:43,886] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,886] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,914] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,917] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-01-20 10:14:43,943] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,944] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,968] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:43,972] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-01-20 10:14:43,996] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-20 10:14:43,996] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:44,022] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:14:44,025] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-01-20 10:14:44,029] INFO Logs loading complete in 1263 ms. (kafka.log.LogManager)
[2019-01-20 10:14:44,045] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-20 10:14:44,046] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-20 10:14:44,386] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-20 10:14:44,425] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-20 10:14:44,474] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:14:44,476] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:14:44,476] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:14:44,493] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-20 10:14:44,555] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 10:14:44,561] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 10:14:44,562] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 10:14:44,628] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:14:44,632] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:14:44,633] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:14:44,673] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:14:44,675] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:14:44,682] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:44,700] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-20 10:14:44,742] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-20 10:14:44,744] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-20 10:14:44,744] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-20 10:14:44,813] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-20 10:14:44,835] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-20 10:14:44,843] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-20 10:14:44,844] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-20 10:14:44,846] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-20 10:14:44,936] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, alltools-2, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, alltools-0, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:14:44,963] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:44,967] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:44,972] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:multi cxid:0xac zxid:0xeb txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:44,993] INFO Got user-level KeeperException when processing sessionid:0x100048300d50000 type:multi cxid:0xae zxid:0xec txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:14:45,005] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,007] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,018] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,019] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,030] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,031] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,041] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 22 (kafka.cluster.Replica)
[2019-01-20 10:14:45,041] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 25. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,049] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,050] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,062] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,063] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,074] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,074] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,083] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,083] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,093] INFO Replica loaded for partition alltools-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-20 10:14:45,094] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,094] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,107] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,108] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,116] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,116] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,125] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,125] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,134] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,134] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,144] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,145] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,154] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,155] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,164] INFO Replica loaded for partition alltools-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-20 10:14:45,164] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,165] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,174] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,175] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,183] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:14:45,184] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:14:45,206] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,208] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,208] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,209] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,210] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,211] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,212] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,212] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,213] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,213] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,214] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,214] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,215] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,216] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,216] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,222] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,223] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,229] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,231] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,233] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,234] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,235] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,235] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,236] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,237] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,239] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,240] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,240] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,241] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,241] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,303] INFO [GroupCoordinator 1]: Loading group metadata for group2 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:14:45,308] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 67 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,308] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,309] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:45,309] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:14:55,315] INFO [GroupCoordinator 1]: Member consumer-1-10e3d80d-8e56-4a76-a53e-f0a4085e7574 in group group2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:14:55,321] INFO [GroupCoordinator 1]: Preparing to rebalance group group2 in state PreparingRebalance with old generation 1 (__consumer_offsets-39) (reason: removing member consumer-1-10e3d80d-8e56-4a76-a53e-f0a4085e7574 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:14:55,329] INFO [GroupCoordinator 1]: Group group2 with generation 2 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:14:59,196] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-20 10:14:59,859] INFO starting (kafka.server.KafkaServer)
[2019-01-20 10:14:59,860] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-20 10:14:59,883] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:14:59,891] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,891] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,891] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,891] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,891] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,891] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,893] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,899] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,900] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,900] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,901] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,901] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,902] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,902] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,903] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,905] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:14:59,926] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:14:59,927] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:14:59,929] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51029 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 10:14:59,929] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:14:59,937] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51029 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:59,939] INFO Established session 0x100048300d50001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51029 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:14:59,942] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100048300d50001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:14:59,946] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:15:00,002] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x1 zxid:0xee txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,019] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x2 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,022] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x3 zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,025] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x4 zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,027] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x5 zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,030] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x6 zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,034] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x7 zxid:0xf4 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,038] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x8 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,041] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0x9 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,043] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0xa zxid:0xf7 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,048] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0xb zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,052] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0xc zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,054] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:create cxid:0xd zxid:0xfa txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:00,255] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-20 10:15:00,345] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-20 10:15:00,359] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-20 10:15:00,393] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:15:00,393] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:15:00,395] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:15:00,443] INFO Loading logs. (kafka.log.LogManager)
[2019-01-20 10:15:00,578] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,600] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:15:00,622] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 124 ms (kafka.log.Log)
[2019-01-20 10:15:00,666] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,668] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-1\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:15:00,670] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 31 ms (kafka.log.Log)
[2019-01-20 10:15:00,687] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,691] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-20 10:15:00,708] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,709] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:00,726] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,727] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:00,745] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,746] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:00,764] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,765] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:00,781] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,783] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:00,798] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,800] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:00,814] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,815] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:00,832] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,833] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:00,847] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,848] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:00,865] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,867] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:00,880] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,882] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:00,899] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,900] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:00,915] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,916] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:00,933] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,933] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:00,948] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,950] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-01-20 10:15:00,966] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:00,968] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-20 10:15:00,974] INFO Logs loading complete in 531 ms. (kafka.log.LogManager)
[2019-01-20 10:15:00,989] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-20 10:15:00,990] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-20 10:15:01,301] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-20 10:15:01,335] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-20 10:15:01,377] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:01,379] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:01,379] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:01,392] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-20 10:15:01,469] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 10:15:01,474] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 10:15:01,476] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 10:15:01,558] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:01,561] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:01,562] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:01,590] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:01,592] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:01,600] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:01,613] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-20 10:15:01,641] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-20 10:15:01,644] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-20 10:15:01,644] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-20 10:15:01,697] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-20 10:15:01,717] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-20 10:15:01,723] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-20 10:15:01,724] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-20 10:15:01,726] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-20 10:15:01,819] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,824] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,828] INFO Replica loaded for partition alltools-1 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-20 10:15:01,835] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,839] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,842] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,846] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,852] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,856] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,859] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,864] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,870] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,875] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,879] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,883] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,885] INFO Replica loaded for partition alltools-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-20 10:15:01,890] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,894] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,896] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,902] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:01,904] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:15:01,940] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 10:15:01,944] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(alltools-0 -> (offset=2, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:15:01,969] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, alltools-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:15:01,976] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:01,987] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-20 10:15:02,007] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:02,007] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,024] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,031] INFO [Partition alltools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 10:15:02,033] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,042] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,050] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,057] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,065] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,071] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,077] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,085] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,091] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,097] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,105] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,112] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,121] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,126] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,134] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:02,144] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,146] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,147] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,149] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,150] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,151] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,151] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,152] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,156] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,157] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,158] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,159] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,161] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,161] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,161] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,162] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,176] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,177] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,178] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,178] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,184] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,184] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,185] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,187] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,188] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,188] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,189] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,190] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,191] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,197] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:02,198] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:09,898] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-20 10:15:10,588] INFO starting (kafka.server.KafkaServer)
[2019-01-20 10:15:10,590] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-20 10:15:10,612] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:15:10,619] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,620] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,620] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,620] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,620] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,620] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,622] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,627] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,628] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,629] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,629] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,629] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,630] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,630] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,631] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,633] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 10:15:10,655] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:15:10,655] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:15:10,658] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51055 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 10:15:10,658] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:15:10,663] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51055 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:15:10,667] INFO Established session 0x100048300d50002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51055 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:15:10,670] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100048300d50002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 10:15:10,674] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 10:15:10,730] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x1 zxid:0x113 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,744] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x2 zxid:0x114 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,748] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x3 zxid:0x115 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,750] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x4 zxid:0x116 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,753] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x5 zxid:0x117 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,754] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x6 zxid:0x118 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,757] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x7 zxid:0x119 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,759] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x8 zxid:0x11a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,763] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0x9 zxid:0x11b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,769] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0xa zxid:0x11c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,772] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0xb zxid:0x11d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,775] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0xc zxid:0x11e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,778] INFO Got user-level KeeperException when processing sessionid:0x100048300d50002 type:create cxid:0xd zxid:0x11f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:10,983] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-20 10:15:11,068] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-20 10:15:11,081] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-20 10:15:11,115] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:15:11,115] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:15:11,116] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-20 10:15:11,164] INFO Loading logs. (kafka.log.LogManager)
[2019-01-20 10:15:11,284] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,302] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-1\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:15:11,335] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 119 ms (kafka.log.Log)
[2019-01-20 10:15:11,364] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,366] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:15:11,368] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 16 ms (kafka.log.Log)
[2019-01-20 10:15:11,386] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,390] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 10:15:11,407] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,408] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:11,425] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,427] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-20 10:15:11,452] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,455] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-20 10:15:11,457] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 23 ms (kafka.log.Log)
[2019-01-20 10:15:11,471] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,472] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-01-20 10:15:11,489] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,490] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:11,506] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,507] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-01-20 10:15:11,523] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,524] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:11,539] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,540] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-01-20 10:15:11,556] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,556] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-01-20 10:15:11,572] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,573] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:11,587] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,588] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:11,603] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,604] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-01-20 10:15:11,620] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,621] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:11,634] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,635] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-01-20 10:15:11,650] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 10:15:11,651] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-20 10:15:11,656] INFO Logs loading complete in 492 ms. (kafka.log.LogManager)
[2019-01-20 10:15:11,671] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-20 10:15:11,672] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-20 10:15:11,984] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-20 10:15:12,017] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-20 10:15:12,056] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:12,058] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:12,058] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:12,073] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-20 10:15:12,143] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 10:15:12,149] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 10:15:12,151] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 10:15:12,239] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:12,243] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:12,245] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-20 10:15:12,268] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:12,269] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:12,274] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,289] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-20 10:15:12,315] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-20 10:15:12,317] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-20 10:15:12,317] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-20 10:15:12,365] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-20 10:15:12,384] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-20 10:15:12,391] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-20 10:15:12,391] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-20 10:15:12,394] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-20 10:15:12,485] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,488] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,492] INFO Replica loaded for partition alltools-1 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-20 10:15:12,499] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,503] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,506] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,510] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,516] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,520] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,523] INFO Replica loaded for partition alltools-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-20 10:15:12,524] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,530] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,534] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,537] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-20 10:15:12,541] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,547] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,550] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,554] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,557] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,563] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 10:15:12,565] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(alltools-2, alltools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:15:12,597] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 10:15:12,602] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(alltools-2 -> (offset=2, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:15:12,606] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(alltools-1 -> (offset=2, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:15:12,607] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 10:15:12,633] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-20 10:15:12,633] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-20 10:15:12,641] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-20 10:15:12,646] INFO [Partition alltools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 10:15:12,649] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,675] INFO [Partition alltools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-20 10:15:12,676] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,686] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,691] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,698] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,703] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,708] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,715] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,720] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,725] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,736] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,741] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,747] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,752] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,758] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,764] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 10:15:12,772] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,773] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,774] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,774] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,775] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,780] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,780] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,781] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,783] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,784] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,784] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,785] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,786] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,786] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,787] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,787] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,825] INFO [GroupCoordinator 3]: Loading group metadata for console-consumer-11117 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:12,832] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 59 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,833] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,834] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,835] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,835] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,836] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,839] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,840] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,840] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,841] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,841] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,842] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,843] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,844] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,845] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:12,846] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:15:22,837] INFO [GroupCoordinator 3]: Member consumer-1-bcf9270f-829a-41b9-87ec-4090cff92dcf in group console-consumer-11117 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:22,844] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-11117 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member consumer-1-bcf9270f-829a-41b9-87ec-4090cff92dcf on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:22,853] INFO [GroupCoordinator 3]: Group console-consumer-11117 with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:15:43,287] INFO Accepted socket connection from /127.0.0.1:51096 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 10:15:43,289] INFO Client attempting to establish new session at /127.0.0.1:51096 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:15:43,293] INFO Established session 0x100048300d50003 with negotiated timeout 30000 for client /127.0.0.1:51096 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 10:15:43,582] INFO Processed session termination for sessionid: 0x100048300d50003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 10:15:43,586] INFO Closed socket connection for client /127.0.0.1:51096 which had sessionid 0x100048300d50003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 10:16:02,555] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-94925 in state PreparingRebalance with old generation 0 (__consumer_offsets-10) (reason: Adding new member consumer-1-3592497f-32fc-4acc-8874-f1e3f20e1c05) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:16:02,562] INFO [GroupCoordinator 2]: Stabilized group console-consumer-94925 generation 1 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:16:02,573] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-94925 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:24:44,688] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:25:01,604] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:25:12,277] INFO [GroupMetadataManager brokerId=3] Group console-consumer-11117 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:25:12,288] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:34:44,676] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:35:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:35:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:44:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:45:01,605] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:45:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:48:33,563] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-94925 in state PreparingRebalance with old generation 1 (__consumer_offsets-10) (reason: removing member consumer-1-3592497f-32fc-4acc-8874-f1e3f20e1c05 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:48:33,566] INFO [GroupCoordinator 2]: Group console-consumer-94925 with generation 2 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:48:47,770] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-38063 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member consumer-1-227ed072-06bb-4079-975a-41a3d85a2b6c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:48:47,776] INFO [GroupCoordinator 1]: Stabilized group console-consumer-38063 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:48:47,786] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-38063 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 10:54:44,674] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:55:01,600] INFO [GroupMetadataManager brokerId=2] Group console-consumer-94925 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:55:01,605] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 10:55:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:04:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:05:01,605] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:05:12,273] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:14:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:15:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:15:12,283] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:21:08,558] INFO Got user-level KeeperException when processing sessionid:0x100048300d50001 type:setData cxid:0x3f zxid:0x13a txntype:-1 reqpath:n/a Error Path:/config/topics/my-example-topic Error:KeeperErrorCode = NoNode for /config/topics/my-example-topic (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 11:21:08,573] INFO Topic creation Map(my-example-topic-0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2019-01-20 11:21:08,577] INFO [KafkaApi-2] Auto creation of topic my-example-topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-01-20 11:21:08,615] INFO [GroupCoordinator 2]: Preparing to rebalance group KafkaExampleConsumer in state PreparingRebalance with old generation 0 (__consumer_offsets-10) (reason: Adding new member consumer-1-23dad023-db79-406c-929b-34767e1b3cab) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:21:08,617] INFO [GroupCoordinator 2]: Stabilized group KafkaExampleConsumer generation 1 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:21:08,631] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my-example-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 11:21:08,640] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 11:21:08,643] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-20 11:21:08,645] INFO Created log for partition my-example-topic-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 11:21:08,647] INFO [Partition my-example-topic-0 broker=2] No checkpointed highwatermark is found for partition my-example-topic-0 (kafka.cluster.Partition)
[2019-01-20 11:21:08,647] INFO Replica loaded for partition my-example-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 11:21:08,647] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 11:21:08,687] INFO [GroupCoordinator 2]: Assignment received from leader for group KafkaExampleConsumer for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:22:03,704] INFO [GroupCoordinator 2]: Member consumer-1-23dad023-db79-406c-929b-34767e1b3cab in group KafkaExampleConsumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:22:03,704] INFO [GroupCoordinator 2]: Preparing to rebalance group KafkaExampleConsumer in state PreparingRebalance with old generation 1 (__consumer_offsets-10) (reason: removing member consumer-1-23dad023-db79-406c-929b-34767e1b3cab on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:22:03,706] INFO [GroupCoordinator 2]: Group KafkaExampleConsumer with generation 2 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:22:03,709] INFO [GroupCoordinator 2]: Member consumer-1-23dad023-db79-406c-929b-34767e1b3cab in group KafkaExampleConsumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:23:55,805] INFO [GroupCoordinator 2]: Preparing to rebalance group KafkaExampleConsumer in state PreparingRebalance with old generation 2 (__consumer_offsets-10) (reason: Adding new member consumer-1-78b6e1fb-faaf-4e5d-bc92-8a50c2ce56be) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:23:55,807] INFO [GroupCoordinator 2]: Stabilized group KafkaExampleConsumer generation 3 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:23:55,812] INFO [GroupCoordinator 2]: Assignment received from leader for group KafkaExampleConsumer for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:24:38,823] INFO [GroupCoordinator 2]: Member consumer-1-78b6e1fb-faaf-4e5d-bc92-8a50c2ce56be in group KafkaExampleConsumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:24:38,824] INFO [GroupCoordinator 2]: Preparing to rebalance group KafkaExampleConsumer in state PreparingRebalance with old generation 3 (__consumer_offsets-10) (reason: removing member consumer-1-78b6e1fb-faaf-4e5d-bc92-8a50c2ce56be on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:24:38,825] INFO [GroupCoordinator 2]: Group KafkaExampleConsumer with generation 4 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 11:24:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:25:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:25:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:34:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:35:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:35:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:44:44,684] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:45:01,597] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:45:12,282] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:54:44,682] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:55:01,603] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 11:55:12,273] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:04:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:05:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:05:12,280] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:14:44,689] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:15:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:15:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:24:44,681] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:25:01,598] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:25:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:34:44,688] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:35:01,595] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:35:12,281] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:44:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:45:01,607] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:45:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:52:55,867] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-38063 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: removing member consumer-1-227ed072-06bb-4079-975a-41a3d85a2b6c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:52:55,867] INFO [GroupCoordinator 1]: Group console-consumer-38063 with generation 2 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:53:15,545] INFO Accepted socket connection from /127.0.0.1:58097 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 12:53:15,545] INFO Client attempting to establish new session at /127.0.0.1:58097 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 12:53:15,561] INFO Established session 0x100048300d50004 with negotiated timeout 30000 for client /127.0.0.1:58097 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 12:53:15,904] INFO Got user-level KeeperException when processing sessionid:0x100048300d50004 type:setData cxid:0x6 zxid:0x141 txntype:-1 reqpath:n/a Error Path:/config/topics/edited Error:KeeperErrorCode = NoNode for /config/topics/edited (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 12:53:15,967] INFO Processed session termination for sessionid: 0x100048300d50004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 12:53:15,967] INFO Closed socket connection for client /127.0.0.1:58097 which had sessionid 0x100048300d50004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 12:53:15,983] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:15,998] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:15,998] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:15,998] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 12:53:15,998] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 12:53:15,998] INFO Created log for partition edited-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 12:53:15,998] INFO [Partition edited-1 broker=1] No checkpointed highwatermark is found for partition edited-1 (kafka.cluster.Partition)
[2019-01-20 12:53:15,998] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:15,998] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:15,998] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 12:53:15,998] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 12:53:16,014] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 12:53:16,014] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 12:53:16,014] INFO Created log for partition edited-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 12:53:16,014] INFO [Partition edited-2 broker=2] No checkpointed highwatermark is found for partition edited-2 (kafka.cluster.Partition)
[2019-01-20 12:53:16,014] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,014] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,014] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 12:53:16,014] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 12:53:16,014] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,014] INFO Created log for partition edited-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 12:53:16,029] INFO [Partition edited-0 broker=3] No checkpointed highwatermark is found for partition edited-0 (kafka.cluster.Partition)
[2019-01-20 12:53:16,029] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,029] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,029] INFO [Partition edited-0 broker=3] edited-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 12:53:16,029] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,029] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 12:53:16,029] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 12:53:16,029] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 12:53:16,029] INFO Created log for partition edited-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 12:53:16,029] INFO [Partition edited-1 broker=2] No checkpointed highwatermark is found for partition edited-1 (kafka.cluster.Partition)
[2019-01-20 12:53:16,029] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,029] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:16,029] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 12:53:16,029] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:16,029] INFO Created log for partition edited-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 12:53:16,045] INFO [Partition edited-0 broker=1] No checkpointed highwatermark is found for partition edited-0 (kafka.cluster.Partition)
[2019-01-20 12:53:16,045] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,045] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:16,045] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,045] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 12:53:16,045] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 12:53:16,045] INFO Created log for partition edited-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 12:53:16,061] INFO [Partition edited-2 broker=3] No checkpointed highwatermark is found for partition edited-2 (kafka.cluster.Partition)
[2019-01-20 12:53:16,061] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 12:53:16,061] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:16,061] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(edited-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:16,076] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 12:53:16,092] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(edited-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 12:53:16,092] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 12:53:16,092] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 12:53:16,436] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 12:53:16,436] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 12:53:16,499] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 12:53:16,499] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 12:53:39,983] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-31126 in state PreparingRebalance with old generation 0 (__consumer_offsets-24) (reason: Adding new member consumer-1-5ff44f3d-4bb1-4395-aec0-41e0fcc54e37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:53:39,983] INFO [GroupCoordinator 1]: Stabilized group console-consumer-31126 generation 1 (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:53:39,998] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-31126 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:54:43,905] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-0fe8fcf0-fa14-4db5-a304-ed6dc81a14e2-StreamThread-1-consumer-9ffdbfe2-221d-4bae-a1e8-19709db31776) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:54:43,905] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:54:43,920] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:54:44,682] INFO [GroupMetadataManager brokerId=1] Group console-consumer-38063 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:54:44,682] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:54:53,952] INFO [GroupCoordinator 3]: Member alltoolsStream-0fe8fcf0-fa14-4db5-a304-ed6dc81a14e2-StreamThread-1-consumer-9ffdbfe2-221d-4bae-a1e8-19709db31776 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:54:53,952] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-0fe8fcf0-fa14-4db5-a304-ed6dc81a14e2-StreamThread-1-consumer-9ffdbfe2-221d-4bae-a1e8-19709db31776 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:54:53,952] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:55:01,596] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:55:12,269] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:55:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 12:56:05,077] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-10c60b26-02a8-4332-bb9e-9cab2ee96f15-StreamThread-1-consumer-dde3a030-fa2b-4a18-9bfa-15fcaec08b37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:56:05,077] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:56:05,092] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:56:15,109] INFO [GroupCoordinator 3]: Member alltoolsStream-10c60b26-02a8-4332-bb9e-9cab2ee96f15-StreamThread-1-consumer-dde3a030-fa2b-4a18-9bfa-15fcaec08b37 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:56:15,109] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-10c60b26-02a8-4332-bb9e-9cab2ee96f15-StreamThread-1-consumer-dde3a030-fa2b-4a18-9bfa-15fcaec08b37 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 12:56:15,109] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 13:04:44,684] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:05:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:05:12,269] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:05:12,274] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:14:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:15:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:15:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:24:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:25:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:25:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:34:44,688] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:35:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:35:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:44:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:45:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:45:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:54:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:55:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 13:55:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:04:44,683] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:05:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:05:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:06:10,155] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-9c7ac07a-a646-4649-83c8-87c48bec727d-StreamThread-1-consumer-eba6ba26-7b22-4670-8730-206acd47f29e) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:06:10,155] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:06:10,155] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:06:20,171] INFO [GroupCoordinator 3]: Member alltoolsStream-9c7ac07a-a646-4649-83c8-87c48bec727d-StreamThread-1-consumer-eba6ba26-7b22-4670-8730-206acd47f29e in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:06:20,171] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-9c7ac07a-a646-4649-83c8-87c48bec727d-StreamThread-1-consumer-eba6ba26-7b22-4670-8730-206acd47f29e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:06:20,171] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:08:15,672] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-4746207d-04bc-4c0d-adef-119bdb04d9c1-StreamThread-1-consumer-a7e598e2-9bea-4103-b483-7bf2dd04eaca) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:08:15,672] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 3 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:08:15,687] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:08:25,707] INFO [GroupCoordinator 3]: Member alltoolsStream-4746207d-04bc-4c0d-adef-119bdb04d9c1-StreamThread-1-consumer-a7e598e2-9bea-4103-b483-7bf2dd04eaca in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:08:25,707] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: removing member alltoolsStream-4746207d-04bc-4c0d-adef-119bdb04d9c1-StreamThread-1-consumer-a7e598e2-9bea-4103-b483-7bf2dd04eaca on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:08:25,707] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 4 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:10:24,260] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 4 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-aea7646c-ca0f-41c9-8f57-61a44ee432d6-StreamThread-1-consumer-4c999304-2999-48c8-b241-03fc1a61dbda) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:10:24,262] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 5 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:10:24,280] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:10:34,283] INFO [GroupCoordinator 3]: Member alltoolsStream-aea7646c-ca0f-41c9-8f57-61a44ee432d6-StreamThread-1-consumer-4c999304-2999-48c8-b241-03fc1a61dbda in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:10:34,287] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 5 (__consumer_offsets-2) (reason: removing member alltoolsStream-aea7646c-ca0f-41c9-8f57-61a44ee432d6-StreamThread-1-consumer-4c999304-2999-48c8-b241-03fc1a61dbda on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:10:34,288] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 6 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:14:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:15:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:15:12,269] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:15:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:19:05,186] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-b34760d5-6929-4db5-a3a5-e4db2cdddb52-StreamThread-1-consumer-779e33c9-ff70-41aa-86bd-b886935348a5) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:19:05,186] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:19:05,186] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:19:15,202] INFO [GroupCoordinator 3]: Member alltoolsStream-b34760d5-6929-4db5-a3a5-e4db2cdddb52-StreamThread-1-consumer-779e33c9-ff70-41aa-86bd-b886935348a5 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:19:15,202] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-b34760d5-6929-4db5-a3a5-e4db2cdddb52-StreamThread-1-consumer-779e33c9-ff70-41aa-86bd-b886935348a5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:19:15,202] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:24:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:25:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:25:12,269] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:25:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:33:22,030] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-516db89a-3791-4980-8a53-2725999ed5e0-StreamThread-1-consumer-a0202a78-2ae8-46b9-8a23-671eb1524c7d) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:33:22,030] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:33:22,045] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:33:32,061] INFO [GroupCoordinator 3]: Member alltoolsStream-516db89a-3791-4980-8a53-2725999ed5e0-StreamThread-1-consumer-a0202a78-2ae8-46b9-8a23-671eb1524c7d in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:33:32,061] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-516db89a-3791-4980-8a53-2725999ed5e0-StreamThread-1-consumer-a0202a78-2ae8-46b9-8a23-671eb1524c7d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:33:32,061] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:33:55,703] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-31126 in state PreparingRebalance with old generation 1 (__consumer_offsets-24) (reason: removing member consumer-1-5ff44f3d-4bb1-4395-aec0-41e0fcc54e37 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:33:55,703] INFO [GroupCoordinator 1]: Group console-consumer-31126 with generation 2 is now empty (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:34:44,687] INFO [GroupMetadataManager brokerId=1] Group console-consumer-31126 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:34:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:34:45,140] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61929 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 14:34:45,156] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61929 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 14:34:45,171] INFO Established session 0x100048300d50005 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:61929 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 14:34:45,514] INFO Got user-level KeeperException when processing sessionid:0x100048300d50005 type:setData cxid:0x6 zxid:0x14d txntype:-1 reqpath:n/a Error Path:/config/topics/tools Error:KeeperErrorCode = NoNode for /config/topics/tools (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 14:34:45,577] INFO Processed session termination for sessionid: 0x100048300d50005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 14:34:45,577] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61929 which had sessionid 0x100048300d50005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 14:34:45,608] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,608] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,608] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,608] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:34:45,624] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:34:45,624] INFO Created log for partition tools-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:34:45,624] INFO [Partition tools-0 broker=1] No checkpointed highwatermark is found for partition tools-0 (kafka.cluster.Partition)
[2019-01-20 14:34:45,624] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:34:45,624] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,624] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,624] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:34:45,624] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:34:45,624] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:34:45,624] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 14:34:45,624] INFO Created log for partition tools-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:34:45,624] INFO [Partition tools-2 broker=3] No checkpointed highwatermark is found for partition tools-2 (kafka.cluster.Partition)
[2019-01-20 14:34:45,624] INFO Created log for partition tools-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:34:45,624] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,639] INFO [Partition tools-1 broker=2] No checkpointed highwatermark is found for partition tools-1 (kafka.cluster.Partition)
[2019-01-20 14:34:45,639] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,639] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,639] INFO [Partition tools-2 broker=3] tools-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:34:45,639] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,639] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:34:45,639] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,639] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,639] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,639] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:34:45,655] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:34:45,655] INFO Created log for partition tools-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:34:45,655] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:34:45,655] INFO [Partition tools-2 broker=1] No checkpointed highwatermark is found for partition tools-2 (kafka.cluster.Partition)
[2019-01-20 14:34:45,655] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,655] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,655] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,655] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:34:45,655] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:34:45,655] INFO Created log for partition tools-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:34:45,655] INFO [Partition tools-1 broker=3] No checkpointed highwatermark is found for partition tools-1 (kafka.cluster.Partition)
[2019-01-20 14:34:45,655] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,655] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,655] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 14:34:45,655] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,655] INFO Created log for partition tools-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:34:45,655] INFO [Partition tools-0 broker=2] No checkpointed highwatermark is found for partition tools-0 (kafka.cluster.Partition)
[2019-01-20 14:34:45,655] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:34:45,655] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,655] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:34:45,764] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:34:45,764] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:34:45,811] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:34:45,811] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:34:45,889] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:34:45,889] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:35:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:35:12,270] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:35:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:35:23,327] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-ee00e3a4-7f39-45f2-9f7c-21ab92bfa6c1-StreamThread-1-consumer-10130240-3437-4c25-a103-4346389cd384) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:35:23,327] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:35:23,342] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:36:00,437] INFO [GroupCoordinator 3]: Member alltoolsStream-ee00e3a4-7f39-45f2-9f7c-21ab92bfa6c1-StreamThread-1-consumer-10130240-3437-4c25-a103-4346389cd384 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:36:00,437] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-ee00e3a4-7f39-45f2-9f7c-21ab92bfa6c1-StreamThread-1-consumer-10130240-3437-4c25-a103-4346389cd384 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:36:00,437] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:07,186] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-32f7b956-bf80-416f-8e97-504b198e1584-StreamThread-1-consumer-4c8c74b1-a5a8-475e-bf6b-4b40fdd4314b) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:07,186] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 3 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:07,201] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:17,217] INFO [GroupCoordinator 3]: Member alltoolsStream-32f7b956-bf80-416f-8e97-504b198e1584-StreamThread-1-consumer-4c8c74b1-a5a8-475e-bf6b-4b40fdd4314b in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:17,217] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: removing member alltoolsStream-32f7b956-bf80-416f-8e97-504b198e1584-StreamThread-1-consumer-4c8c74b1-a5a8-475e-bf6b-4b40fdd4314b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:17,217] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 4 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:57,107] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-65191 in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member consumer-1-021922e9-21d9-4903-ad0f-649eb9a8dafd) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:57,107] INFO [GroupCoordinator 2]: Stabilized group console-consumer-65191 generation 1 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:37:57,123] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-65191 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:38:28,811] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 4 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-0079378d-0642-4a4a-bf41-81255559f1e5-StreamThread-1-consumer-1913350d-74b6-4dcd-b665-4cfd5b26d6df) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:38:28,811] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 5 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:38:28,827] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:38:38,843] INFO [GroupCoordinator 3]: Member alltoolsStream-0079378d-0642-4a4a-bf41-81255559f1e5-StreamThread-1-consumer-1913350d-74b6-4dcd-b665-4cfd5b26d6df in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:38:38,843] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 5 (__consumer_offsets-2) (reason: removing member alltoolsStream-0079378d-0642-4a4a-bf41-81255559f1e5-StreamThread-1-consumer-1913350d-74b6-4dcd-b665-4cfd5b26d6df on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:38:38,843] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 6 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:42:10,446] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-65191 in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: removing member consumer-1-021922e9-21d9-4903-ad0f-649eb9a8dafd on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:42:10,462] INFO [GroupCoordinator 2]: Group console-consumer-65191 with generation 2 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:42:22,092] INFO Accepted socket connection from /127.0.0.1:62249 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 14:42:22,092] INFO Client attempting to establish new session at /127.0.0.1:62249 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 14:42:22,092] INFO Established session 0x100048300d50006 with negotiated timeout 30000 for client /127.0.0.1:62249 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 14:42:22,420] INFO Got user-level KeeperException when processing sessionid:0x100048300d50006 type:setData cxid:0x6 zxid:0x159 txntype:-1 reqpath:n/a Error Path:/config/topics/mytools Error:KeeperErrorCode = NoNode for /config/topics/mytools (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 14:42:22,467] INFO Processed session termination for sessionid: 0x100048300d50006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 14:42:22,467] INFO Closed socket connection for client /127.0.0.1:62249 which had sessionid 0x100048300d50006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 14:42:22,483] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(mytools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,483] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(mytools-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,483] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,483] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:42:22,498] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:42:22,498] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:42:22,498] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 14:42:22,498] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 14:42:22,498] INFO Created log for partition mytools-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:42:22,498] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 14:42:22,498] INFO [Partition mytools-0 broker=1] No checkpointed highwatermark is found for partition mytools-0 (kafka.cluster.Partition)
[2019-01-20 14:42:22,498] INFO Created log for partition mytools-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:42:22,498] INFO Created log for partition mytools-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:42:22,498] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,498] INFO [Partition mytools-1 broker=2] No checkpointed highwatermark is found for partition mytools-1 (kafka.cluster.Partition)
[2019-01-20 14:42:22,498] INFO [Partition mytools-2 broker=3] No checkpointed highwatermark is found for partition mytools-2 (kafka.cluster.Partition)
[2019-01-20 14:42:22,498] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,498] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,498] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,498] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:42:22,498] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,498] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,498] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:42:22,498] INFO [Partition mytools-2 broker=3] mytools-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:42:22,514] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,514] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,514] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,514] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:42:22,514] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:42:22,530] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:42:22,530] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:42:22,530] INFO Created log for partition mytools-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:42:22,530] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:42:22,530] INFO [Partition mytools-2 broker=1] No checkpointed highwatermark is found for partition mytools-2 (kafka.cluster.Partition)
[2019-01-20 14:42:22,530] INFO Created log for partition mytools-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:42:22,530] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,530] INFO [Partition mytools-0 broker=2] No checkpointed highwatermark is found for partition mytools-0 (kafka.cluster.Partition)
[2019-01-20 14:42:22,530] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,530] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,530] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:42:22,530] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(mytools-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,530] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(mytools-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,530] INFO Created log for partition mytools-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:42:22,530] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(mytools-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,530] INFO [Partition mytools-1 broker=3] No checkpointed highwatermark is found for partition mytools-1 (kafka.cluster.Partition)
[2019-01-20 14:42:22,530] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:42:22,530] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(mytools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,530] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(mytools-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:42:22,701] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:42:22,701] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:42:22,701] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:42:22,701] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:42:22,827] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:42:22,827] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:43:21,514] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-28628 in state PreparingRebalance with old generation 0 (__consumer_offsets-47) (reason: Adding new member consumer-1-17336afa-c185-4edb-8941-8c12dc003722) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:43:21,514] INFO [GroupCoordinator 3]: Stabilized group console-consumer-28628 generation 1 (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:43:21,530] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-28628 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:43:34,953] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 6 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-672f5719-7cbc-49c1-88de-a909713da209-StreamThread-1-consumer-33d9d8ea-5c53-4755-866d-94f47a839a85) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:43:34,953] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 7 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:43:34,953] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:44:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:45:01,592] INFO [GroupMetadataManager brokerId=2] Group console-consumer-65191 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:45:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:45:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:45:27,187] INFO [GroupCoordinator 3]: Member alltoolsStream-672f5719-7cbc-49c1-88de-a909713da209-StreamThread-1-consumer-33d9d8ea-5c53-4755-866d-94f47a839a85 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:45:27,187] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 7 (__consumer_offsets-2) (reason: removing member alltoolsStream-672f5719-7cbc-49c1-88de-a909713da209-StreamThread-1-consumer-33d9d8ea-5c53-4755-866d-94f47a839a85 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:45:27,187] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 8 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:08,030] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-28628 in state PreparingRebalance with old generation 1 (__consumer_offsets-47) (reason: removing member consumer-1-17336afa-c185-4edb-8941-8c12dc003722 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:08,030] INFO [GroupCoordinator 3]: Group console-consumer-28628 with generation 2 is now empty (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:24,405] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62550 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 14:49:24,405] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62550 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 14:49:24,405] INFO Established session 0x100048300d50007 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62550 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 14:49:24,748] INFO Got user-level KeeperException when processing sessionid:0x100048300d50007 type:setData cxid:0x6 zxid:0x165 txntype:-1 reqpath:n/a Error Path:/config/topics/tools1 Error:KeeperErrorCode = NoNode for /config/topics/tools1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 14:49:24,795] INFO Processed session termination for sessionid: 0x100048300d50007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 14:49:24,811] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62550 which had sessionid 0x100048300d50007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 14:49:24,811] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,811] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,811] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,827] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:49:24,827] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:49:24,827] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:49:24,827] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:49:24,827] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:49:24,827] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:49:24,827] INFO Created log for partition tools1-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:49:24,827] INFO Created log for partition tools1-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:49:24,827] INFO [Partition tools1-1 broker=3] No checkpointed highwatermark is found for partition tools1-1 (kafka.cluster.Partition)
[2019-01-20 14:49:24,827] INFO Created log for partition tools1-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:49:24,827] INFO [Partition tools1-2 broker=1] No checkpointed highwatermark is found for partition tools1-2 (kafka.cluster.Partition)
[2019-01-20 14:49:24,827] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,827] INFO [Partition tools1-0 broker=2] No checkpointed highwatermark is found for partition tools1-0 (kafka.cluster.Partition)
[2019-01-20 14:49:24,827] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,827] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,827] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,827] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,827] INFO [Partition tools1-1 broker=3] tools1-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:49:24,827] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,827] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:49:24,827] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 14:49:24,842] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,842] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,842] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,842] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:49:24,858] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:49:24,858] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:49:24,858] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 14:49:24,858] INFO Created log for partition tools1-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:49:24,858] INFO [Partition tools1-0 broker=3] No checkpointed highwatermark is found for partition tools1-0 (kafka.cluster.Partition)
[2019-01-20 14:49:24,858] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,858] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,858] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:49:24,858] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,858] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 14:49:24,858] INFO Created log for partition tools1-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:49:24,858] INFO [Partition tools1-2 broker=2] No checkpointed highwatermark is found for partition tools1-2 (kafka.cluster.Partition)
[2019-01-20 14:49:24,858] INFO Created log for partition tools1-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 14:49:24,858] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,858] INFO [Partition tools1-1 broker=1] No checkpointed highwatermark is found for partition tools1-1 (kafka.cluster.Partition)
[2019-01-20 14:49:24,858] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,858] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 14:49:24,858] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools1-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,858] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:24,858] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools1-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 14:49:25,077] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:49:25,077] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:49:25,171] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:49:25,171] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:49:25,312] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 14:49:25,312] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 14:49:44,655] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 8 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-f55fb8c7-2b15-41ae-b786-dab6743ed7a0-StreamThread-1-consumer-1f17181a-52dc-4a64-a940-1a26fa7f7a50) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:44,655] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 9 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:44,655] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:59,858] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-85767 in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-1-c3928b7c-434a-4ba7-948f-0b0d3e2dad6c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:59,858] INFO [GroupCoordinator 2]: Stabilized group console-consumer-85767 generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:49:59,858] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-85767 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:51:39,920] INFO [GroupCoordinator 3]: Member alltoolsStream-f55fb8c7-2b15-41ae-b786-dab6743ed7a0-StreamThread-1-consumer-1f17181a-52dc-4a64-a940-1a26fa7f7a50 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:51:39,920] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 9 (__consumer_offsets-2) (reason: removing member alltoolsStream-f55fb8c7-2b15-41ae-b786-dab6743ed7a0-StreamThread-1-consumer-1f17181a-52dc-4a64-a940-1a26fa7f7a50 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:51:39,920] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 10 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:51:41,655] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 10 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-d94248db-2775-4a96-b04c-2b66594e710e-StreamThread-1-consumer-68da5979-1e9b-48f0-8802-31701062c0e9) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:51:41,655] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 11 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:51:41,655] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 14:54:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:55:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:55:12,269] INFO [GroupMetadataManager brokerId=3] Group console-consumer-28628 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 14:55:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:01:10,280] INFO [GroupCoordinator 3]: Member alltoolsStream-d94248db-2775-4a96-b04c-2b66594e710e-StreamThread-1-consumer-68da5979-1e9b-48f0-8802-31701062c0e9 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:01:10,281] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 11 (__consumer_offsets-2) (reason: removing member alltoolsStream-d94248db-2775-4a96-b04c-2b66594e710e-StreamThread-1-consumer-68da5979-1e9b-48f0-8802-31701062c0e9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:01:10,281] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 12 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:01:27,608] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-85767 in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: removing member consumer-1-c3928b7c-434a-4ba7-948f-0b0d3e2dad6c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:01:27,608] INFO [GroupCoordinator 2]: Group console-consumer-85767 with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:01:40,108] INFO Accepted socket connection from /127.0.0.1:63028 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 15:01:40,108] INFO Client attempting to establish new session at /127.0.0.1:63028 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:01:40,108] INFO Established session 0x100048300d50008 with negotiated timeout 30000 for client /127.0.0.1:63028 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:01:40,452] INFO Got user-level KeeperException when processing sessionid:0x100048300d50008 type:setData cxid:0x6 zxid:0x171 txntype:-1 reqpath:n/a Error Path:/config/topics/tools2 Error:KeeperErrorCode = NoNode for /config/topics/tools2 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:01:40,499] INFO Processed session termination for sessionid: 0x100048300d50008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:01:40,499] INFO Closed socket connection for client /127.0.0.1:63028 which had sessionid 0x100048300d50008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 15:01:40,515] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools2-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,515] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools2-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,515] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,515] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:01:40,515] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:01:40,515] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:01:40,530] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 15:01:40,530] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 15:01:40,530] INFO Created log for partition tools2-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:01:40,530] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 15:01:40,530] INFO Created log for partition tools2-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:01:40,530] INFO [Partition tools2-2 broker=3] No checkpointed highwatermark is found for partition tools2-2 (kafka.cluster.Partition)
[2019-01-20 15:01:40,530] INFO Created log for partition tools2-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:01:40,530] INFO [Partition tools2-0 broker=1] No checkpointed highwatermark is found for partition tools2-0 (kafka.cluster.Partition)
[2019-01-20 15:01:40,530] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,530] INFO [Partition tools2-1 broker=2] No checkpointed highwatermark is found for partition tools2-1 (kafka.cluster.Partition)
[2019-01-20 15:01:40,530] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,530] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,530] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,530] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,530] INFO [Partition tools2-2 broker=3] tools2-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:01:40,530] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,530] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:01:40,530] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:01:40,546] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,546] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,546] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,546] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:01:40,546] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:01:40,546] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:01:40,546] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:01:40,546] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:01:40,546] INFO Created log for partition tools2-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:01:40,546] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:01:40,546] INFO Created log for partition tools2-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:01:40,546] INFO [Partition tools2-1 broker=3] No checkpointed highwatermark is found for partition tools2-1 (kafka.cluster.Partition)
[2019-01-20 15:01:40,546] INFO Created log for partition tools2-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:01:40,546] INFO [Partition tools2-0 broker=2] No checkpointed highwatermark is found for partition tools2-0 (kafka.cluster.Partition)
[2019-01-20 15:01:40,546] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,546] INFO [Partition tools2-2 broker=1] No checkpointed highwatermark is found for partition tools2-2 (kafka.cluster.Partition)
[2019-01-20 15:01:40,561] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,546] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:01:40,561] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,561] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools2-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,561] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools2-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,561] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools2-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,561] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools2-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,561] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools2-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:01:40,859] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:01:40,859] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:01:40,937] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:01:40,937] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:01:40,983] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:01:40,983] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:01:45,733] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-2289 in state PreparingRebalance with old generation 0 (__consumer_offsets-10) (reason: Adding new member consumer-1-8a48e5fa-e017-4710-8700-64319d641cd5) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:01:45,733] INFO [GroupCoordinator 2]: Stabilized group console-consumer-2289 generation 1 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:01:45,733] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-2289 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:02:20,405] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 12 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-c71d9015-cace-4f88-a9fe-258f8d9db415-StreamThread-1-consumer-34855405-8f10-42a1-b08f-95d21013863c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:02:20,405] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 13 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:02:20,421] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 13 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:02:39,468] INFO [GroupCoordinator 3]: Member alltoolsStream-c71d9015-cace-4f88-a9fe-258f8d9db415-StreamThread-1-consumer-34855405-8f10-42a1-b08f-95d21013863c in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:02:39,468] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 13 (__consumer_offsets-2) (reason: removing member alltoolsStream-c71d9015-cace-4f88-a9fe-258f8d9db415-StreamThread-1-consumer-34855405-8f10-42a1-b08f-95d21013863c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:02:39,468] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 14 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:03:32,514] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 14 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-428fb3c8-e646-43c2-80da-6fb08c43039b-StreamThread-1-consumer-7d89a1a7-be9f-426e-acf4-f955cf6a68ee) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:03:32,514] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 15 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:03:32,530] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 15 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:03:42,532] INFO [GroupCoordinator 3]: Member alltoolsStream-428fb3c8-e646-43c2-80da-6fb08c43039b-StreamThread-1-consumer-7d89a1a7-be9f-426e-acf4-f955cf6a68ee in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:03:42,532] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 15 (__consumer_offsets-2) (reason: removing member alltoolsStream-428fb3c8-e646-43c2-80da-6fb08c43039b-StreamThread-1-consumer-7d89a1a7-be9f-426e-acf4-f955cf6a68ee on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:03:42,532] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 16 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:04,280] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 16 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-43158174-2a27-46d2-a8e8-262f6bd2eede-StreamThread-1-consumer-5e9d8ab3-76a5-4dd4-b6a1-ca8c5dd0fa4a) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:04,280] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 17 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:04,295] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 17 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:14,311] INFO [GroupCoordinator 3]: Member alltoolsStream-43158174-2a27-46d2-a8e8-262f6bd2eede-StreamThread-1-consumer-5e9d8ab3-76a5-4dd4-b6a1-ca8c5dd0fa4a in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:14,311] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 17 (__consumer_offsets-2) (reason: removing member alltoolsStream-43158174-2a27-46d2-a8e8-262f6bd2eede-StreamThread-1-consumer-5e9d8ab3-76a5-4dd4-b6a1-ca8c5dd0fa4a on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:14,311] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 18 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:40,266] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 18 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-55ab7f84-2b11-4910-9415-5da7851b6cd0-StreamThread-1-consumer-975335cc-ac81-4132-a35a-cbf94c592fca) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:40,267] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 19 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:40,276] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 19 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:04:50,279] INFO [GroupCoordinator 3]: Member alltoolsStream-55ab7f84-2b11-4910-9415-5da7851b6cd0-StreamThread-1-consumer-975335cc-ac81-4132-a35a-cbf94c592fca in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:50,280] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 19 (__consumer_offsets-2) (reason: removing member alltoolsStream-55ab7f84-2b11-4910-9415-5da7851b6cd0-StreamThread-1-consumer-975335cc-ac81-4132-a35a-cbf94c592fca on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:50,280] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 20 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:58,780] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 20 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-ee5b9cba-bcc2-4ead-932e-55fb396c051a-StreamThread-1-consumer-36842a7d-3fdd-4d10-9203-25419c8caeca) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:58,780] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 21 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:04:58,795] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 21 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:05:01,595] INFO [GroupMetadataManager brokerId=2] Group console-consumer-85767 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:05:01,595] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:05:08,812] INFO [GroupCoordinator 3]: Member alltoolsStream-ee5b9cba-bcc2-4ead-932e-55fb396c051a-StreamThread-1-consumer-36842a7d-3fdd-4d10-9203-25419c8caeca in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:05:08,812] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 21 (__consumer_offsets-2) (reason: removing member alltoolsStream-ee5b9cba-bcc2-4ead-932e-55fb396c051a-StreamThread-1-consumer-36842a7d-3fdd-4d10-9203-25419c8caeca on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:05:08,812] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 22 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:05:12,270] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:05:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:07:39,308] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-2289 in state PreparingRebalance with old generation 1 (__consumer_offsets-10) (reason: removing member consumer-1-8a48e5fa-e017-4710-8700-64319d641cd5 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:07:39,309] INFO [GroupCoordinator 2]: Group console-consumer-2289 with generation 2 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:07:51,230] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63347 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 15:07:51,233] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63347 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:07:51,236] INFO Established session 0x100048300d50009 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:63347 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:07:51,575] INFO Got user-level KeeperException when processing sessionid:0x100048300d50009 type:setData cxid:0x6 zxid:0x17d txntype:-1 reqpath:n/a Error Path:/config/topics/tools3 Error:KeeperErrorCode = NoNode for /config/topics/tools3 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:07:51,625] INFO Processed session termination for sessionid: 0x100048300d50009 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:07:51,630] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63347 which had sessionid 0x100048300d50009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 15:07:51,642] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,642] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,642] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,649] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:07:51,649] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:07:51,650] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:07:51,652] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-20 15:07:51,652] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-20 15:07:51,653] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-20 15:07:51,653] INFO Created log for partition tools3-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:07:51,654] INFO Created log for partition tools3-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:07:51,654] INFO Created log for partition tools3-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:07:51,656] INFO [Partition tools3-0 broker=1] No checkpointed highwatermark is found for partition tools3-0 (kafka.cluster.Partition)
[2019-01-20 15:07:51,656] INFO [Partition tools3-1 broker=2] No checkpointed highwatermark is found for partition tools3-1 (kafka.cluster.Partition)
[2019-01-20 15:07:51,656] INFO [Partition tools3-2 broker=3] No checkpointed highwatermark is found for partition tools3-2 (kafka.cluster.Partition)
[2019-01-20 15:07:51,656] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,656] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,657] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,658] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,658] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,659] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,659] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:07:51,660] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:07:51,660] INFO [Partition tools3-2 broker=3] tools3-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:07:51,668] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,668] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,669] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,673] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:07:51,674] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:07:51,676] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:07:51,676] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-20 15:07:51,676] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-20 15:07:51,678] INFO Created log for partition tools3-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:07:51,678] INFO Created log for partition tools3-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:07:51,679] INFO [Partition tools3-0 broker=2] No checkpointed highwatermark is found for partition tools3-0 (kafka.cluster.Partition)
[2019-01-20 15:07:51,679] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-01-20 15:07:51,679] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,679] INFO [Partition tools3-2 broker=1] No checkpointed highwatermark is found for partition tools3-2 (kafka.cluster.Partition)
[2019-01-20 15:07:51,680] INFO Created log for partition tools3-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:07:51,681] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,681] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,683] INFO [Partition tools3-1 broker=3] No checkpointed highwatermark is found for partition tools3-1 (kafka.cluster.Partition)
[2019-01-20 15:07:51,683] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools3-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,683] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,684] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:07:51,685] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools3-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,686] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,687] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools3-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:07:51,797] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:07:51,798] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:07:51,815] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:07:51,816] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:07:51,892] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:07:51,894] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:08:02,134] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-87ecb692-f41f-42a2-b2a2-e8de50ef368c-StreamThread-1-consumer-b7307110-2ed7-4c1d-b3cf-9aa376c8affa) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:08:02,135] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:08:02,144] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:09:57,162] INFO [GroupCoordinator 3]: Member alltoolsStream-87ecb692-f41f-42a2-b2a2-e8de50ef368c-StreamThread-1-consumer-b7307110-2ed7-4c1d-b3cf-9aa376c8affa in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:09:57,163] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-87ecb692-f41f-42a2-b2a2-e8de50ef368c-StreamThread-1-consumer-b7307110-2ed7-4c1d-b3cf-9aa376c8affa on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:09:57,164] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:10:34,590] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-f65bae75-9a16-4d4d-81eb-05d23e13afe3-StreamThread-1-consumer-d89cbab0-e409-4512-8250-e50cb24d8a7a) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:10:34,590] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 3 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:10:34,600] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:10:44,602] INFO [GroupCoordinator 3]: Member alltoolsStream-f65bae75-9a16-4d4d-81eb-05d23e13afe3-StreamThread-1-consumer-d89cbab0-e409-4512-8250-e50cb24d8a7a in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:10:44,603] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: removing member alltoolsStream-f65bae75-9a16-4d4d-81eb-05d23e13afe3-StreamThread-1-consumer-d89cbab0-e409-4512-8250-e50cb24d8a7a on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:10:44,604] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 4 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:13:56,043] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-66670 in state PreparingRebalance with old generation 0 (__consumer_offsets-46) (reason: Adding new member consumer-1-4811ac9e-68c3-44c9-a0ca-531c2c9380e6) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:13:56,044] INFO [GroupCoordinator 2]: Stabilized group console-consumer-66670 generation 1 (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:13:56,048] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-66670 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:13:59,425] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-66670 in state PreparingRebalance with old generation 1 (__consumer_offsets-46) (reason: removing member consumer-1-4811ac9e-68c3-44c9-a0ca-531c2c9380e6 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:13:59,425] INFO [GroupCoordinator 2]: Group console-consumer-66670 with generation 2 is now empty (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:07,112] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-50031 in state PreparingRebalance with old generation 0 (__consumer_offsets-40) (reason: Adding new member consumer-1-aac296b1-ab0a-4f5c-b100-29d27d0f8c4a) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:07,113] INFO [GroupCoordinator 2]: Stabilized group console-consumer-50031 generation 1 (__consumer_offsets-40) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:07,117] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-50031 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:29,184] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 4 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-b7633171-463b-414d-96fc-061d6734475b-StreamThread-1-consumer-f1f35ebf-50e6-4d35-8c85-983705ccc490) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:29,185] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 5 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:29,194] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:39,197] INFO [GroupCoordinator 3]: Member alltoolsStream-b7633171-463b-414d-96fc-061d6734475b-StreamThread-1-consumer-f1f35ebf-50e6-4d35-8c85-983705ccc490 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:39,198] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 5 (__consumer_offsets-2) (reason: removing member alltoolsStream-b7633171-463b-414d-96fc-061d6734475b-StreamThread-1-consumer-f1f35ebf-50e6-4d35-8c85-983705ccc490 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:39,199] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 6 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:14:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:15:01,593] INFO [GroupMetadataManager brokerId=2] Group console-consumer-66670 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:15:01,595] INFO [GroupMetadataManager brokerId=2] Group console-consumer-2289 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:15:01,597] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:15:12,270] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:15:12,272] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:17:40,328] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-50031 in state PreparingRebalance with old generation 1 (__consumer_offsets-40) (reason: removing member consumer-1-aac296b1-ab0a-4f5c-b100-29d27d0f8c4a on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:17:40,328] INFO [GroupCoordinator 2]: Group console-consumer-50031 with generation 2 is now empty (__consumer_offsets-40) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:17:49,984] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63737 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 15:17:49,984] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63737 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:17:49,984] INFO Established session 0x100048300d5000a with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:63737 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:17:50,327] INFO Got user-level KeeperException when processing sessionid:0x100048300d5000a type:setData cxid:0x6 zxid:0x189 txntype:-1 reqpath:n/a Error Path:/config/topics/tools4 Error:KeeperErrorCode = NoNode for /config/topics/tools4 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:17:50,374] INFO Processed session termination for sessionid: 0x100048300d5000a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:17:50,374] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63737 which had sessionid 0x100048300d5000a (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 15:17:50,374] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,374] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools4-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,374] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,389] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:17:50,389] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:17:50,389] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-20 15:17:50,389] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:17:50,389] INFO Created log for partition tools4-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:17:50,389] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:17:50,389] INFO [Partition tools4-1 broker=1] No checkpointed highwatermark is found for partition tools4-1 (kafka.cluster.Partition)
[2019-01-20 15:17:50,389] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,389] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,389] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:17:50,389] INFO Created log for partition tools4-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:17:50,389] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:17:50,389] INFO [Partition tools4-2 broker=2] No checkpointed highwatermark is found for partition tools4-2 (kafka.cluster.Partition)
[2019-01-20 15:17:50,389] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,389] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,389] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:17:50,389] INFO Created log for partition tools4-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:17:50,405] INFO [Partition tools4-0 broker=3] No checkpointed highwatermark is found for partition tools4-0 (kafka.cluster.Partition)
[2019-01-20 15:17:50,405] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,405] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,405] INFO [Partition tools4-0 broker=3] tools4-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:17:50,405] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,405] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,405] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,405] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:17:50,405] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:17:50,405] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:17:50,421] INFO Created log for partition tools4-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:17:50,421] INFO [Partition tools4-0 broker=1] No checkpointed highwatermark is found for partition tools4-0 (kafka.cluster.Partition)
[2019-01-20 15:17:50,421] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,421] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,421] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 15:17:50,421] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:17:50,421] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,421] INFO Created log for partition tools4-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:17:50,421] INFO [Partition tools4-1 broker=2] No checkpointed highwatermark is found for partition tools4-1 (kafka.cluster.Partition)
[2019-01-20 15:17:50,421] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,421] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools4-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,421] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools4-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,421] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-20 15:17:50,421] INFO Created log for partition tools4-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:17:50,421] INFO [Partition tools4-2 broker=3] No checkpointed highwatermark is found for partition tools4-2 (kafka.cluster.Partition)
[2019-01-20 15:17:50,421] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:17:50,421] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,421] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools4-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:17:50,468] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:17:50,468] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:17:50,593] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:17:50,593] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:17:50,655] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:17:50,655] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:17:55,405] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-86483 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-1-5bb83859-c88c-481a-9237-3abb96d19ef4) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:17:55,405] INFO [GroupCoordinator 1]: Stabilized group console-consumer-86483 generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:17:55,405] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-86483 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:18:06,516] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-49404edf-7103-45f6-a91d-3453e1d3cb3d-StreamThread-1-consumer-ccd3c854-fa6a-4994-8264-2a80e961bb6b) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:18:06,516] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:18:06,532] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:18:25,561] INFO [GroupCoordinator 3]: Member alltoolsStream-49404edf-7103-45f6-a91d-3453e1d3cb3d-StreamThread-1-consumer-ccd3c854-fa6a-4994-8264-2a80e961bb6b in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:18:25,561] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-49404edf-7103-45f6-a91d-3453e1d3cb3d-StreamThread-1-consumer-ccd3c854-fa6a-4994-8264-2a80e961bb6b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:18:25,561] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:12,515] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-86483 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-1-5bb83859-c88c-481a-9237-3abb96d19ef4 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:12,515] INFO [GroupCoordinator 1]: Group console-consumer-86483 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:26,827] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64009 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 15:24:26,827] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64009 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:24:26,827] INFO Established session 0x100048300d5000b with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:64009 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 15:24:27,155] INFO Got user-level KeeperException when processing sessionid:0x100048300d5000b type:setData cxid:0x6 zxid:0x195 txntype:-1 reqpath:n/a Error Path:/config/topics/tools5 Error:KeeperErrorCode = NoNode for /config/topics/tools5 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:24:27,202] INFO Processed session termination for sessionid: 0x100048300d5000b (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 15:24:27,202] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64009 which had sessionid 0x100048300d5000b (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 15:24:27,217] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools5-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,217] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools5-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,217] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools5-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,217] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:24:27,217] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:24:27,217] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:24:27,217] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:24:27,217] INFO Created log for partition tools5-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:24:27,217] INFO [Partition tools5-2 broker=1] No checkpointed highwatermark is found for partition tools5-2 (kafka.cluster.Partition)
[2019-01-20 15:24:27,217] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:24:27,217] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-20 15:24:27,217] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,233] INFO Created log for partition tools5-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:24:27,233] INFO Created log for partition tools5-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:24:27,233] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,233] INFO [Partition tools5-0 broker=2] No checkpointed highwatermark is found for partition tools5-0 (kafka.cluster.Partition)
[2019-01-20 15:24:27,233] INFO [Partition tools5-1 broker=3] No checkpointed highwatermark is found for partition tools5-1 (kafka.cluster.Partition)
[2019-01-20 15:24:27,233] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:24:27,233] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,233] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,233] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,233] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,233] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:24:27,233] INFO [Partition tools5-1 broker=3] tools5-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-20 15:24:27,233] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,253] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,254] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,254] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:24:27,257] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-01-20 15:24:27,257] INFO Created log for partition tools5-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:24:27,258] INFO [Partition tools5-1 broker=1] No checkpointed highwatermark is found for partition tools5-1 (kafka.cluster.Partition)
[2019-01-20 15:24:27,258] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,259] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools5-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,259] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:24:27,260] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-20 15:24:27,260] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools5-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,262] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-20 15:24:27,263] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-20 15:24:27,263] INFO Created log for partition tools5-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:24:27,264] INFO [Partition tools5-0 broker=3] No checkpointed highwatermark is found for partition tools5-0 (kafka.cluster.Partition)
[2019-01-20 15:24:27,264] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,264] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools5-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,265] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools5-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,270] INFO Created log for partition tools5-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-20 15:24:27,271] INFO [Partition tools5-2 broker=2] No checkpointed highwatermark is found for partition tools5-2 (kafka.cluster.Partition)
[2019-01-20 15:24:27,271] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-20 15:24:27,272] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools5-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,272] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools5-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 15:24:27,390] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools5-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:24:27,390] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:24:27,608] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools5-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:24:27,608] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools5-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 15:24:27,608] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:24:27,608] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 15:24:33,498] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-53893 in state PreparingRebalance with old generation 0 (__consumer_offsets-39) (reason: Adding new member consumer-1-dcd3e6a6-ce62-4b71-97c2-4ee69e34a409) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:33,498] INFO [GroupCoordinator 1]: Stabilized group console-consumer-53893 generation 1 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:33,498] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-53893 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:37,405] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-c69118c9-6162-4902-88e8-b996588db6bc-StreamThread-1-consumer-90dd229d-9771-479c-8f58-f02a9ebdbac2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:37,405] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 3 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:37,420] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:44,686] INFO [GroupMetadataManager brokerId=1] Group console-consumer-86483 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:24:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:24:56,436] INFO [GroupCoordinator 3]: Member alltoolsStream-c69118c9-6162-4902-88e8-b996588db6bc-StreamThread-1-consumer-90dd229d-9771-479c-8f58-f02a9ebdbac2 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:56,436] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: removing member alltoolsStream-c69118c9-6162-4902-88e8-b996588db6bc-StreamThread-1-consumer-90dd229d-9771-479c-8f58-f02a9ebdbac2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:24:56,436] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 4 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:25:01,596] INFO [GroupMetadataManager brokerId=2] Group console-consumer-50031 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:25:01,596] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:25:12,269] INFO [GroupMetadataManager brokerId=3] Group alltoolsStream transitioned to Dead in generation 4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:25:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:26:46,691] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-9ec46397-190c-4258-81b9-d48684b2c111-StreamThread-1-consumer-1f4e7ec0-5831-46d3-afd5-5ad19cd7a579) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:26:46,691] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:26:46,707] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:26:56,734] INFO [GroupCoordinator 3]: Member alltoolsStream-9ec46397-190c-4258-81b9-d48684b2c111-StreamThread-1-consumer-1f4e7ec0-5831-46d3-afd5-5ad19cd7a579 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:26:56,734] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-9ec46397-190c-4258-81b9-d48684b2c111-StreamThread-1-consumer-1f4e7ec0-5831-46d3-afd5-5ad19cd7a579 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:26:56,734] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:27:52,359] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-c258a2fb-14ce-4211-ae59-d19b3a6a6dc1-StreamThread-1-consumer-72688ff6-269f-4d56-a044-b9821c6384ba) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:27:52,359] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 3 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:27:52,390] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:28:02,406] INFO [GroupCoordinator 3]: Member alltoolsStream-c258a2fb-14ce-4211-ae59-d19b3a6a6dc1-StreamThread-1-consumer-72688ff6-269f-4d56-a044-b9821c6384ba in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:28:02,406] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: removing member alltoolsStream-c258a2fb-14ce-4211-ae59-d19b3a6a6dc1-StreamThread-1-consumer-72688ff6-269f-4d56-a044-b9821c6384ba on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:28:02,406] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 4 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:29:24,311] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 4 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-ef16f5a8-cf74-46d6-a8a5-8487f3a774fd-StreamThread-1-consumer-7a5d85c9-cdb8-4e37-bf0e-7c429cb5737d) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:29:24,311] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 5 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:29:24,326] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:34:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:35:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:35:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:44:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:45:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:45:12,271] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:54:44,688] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:55:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:55:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 15:57:28,405] INFO [GroupCoordinator 3]: Member alltoolsStream-ef16f5a8-cf74-46d6-a8a5-8487f3a774fd-StreamThread-1-consumer-7a5d85c9-cdb8-4e37-bf0e-7c429cb5737d in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:57:28,405] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 5 (__consumer_offsets-2) (reason: removing member alltoolsStream-ef16f5a8-cf74-46d6-a8a5-8487f3a774fd-StreamThread-1-consumer-7a5d85c9-cdb8-4e37-bf0e-7c429cb5737d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:57:28,405] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 6 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:58:34,936] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 6 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-4eba9794-195f-4ea2-a116-92c8f7591297-StreamThread-1-consumer-d68b8c9f-337e-4294-abfe-eead7b3cd6cf) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:58:34,936] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 7 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:58:34,936] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:59:33,045] INFO [GroupCoordinator 3]: Member alltoolsStream-4eba9794-195f-4ea2-a116-92c8f7591297-StreamThread-1-consumer-d68b8c9f-337e-4294-abfe-eead7b3cd6cf in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:59:33,045] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 7 (__consumer_offsets-2) (reason: removing member alltoolsStream-4eba9794-195f-4ea2-a116-92c8f7591297-StreamThread-1-consumer-d68b8c9f-337e-4294-abfe-eead7b3cd6cf on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 15:59:33,045] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 8 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:00:09,983] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 8 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-c42de40a-352e-46df-9502-51abec7b4cdf-StreamThread-1-consumer-062cd060-4cb9-48e8-8b56-349c9aa398bd) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:00:09,983] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 9 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:00:09,998] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:00:20,014] INFO [GroupCoordinator 3]: Member alltoolsStream-c42de40a-352e-46df-9502-51abec7b4cdf-StreamThread-1-consumer-062cd060-4cb9-48e8-8b56-349c9aa398bd in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:00:20,014] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 9 (__consumer_offsets-2) (reason: removing member alltoolsStream-c42de40a-352e-46df-9502-51abec7b4cdf-StreamThread-1-consumer-062cd060-4cb9-48e8-8b56-349c9aa398bd on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:00:20,014] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 10 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:01:53,811] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 10 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-53854db9-8754-47ef-85bb-25e7384acabc-StreamThread-1-consumer-664c7a02-bce8-40e9-9fdd-c6c0ca632b61) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:01:53,811] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 11 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:01:53,827] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:03,843] INFO [GroupCoordinator 3]: Member alltoolsStream-53854db9-8754-47ef-85bb-25e7384acabc-StreamThread-1-consumer-664c7a02-bce8-40e9-9fdd-c6c0ca632b61 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:03,843] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 11 (__consumer_offsets-2) (reason: removing member alltoolsStream-53854db9-8754-47ef-85bb-25e7384acabc-StreamThread-1-consumer-664c7a02-bce8-40e9-9fdd-c6c0ca632b61 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:03,843] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 12 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:42,671] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 12 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-ac1ae3a6-ab1e-4995-9284-df8a6cad1c89-StreamThread-1-consumer-24d232e3-ae67-4103-9546-2572b48a1ca0) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:42,671] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 13 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:42,671] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 13 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:52,689] INFO [GroupCoordinator 3]: Member alltoolsStream-ac1ae3a6-ab1e-4995-9284-df8a6cad1c89-StreamThread-1-consumer-24d232e3-ae67-4103-9546-2572b48a1ca0 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:52,689] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 13 (__consumer_offsets-2) (reason: removing member alltoolsStream-ac1ae3a6-ab1e-4995-9284-df8a6cad1c89-StreamThread-1-consumer-24d232e3-ae67-4103-9546-2572b48a1ca0 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:52,689] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 14 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:02:52,689] INFO [GroupCoordinator 3]: Member alltoolsStream-ac1ae3a6-ab1e-4995-9284-df8a6cad1c89-StreamThread-1-consumer-24d232e3-ae67-4103-9546-2572b48a1ca0 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:16,422] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 14 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-5237489c-c56e-44c9-bc03-adc2d70de935-StreamThread-1-consumer-050051b1-f558-4a05-b105-096fbf62ce0c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:16,422] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 15 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:16,437] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 15 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:36,390] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 15 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-5667bdb7-4c36-4446-b968-ac91b7b8a851-StreamThread-1-consumer-ecdf0343-a8b7-4554-a711-6614c93e2ff5) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:38,499] INFO [GroupCoordinator 3]: Member alltoolsStream-5237489c-c56e-44c9-bc03-adc2d70de935-StreamThread-1-consumer-050051b1-f558-4a05-b105-096fbf62ce0c in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:38,499] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 16 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:38,514] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 16 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:54,537] INFO [GroupCoordinator 3]: Member alltoolsStream-5667bdb7-4c36-4446-b968-ac91b7b8a851-StreamThread-1-consumer-ecdf0343-a8b7-4554-a711-6614c93e2ff5 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:54,537] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 16 (__consumer_offsets-2) (reason: removing member alltoolsStream-5667bdb7-4c36-4446-b968-ac91b7b8a851-StreamThread-1-consumer-ecdf0343-a8b7-4554-a711-6614c93e2ff5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:03:54,537] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 17 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:04:44,683] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:05:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:05:12,272] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:07:36,812] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 17 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-346b0794-5ad2-4e45-804e-cd7d71a24de8-StreamThread-1-consumer-05db4f3b-6d06-460a-a672-545d5ea41026) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:07:36,812] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 18 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:07:36,812] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 18 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 16:14:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:15:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:15:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:24:44,676] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:25:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:25:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:34:44,676] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:35:01,605] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:35:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:44:44,684] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:45:01,595] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:45:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:54:44,677] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:55:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 16:55:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:04:44,680] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:05:01,605] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:05:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:14:44,676] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:15:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:15:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:24:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:25:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:25:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:34:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:35:01,591] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:35:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:44:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:45:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:45:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:54:44,674] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:55:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 17:55:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:04:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:05:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:05:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:14:44,676] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:15:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:15:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:24:44,675] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:25:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:25:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:34:44,687] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:35:01,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:35:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:44:44,674] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:45:01,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:45:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:54:44,686] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:55:01,595] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 18:55:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:04:44,676] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:05:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:05:12,269] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:14:44,688] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:15:01,593] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:15:12,270] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:24:44,683] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:45:01,500] INFO [GroupCoordinator 1]: Member consumer-1-dcd3e6a6-ce62-4b71-97c2-4ee69e34a409 in group console-consumer-53893 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:01,515] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:51075-0 (kafka.network.Processor)
[2019-01-20 19:45:01,515] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:64020-30 (kafka.network.Processor)
[2019-01-20 19:45:01,515] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:64019-33 (kafka.network.Processor)
[2019-01-20 19:45:01,515] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-53893 in state PreparingRebalance with old generation 1 (__consumer_offsets-39) (reason: removing member consumer-1-dcd3e6a6-ce62-4b71-97c2-4ee69e34a409 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:01,500] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:51074-0 (kafka.network.Processor)
[2019-01-20 19:45:01,515] INFO [GroupCoordinator 1]: Group console-consumer-53893 with generation 2 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:01,531] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=954100613, epoch=64971) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-20 19:45:01,577] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-53893 in state PreparingRebalance with old generation 2 (__consumer_offsets-39) (reason: Adding new member consumer-1-0793f553-fec7-4da3-85a7-fa9ba3be8639) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:01,577] INFO [GroupCoordinator 1]: Stabilized group console-consumer-53893 generation 3 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:01,577] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-53893 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:01,921] WARN Client session timed out, have not heard from server in 1215672ms for sessionid 0x100048300d50000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:01,921] INFO Client session timed out, have not heard from server in 1215672ms for sessionid 0x100048300d50000, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:01,921] WARN Unable to read additional data from client sessionid 0x100048300d50000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:01,937] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51003 which had sessionid 0x100048300d50000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:02,095] INFO [GroupCoordinator 3]: Member alltoolsStream-346b0794-5ad2-4e45-804e-cd7d71a24de8-StreamThread-1-consumer-05db4f3b-6d06-460a-a672-545d5ea41026 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:02,111] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=2043131013, epoch=46206) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-20 19:45:02,095] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 18 (__consumer_offsets-2) (reason: removing member alltoolsStream-346b0794-5ad2-4e45-804e-cd7d71a24de8-StreamThread-1-consumer-05db4f3b-6d06-460a-a672-545d5ea41026 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:02,095] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:49300-31 (kafka.network.Processor)
[2019-01-20 19:45:01,531] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=954100613, epoch=64971)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-20 19:45:02,095] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:58103-2 (kafka.network.Processor)
[2019-01-20 19:45:02,111] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 19 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:02,111] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=2043131013, epoch=46206)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-20 19:45:02,111] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1418010131, epoch=64968) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-20 19:45:02,111] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1407830366, epoch=64963) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-20 19:45:02,111] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:64018-21 (kafka.network.Processor)
[2019-01-20 19:45:02,127] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1407830366, epoch=64963)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-20 19:45:02,127] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1418010131, epoch=64968)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-20 19:45:02,914] WARN Client session timed out, have not heard from server in 1215672ms for sessionid 0x100048300d50002 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:02,914] WARN Client session timed out, have not heard from server in 1215669ms for sessionid 0x100048300d50001 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:02,914] INFO Client session timed out, have not heard from server in 1215672ms for sessionid 0x100048300d50002, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:02,914] INFO Client session timed out, have not heard from server in 1215669ms for sessionid 0x100048300d50001, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:02,914] WARN Unable to read additional data from client sessionid 0x100048300d50001, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:02,914] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51029 which had sessionid 0x100048300d50001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:02,914] WARN Unable to read additional data from client sessionid 0x100048300d50002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:02,914] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51055 which had sessionid 0x100048300d50002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:02,961] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 19 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-346b0794-5ad2-4e45-804e-cd7d71a24de8-StreamThread-1-consumer-b290844e-a7a0-44d9-83a3-d9605f34b98d) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:03,081] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 20 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:03,114] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 20 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:45:03,130] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:03,304] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64974 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 19:45:03,303] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:03,521] INFO Client attempting to renew session 0x100048300d50000 at /0:0:0:0:0:0:0:1:64974 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:03,597] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100048300d50000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:03,597] INFO Established session 0x100048300d50000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64974 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:03,955] INFO Expiring session 0x100048300d50001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:04,002] INFO Expiring session 0x100048300d50002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:04,018] INFO Processed session termination for sessionid: 0x100048300d50001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 19:45:04,018] INFO Processed session termination for sessionid: 0x100048300d50002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 19:45:04,955] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:04,908] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, tools5-1, edited-0, tools3-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:05,033] INFO Accepted socket connection from /127.0.0.1:64991 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 19:45:05,002] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,127] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64993 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 19:45:05,033] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,158] INFO Client attempting to renew session 0x100048300d50002 at /127.0.0.1:64991 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:05,189] INFO Invalid session 0x100048300d50002 for client /127.0.0.1:64991, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:05,189] INFO Closed socket connection for client /127.0.0.1:64991 which had sessionid 0x100048300d50002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:05,064] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:05,127] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,189] WARN Unable to reconnect to ZooKeeper service, session 0x100048300d50002 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,252] INFO Client attempting to renew session 0x100048300d50001 at /0:0:0:0:0:0:0:1:64993 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:05,189] INFO EventThread shut down for session: 0x100048300d50002 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,268] INFO Invalid session 0x100048300d50001 for client /0:0:0:0:0:0:0:1:64993, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:05,268] WARN Unable to reconnect to ZooKeeper service, session 0x100048300d50001 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,299] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64993 which had sessionid 0x100048300d50001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 19:45:05,283] INFO EventThread shut down for session: 0x100048300d50001 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,299] INFO Unable to reconnect to ZooKeeper service, session 0x100048300d50001 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,330] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 19:45:05,268] INFO Unable to reconnect to ZooKeeper service, session 0x100048300d50002 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:05,346] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:05,408] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 19:45:05,346] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 19:45:05,455] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 19:45:05,533] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 19:45:05,549] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 1 from offset 8. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:05,705] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:06,033] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64996 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 19:45:05,549] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 19:45:05,986] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 19:45:06,033] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:06,049] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64996 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:06,064] INFO Established session 0x100048300d5000c with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64996 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:06,064] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100048300d5000c, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:06,064] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 19:45:06,080] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 19:45:06,080] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 19:45:06,283] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:06,283] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:65003 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 19:45:06,283] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:06,299] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:65003 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:06,299] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100048300d5000d, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 19:45:06,299] INFO Established session 0x100048300d5000d with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:65003 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 19:45:06,314] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 19:45:06,314] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 19:45:06,580] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0, mytools-0, tools1-2, tools5-2, tools2-0, tools4-1, tools-0, edited-1, tools3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:06,611] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:06,689] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools3-0 -> (offset=0, leaderEpoch=1), tools4-1 -> (offset=0, leaderEpoch=1), tools5-2 -> (offset=8, leaderEpoch=1), tools1-2 -> (offset=0, leaderEpoch=1), edited-1 -> (offset=9, leaderEpoch=1), mytools-0 -> (offset=1, leaderEpoch=1), alltools-0 -> (offset=4, leaderEpoch=2), tools-0 -> (offset=1, leaderEpoch=1), tools2-0 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:06,830] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:06,783] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, my-example-topic-0, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:06,892] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 1 from offset 5. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:06,877] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 4 from offset 40. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:06,970] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,001] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,017] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,033] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,033] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:06,970] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools2-2, edited-0, tools1-1, tools3-2, alltools-2, tools5-1, tools4-0, tools-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:07,111] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools3-0, tools4-1, alltools-2, tools5-2, tools1-2, edited-1, mytools-0, alltools-0, tools-0, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:07,158] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,220] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,111] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition edited-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,126] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:07,236] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,236] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:07,236] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,236] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition mytools-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,236] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition tools-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,236] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,236] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:07,251] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition tools5-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,251] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,251] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:07,236] WARN [LeaderEpochCache tools3-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,251] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,251] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:07,251] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition alltools-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:07,267] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,283] WARN [LeaderEpochCache tools4-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,126] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=1), tools1-1 -> (offset=0, leaderEpoch=1), tools2-2 -> (offset=0, leaderEpoch=1), tools-2 -> (offset=0, leaderEpoch=1), alltools-2 -> (offset=5, leaderEpoch=2), tools5-1 -> (offset=5, leaderEpoch=1), edited-0 -> (offset=8, leaderEpoch=1), tools3-2 -> (offset=0, leaderEpoch=1), mytools-2 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:07,361] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 1 from offset 8. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,361] INFO [Partition tools4-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:07,423] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,126] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:07,345] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:07,423] INFO [Partition tools3-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:07,461] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,447] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,551] WARN [LeaderEpochCache tools1-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,603] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 2 from offset 5. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:45:07,457] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:07,578] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:07,663] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,669] WARN [LeaderEpochCache tools2-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,697] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 1 from offset 9. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,667] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,622] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:07,745] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:07,760] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 19:45:07,811] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:07,901] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 2 from offset 4. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:45:07,886] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:07,867] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:08,002] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:07,994] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-20 19:45:08,116] INFO [Partition tools1-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,143] INFO [Partition tools2-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,059] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:08,098] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:08,281] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,236] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:08,372] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:08,419] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition alltools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:08,527] INFO [Partition tools4-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,518] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,562] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, tools1-0, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, mytools-1, edited-2, __consumer_offsets-38, __consumer_offsets-17, tools4-2, tools3-1, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, tools5-0, tools-1, tools2-1, __consumer_offsets-20, __consumer_offsets-44, alltools-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:08,596] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,600] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,625] WARN [LeaderEpochCache __consumer_offsets-29] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:08,583] INFO [Partition tools1-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,648] INFO [Partition alltools-1 broker=3] alltools-1 starts at Leader Epoch 6 from offset 6. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,625] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:08,687] INFO [Partition tools2-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,713] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-20 19:45:08,744] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,746] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:45:08,757] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:45:08,761] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,752] INFO [Partition tools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,858] INFO [Partition tools5-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,879] INFO [Partition edited-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,852] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,768] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 19:45:08,906] INFO [Partition tools3-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,843] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:08,924] INFO [Partition mytools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:08,902] WARN [LeaderEpochCache __consumer_offsets-26] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:08,954] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,954] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:08,903] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-20 19:45:08,976] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:08,977] WARN [LeaderEpochCache __consumer_offsets-23] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,008] INFO [Partition edited-2 broker=3] edited-2 starts at Leader Epoch 3 from offset 8. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:08,993] INFO [Partition tools5-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,067] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,098] INFO [Partition mytools-1 broker=3] mytools-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:09,094] INFO [Partition edited-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,106] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,155] INFO [Partition mytools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,165] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,177] INFO [Partition alltools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,186] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,212] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,229] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,200] INFO [Partition tools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,234] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,244] WARN [LeaderEpochCache __consumer_offsets-20] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,262] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,281] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,276] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,288] WARN [LeaderEpochCache __consumer_offsets-17] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,305] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,313] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,315] WARN [LeaderEpochCache __consumer_offsets-14] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,366] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools-1, edited-2, mytools-1, tools2-1, tools4-2, tools1-0, tools3-1, alltools-1, tools5-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:09,398] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=3), mytools-1 -> (offset=0, leaderEpoch=3), edited-2 -> (offset=8, leaderEpoch=3), tools4-2 -> (offset=1, leaderEpoch=3), tools3-1 -> (offset=1, leaderEpoch=3), tools5-0 -> (offset=10, leaderEpoch=3), tools-1 -> (offset=0, leaderEpoch=3), tools2-1 -> (offset=1, leaderEpoch=3), alltools-1 -> (offset=6, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:45:09,399] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:09,380] INFO [Partition tools5-0 broker=3] tools5-0 starts at Leader Epoch 3 from offset 10. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:09,502] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 19:45:09,518] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools1-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:09,526] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools2-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:09,537] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:09,539] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-20 19:45:09,495] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,540] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:09,542] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:09,543] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:09,545] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-20 19:45:09,542] WARN [LeaderEpochCache __consumer_offsets-11] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,567] INFO [Partition mytools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,584] INFO [Partition tools3-1 broker=3] tools3-1 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:09,671] INFO [Partition tools4-2 broker=3] tools4-2 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:09,673] INFO [Partition edited-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,708] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,708] WARN [LeaderEpochCache __consumer_offsets-8] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,740] INFO [Partition tools5-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,755] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,771] INFO [Partition alltools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,771] WARN [LeaderEpochCache __consumer_offsets-5] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:09,833] INFO [Partition tools-1 broker=3] tools-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:09,958] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 4 from offset 82. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:09,974] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-20 19:45:10,047] INFO [Partition alltools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-20 19:45:10,177] INFO [Partition tools2-1 broker=3] tools2-1 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:10,209] INFO [Partition tools1-0 broker=3] tools1-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 19:45:10,240] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,271] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,271] WARN [LeaderEpochCache __consumer_offsets-38] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:10,287] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,302] WARN [LeaderEpochCache __consumer_offsets-35] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:10,318] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,318] WARN [LeaderEpochCache __consumer_offsets-44] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:10,349] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,456] WARN [LeaderEpochCache __consumer_offsets-32] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:10,531] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,556] WARN [LeaderEpochCache __consumer_offsets-41] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:45:10,611] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:10,639] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:10,639] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:45:10,894] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:10,905] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:45:10,910] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:45:10,912] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:45:10,914] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:45:10,919] INFO [Partition tools1-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,931] INFO [Partition tools4-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,937] INFO [Partition tools3-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,943] INFO [Partition tools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:10,953] INFO [Partition tools2-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 19:45:15,240] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:45:15,242] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:45:15,243] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:45:25,924] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:45:25,924] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:45:25,924] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:50:05,501] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools1-0, mytools-1, edited-2, tools4-2, tools3-1, tools5-0, tools-1, tools2-1, alltools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:50:05,501] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 7 from offset 6. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-20 19:50:05,501] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools-1, edited-2, mytools-1, tools2-1, tools4-2, tools1-0, tools3-1, alltools-1, tools5-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:50:05,533] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools2-2, edited-0, tools1-1, tools3-2, alltools-2, tools5-1, tools4-0, tools-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:50:05,548] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=4), mytools-1 -> (offset=0, leaderEpoch=4), edited-2 -> (offset=8, leaderEpoch=4), tools4-2 -> (offset=1, leaderEpoch=4), tools3-1 -> (offset=1, leaderEpoch=4), tools5-0 -> (offset=10, leaderEpoch=4), tools-1 -> (offset=0, leaderEpoch=4), tools2-1 -> (offset=1, leaderEpoch=4), alltools-1 -> (offset=6, leaderEpoch=7)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:50:05,564] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,580] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, alltools-2, tools5-1, edited-0, tools3-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:50:05,580] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 4 from offset 8. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:05,611] INFO [Partition tools1-1 broker=3] tools1-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:05,611] WARN [LeaderEpochCache tools1-1] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:05,642] INFO [Partition tools2-2 broker=3] tools2-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:05,658] WARN [LeaderEpochCache tools2-2] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:05,689] INFO [Partition edited-0 broker=3] edited-0 starts at Leader Epoch 2 from offset 8. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:05,626] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=2), tools1-1 -> (offset=0, leaderEpoch=2), tools2-2 -> (offset=0, leaderEpoch=2), tools-2 -> (offset=0, leaderEpoch=2), alltools-2 -> (offset=5, leaderEpoch=3), tools5-1 -> (offset=5, leaderEpoch=2), edited-0 -> (offset=8, leaderEpoch=2), tools3-2 -> (offset=0, leaderEpoch=2), mytools-2 -> (offset=0, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 19:50:05,704] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,814] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 19:50:05,861] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools1-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,861] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools2-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,861] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition mytools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,861] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools5-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,861] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,861] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,876] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:05,876] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-20 19:50:05,814] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:05,814] INFO [Partition alltools-2 broker=3] alltools-2 starts at Leader Epoch 3 from offset 5. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 19:50:05,908] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:06,001] INFO [Partition mytools-2 broker=3] mytools-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:06,001] WARN [LeaderEpochCache mytools-2] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:06,001] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:06,033] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:06,033] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 4 from offset 10. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:06,033] INFO [Partition tools3-2 broker=3] tools3-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:06,048] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools3-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,048] WARN [LeaderEpochCache tools3-2] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:06,064] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 19:50:06,079] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition mytools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,095] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools5-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,095] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools4-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,111] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,111] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-20 19:50:06,111] INFO [Partition tools5-1 broker=3] tools5-1 starts at Leader Epoch 2 from offset 5. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:06,142] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:06,173] INFO [Partition tools4-0 broker=3] tools4-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:06,173] WARN [LeaderEpochCache tools4-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:06,189] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:06,189] INFO [Partition tools-2 broker=3] tools-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 19:50:06,189] WARN [LeaderEpochCache tools-2] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:06,220] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,251] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,251] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:06,267] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,267] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:06,282] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:06,298] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 19:50:06,298] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 19:50:06,314] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,376] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,376] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 19:50:06,939] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:06,939] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:50:06,939] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:06,939] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-20 19:50:06,939] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:50:06,939] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 19:50:06,939] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:07,142] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:07,142] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:07,142] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-20 19:50:07,142] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:50:07,142] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 19:52:15,494] INFO [GroupCoordinator 1]: Member consumer-1-0793f553-fec7-4da3-85a7-fa9ba3be8639 in group console-consumer-53893 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:52:15,494] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-53893 in state PreparingRebalance with old generation 3 (__consumer_offsets-39) (reason: removing member consumer-1-0793f553-fec7-4da3-85a7-fa9ba3be8639 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:52:15,494] INFO [GroupCoordinator 1]: Group console-consumer-53893 with generation 4 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 19:54:58,323] INFO [GroupMetadataManager brokerId=1] Group console-consumer-53893 transitioned to Dead in generation 4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:54:58,325] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:54:58,326] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:54:58,327] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:55:01,580] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 19:55:12,258] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 20:04:44,663] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 20:05:01,582] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 20:05:12,257] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 20:14:44,676] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,531] INFO [GroupCoordinator 3]: Member alltoolsStream-346b0794-5ad2-4e45-804e-cd7d71a24de8-StreamThread-1-consumer-b290844e-a7a0-44d9-83a3-d9605f34b98d in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 21:22:25,531] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 20 (__consumer_offsets-2) (reason: removing member alltoolsStream-346b0794-5ad2-4e45-804e-cd7d71a24de8-StreamThread-1-consumer-b290844e-a7a0-44d9-83a3-d9605f34b98d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 21:22:25,531] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 21 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 21:22:25,562] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1689367491, epoch=2941) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-20 21:22:25,562] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:64945-59 (kafka.network.Processor)
[2019-01-20 21:22:25,562] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1689367491, epoch=2941)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-20 21:22:25,562] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:65226-58 (kafka.network.Processor)
[2019-01-20 21:22:25,562] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:64944-56 (kafka.network.Processor)
[2019-01-20 21:22:25,562] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1609512422, epoch=3525) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-20 21:22:25,577] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1609512422, epoch=3525)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-20 21:22:25,593] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 21 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-346b0794-5ad2-4e45-804e-cd7d71a24de8-StreamThread-1-consumer-0f996495-bfc8-49b5-b902-ec948f316abc) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 21:22:25,609] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1786900956, epoch=2941) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-20 21:22:25,609] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1786900956, epoch=2941)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-20 21:22:25,609] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 22 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 21:22:25,609] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:64943-38 (kafka.network.Processor)
[2019-01-20 21:22:25,609] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 22 (kafka.coordinator.group.GroupCoordinator)
[2019-01-20 21:22:25,624] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:65229-40 (kafka.network.Processor)
[2019-01-20 21:22:25,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:25,968] WARN Client session timed out, have not heard from server in 4046241ms for sessionid 0x100048300d5000d (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:25,968] INFO Client session timed out, have not heard from server in 4046241ms for sessionid 0x100048300d5000d, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:25,968] WARN Unable to read additional data from client sessionid 0x100048300d5000d, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:25,971] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:65003 which had sessionid 0x100048300d5000d (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:26,494] WARN Client session timed out, have not heard from server in 4046238ms for sessionid 0x100048300d50000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:26,623] INFO Client session timed out, have not heard from server in 4046238ms for sessionid 0x100048300d50000, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:26,566] INFO Expiring session 0x100048300d50000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:26,635] WARN Unable to read additional data from client sessionid 0x100048300d50000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:26,818] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64974 which had sessionid 0x100048300d50000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:26,693] INFO Expiring session 0x100048300d5000c, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:26,927] INFO Expiring session 0x100048300d5000d, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:26,945] INFO Processed session termination for sessionid: 0x100048300d50000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 21:22:26,955] INFO Processed session termination for sessionid: 0x100048300d5000c (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 21:22:26,957] WARN Client session timed out, have not heard from server in 4045724ms for sessionid 0x100048300d5000c (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:26,968] INFO Processed session termination for sessionid: 0x100048300d5000d (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 21:22:26,988] INFO Client session timed out, have not heard from server in 4045724ms for sessionid 0x100048300d5000c, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:26,970] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64996 which had sessionid 0x100048300d5000c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:27,825] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,106] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49766 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 21:22:28,106] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,231] INFO Client attempting to renew session 0x100048300d5000d at /0:0:0:0:0:0:0:1:49766 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:28,231] INFO Invalid session 0x100048300d5000d for client /0:0:0:0:0:0:0:1:49766, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:28,231] WARN Unable to reconnect to ZooKeeper service, session 0x100048300d5000d has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,231] INFO Unable to reconnect to ZooKeeper service, session 0x100048300d5000d has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,231] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 21:22:28,231] INFO EventThread shut down for session: 0x100048300d5000d (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,247] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 21:22:28,247] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 21:22:28,231] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49766 which had sessionid 0x100048300d5000d (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:28,247] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:28,418] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,434] INFO Accepted socket connection from /127.0.0.1:49772 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 21:22:28,434] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,434] INFO Client attempting to establish new session at /127.0.0.1:49772 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:28,434] INFO Established session 0x100048300d5000e with negotiated timeout 6000 for client /127.0.0.1:49772 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:28,434] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100048300d5000e, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:28,450] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:28,450] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:28,903] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,059] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49773 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 21:22:28,793] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,059] INFO Accepted socket connection from /127.0.0.1:49774 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 21:22:29,059] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,121] INFO Client attempting to renew session 0x100048300d5000c at /0:0:0:0:0:0:0:1:49773 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:29,153] WARN Unable to reconnect to ZooKeeper service, session 0x100048300d5000c has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,153] INFO Invalid session 0x100048300d5000c for client /0:0:0:0:0:0:0:1:49773, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:29,153] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 21:22:29,153] INFO Unable to reconnect to ZooKeeper service, session 0x100048300d5000c has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,168] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49773 which had sessionid 0x100048300d5000c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:29,153] INFO EventThread shut down for session: 0x100048300d5000c (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,168] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 21:22:29,184] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 21:22:29,184] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:29,074] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,246] INFO Client attempting to renew session 0x100048300d50000 at /127.0.0.1:49774 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:29,246] INFO Invalid session 0x100048300d50000 for client /127.0.0.1:49774, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:29,262] INFO Closed socket connection for client /127.0.0.1:49774 which had sessionid 0x100048300d50000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-20 21:22:29,403] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,403] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,403] INFO Accepted socket connection from /127.0.0.1:49779 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 21:22:29,403] INFO Client attempting to establish new session at /127.0.0.1:49779 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:29,418] INFO Established session 0x100048300d5000f with negotiated timeout 6000 for client /127.0.0.1:49779 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:29,418] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100048300d5000f, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,418] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:29,418] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:29,262] WARN Unable to reconnect to ZooKeeper service, session 0x100048300d50000 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,606] INFO Unable to reconnect to ZooKeeper service, session 0x100048300d50000 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:29,606] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 21:22:29,262] INFO EventThread shut down for session: 0x100048300d50000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:30,652] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-20 21:22:30,793] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-20 21:22:30,918] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:31,001] INFO Got user-level KeeperException when processing sessionid:0x100048300d5000e type:multi cxid:0xd5 zxid:0x25b txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 21:22:31,120] INFO Got user-level KeeperException when processing sessionid:0x100048300d5000e type:multi cxid:0xd7 zxid:0x25c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-20 21:22:31,062] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools1-0, mytools-1, edited-2, tools4-2, tools3-1, tools5-0, tools-1, tools2-1, alltools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:30,949] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:31,192] INFO Accepted socket connection from /127.0.0.1:49786 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-20 21:22:31,150] INFO [Partition alltools-1 broker=3] alltools-1 starts at Leader Epoch 8 from offset 6. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-20 21:22:31,201] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=8, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:31,192] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:31,378] INFO Client attempting to establish new session at /127.0.0.1:49786 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:31,391] INFO Established session 0x100048300d50010 with negotiated timeout 6000 for client /127.0.0.1:49786 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-20 21:22:31,391] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100048300d50010, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-20 21:22:31,473] INFO [Partition edited-2 broker=3] edited-2 starts at Leader Epoch 5 from offset 8. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:31,477] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=5, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:31,467] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:31,593] INFO [Partition mytools-1 broker=3] mytools-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:31,647] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools-1, edited-2, mytools-1, tools2-1, tools4-2, tools1-0, tools3-1, alltools-1, tools5-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:31,589] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-20 21:22:31,630] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:31,713] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=5), mytools-1 -> (offset=0, leaderEpoch=5), edited-2 -> (offset=8, leaderEpoch=5), tools4-2 -> (offset=1, leaderEpoch=5), tools3-1 -> (offset=1, leaderEpoch=5), tools5-0 -> (offset=10, leaderEpoch=5), tools-1 -> (offset=0, leaderEpoch=5), tools2-1 -> (offset=1, leaderEpoch=5), alltools-1 -> (offset=6, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:31,728] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:31,871] INFO [Partition tools5-0 broker=3] tools5-0 starts at Leader Epoch 5 from offset 10. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:31,878] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=5, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:31,912] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, tools3-0, __consumer_offsets-25, tools4-1, tools5-2, __consumer_offsets-49, tools1-2, edited-1, __consumer_offsets-16, __consumer_offsets-28, mytools-0, __consumer_offsets-31, __consumer_offsets-37, my-example-topic-0, alltools-0, tools-0, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:31,937] INFO [Partition mytools-0 broker=2] mytools-0 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:31,975] INFO [Partition tools4-2 broker=3] tools4-2 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:31,999] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=5, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:32,029] INFO [Partition tools3-1 broker=3] tools3-1 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:32,031] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 21:22:32,031] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=5, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:32,034] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools1-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,035] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools2-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,037] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:32,038] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-20 21:22:32,039] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,040] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:32,040] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,042] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-20 21:22:32,045] INFO [Partition mytools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:32,051] INFO [Partition tools-1 broker=3] tools-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:32,053] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:32,054] INFO [Partition edited-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:32,063] INFO [Partition tools4-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:32,069] INFO [Partition tools5-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:32,080] INFO [Partition tools2-1 broker=3] tools2-1 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:32,082] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=5, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:32,085] INFO [Partition alltools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:32,098] INFO [Partition tools1-0 broker=3] tools1-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:32,103] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:32,091] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 5 from offset 40. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:32,117] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=5, startOffset=40) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=40)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:32,305] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,408] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(alltools-0, mytools-0, tools1-2, tools5-2, tools2-0, tools4-1, tools-0, edited-1, tools3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:32,465] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,465] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,677] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools3-0 -> (offset=0, leaderEpoch=2), tools4-1 -> (offset=0, leaderEpoch=2), tools5-2 -> (offset=8, leaderEpoch=2), tools1-2 -> (offset=0, leaderEpoch=2), edited-1 -> (offset=9, leaderEpoch=2), mytools-0 -> (offset=1, leaderEpoch=2), alltools-0 -> (offset=4, leaderEpoch=3), tools-0 -> (offset=1, leaderEpoch=2), tools2-0 -> (offset=0, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:32,706] INFO [Partition tools4-1 broker=2] tools4-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:32,781] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,834] INFO [Partition tools5-2 broker=2] tools5-2 starts at Leader Epoch 2 from offset 8. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:32,813] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:32,919] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:32,912] INFO [Partition tools3-0 broker=2] tools3-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:32,982] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,996] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools1-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,998] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:32,998] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools2-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,999] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:33,000] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 21:22:33,001] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:33,003] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:33,004] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition alltools-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:32,980] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:33,043] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:33,008] INFO [Partition tools3-0 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:33,069] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:33,162] INFO [Partition tools-0 broker=2] tools-0 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:33,233] INFO [Partition tools4-1 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:33,248] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:33,255] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:33,256] INFO [Partition tools5-2 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:33,259] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:33,261] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:33,262] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:33,263] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:33,264] INFO [Partition mytools-0 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:33,279] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:33,280] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:33,295] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:33,296] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:33,319] INFO [Partition tools1-2 broker=2] tools1-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:33,228] WARN [LeaderEpochCache __consumer_offsets-48] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:33,266] INFO [Partition tools1-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:33,360] INFO [Partition tools3-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:33,358] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:33,432] INFO [Partition tools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:33,452] INFO [Partition tools2-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-20 21:22:33,428] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=5, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:33,579] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:33,685] WARN [LeaderEpochCache __consumer_offsets-45] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:33,870] INFO [Partition tools2-0 broker=2] tools2-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:34,012] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,005] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:34,076] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,164] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:34,145] WARN [LeaderEpochCache __consumer_offsets-42] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,262] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,385] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,390] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=5, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,274] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 1 from offset 31. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:34,406] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,419] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,434] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,444] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=5, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,460] INFO [Partition edited-1 broker=2] edited-1 starts at Leader Epoch 2 from offset 9. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-20 21:22:34,329] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:34,498] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,501] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:34,509] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,638] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,640] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,655] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,658] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,579] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:34,670] INFO [Partition alltools-0 broker=2] alltools-0 starts at Leader Epoch 3 from offset 4. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:34,531] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:34,789] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,796] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,662] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:34,821] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,826] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,856] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,866] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,826] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition alltools-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:34,890] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-20 21:22:34,775] WARN [LeaderEpochCache __consumer_offsets-36] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:34,934] INFO [Partition tools1-2 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:35,035] INFO [Partition tools-0 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:35,044] INFO [Partition tools2-0 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:35,018] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:34,979] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=5, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:35,109] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:35,132] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:35,133] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:35,094] WARN [LeaderEpochCache __consumer_offsets-33] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:35,264] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,336] WARN [LeaderEpochCache __consumer_offsets-30] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:35,380] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,430] WARN [LeaderEpochCache __consumer_offsets-27] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:35,458] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,516] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,658] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,740] WARN [LeaderEpochCache __consumer_offsets-18] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:35,800] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,858] WARN [LeaderEpochCache __consumer_offsets-15] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:35,899] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,922] WARN [LeaderEpochCache __consumer_offsets-12] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:35,944] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:35,977] WARN [LeaderEpochCache __consumer_offsets-9] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:36,005] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:36,057] WARN [LeaderEpochCache __consumer_offsets-6] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:36,099] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-20 21:22:36,123] WARN [LeaderEpochCache __consumer_offsets-3] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:36,164] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-20 21:22:36,184] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-20 21:22:36,236] INFO [Partition edited-1 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:36,241] INFO [Partition alltools-0 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-01-20 21:22:36,319] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools1-0, mytools-1, edited-2, tools4-2, tools3-1, tools5-0, tools-1, tools2-1, alltools-1) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:36,330] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 9 from offset 6. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-20 21:22:36,332] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=9, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:36,351] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools-1, edited-2, mytools-1, tools2-1, tools4-2, tools1-0, tools3-1, alltools-1, tools5-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:36,549] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=6), mytools-1 -> (offset=0, leaderEpoch=6), edited-2 -> (offset=8, leaderEpoch=6), tools4-2 -> (offset=1, leaderEpoch=6), tools3-1 -> (offset=1, leaderEpoch=6), tools5-0 -> (offset=10, leaderEpoch=6), tools-1 -> (offset=0, leaderEpoch=6), tools2-1 -> (offset=1, leaderEpoch=6), alltools-1 -> (offset=6, leaderEpoch=9)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:36,551] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,528] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools3-0, tools4-1, tools5-2, tools1-2, edited-1, mytools-0, alltools-0, tools-0, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:36,573] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:36,695] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:36,746] WARN [LeaderEpochCache mytools-0] New epoch entry EpochEntry(epoch=3, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:36,726] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:36,832] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,896] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools1-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,900] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools2-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,901] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition mytools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,902] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools5-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,910] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,917] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,831] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 6 from offset 8. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:36,924] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:36,928] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-20 21:22:36,926] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=6, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:36,862] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 20 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:37,031] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:37,028] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:37,037] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,038] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:37,082] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:37,054] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:37,090] WARN [LeaderEpochCache tools3-0] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,090] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-20 21:22:37,119] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:37,120] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 6 from offset 10. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:37,131] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=6, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,127] WARN [LeaderEpochCache tools4-1] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,148] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 3 from offset 8. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:37,160] WARN [LeaderEpochCache tools5-2] New epoch entry EpochEntry(epoch=3, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,194] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:37,200] WARN [LeaderEpochCache tools-0] New epoch entry EpochEntry(epoch=3, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,202] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:37,207] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=6, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,216] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:37,227] WARN [LeaderEpochCache tools1-2] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,246] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:37,248] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=6, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,260] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:37,267] WARN [LeaderEpochCache tools2-0] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,268] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:37,271] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,293] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:37,302] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=6, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,287] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 3 from offset 9. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-20 21:22:37,313] WARN [LeaderEpochCache edited-1] New epoch entry EpochEntry(epoch=3, startOffset=9) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=9)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,327] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-20 21:22:37,329] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,351] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,360] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,360] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,374] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0, mytools-0, tools1-2, tools5-2, tools2-0, tools4-1, tools-0, edited-1, tools3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:37,390] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools3-0 -> (offset=0, leaderEpoch=3), tools4-1 -> (offset=0, leaderEpoch=3), tools5-2 -> (offset=8, leaderEpoch=3), tools1-2 -> (offset=0, leaderEpoch=3), edited-1 -> (offset=9, leaderEpoch=3), mytools-0 -> (offset=1, leaderEpoch=3), alltools-0 -> (offset=4, leaderEpoch=4), tools-0 -> (offset=1, leaderEpoch=3), tools2-0 -> (offset=0, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-01-20 21:22:37,392] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,447] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 4 from offset 4. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-20 21:22:37,449] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-20 21:22:37,455] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:37,457] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:37,455] WARN [LeaderEpochCache alltools-0] New epoch entry EpochEntry(epoch=4, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-20 21:22:37,459] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:37,461] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:37,462] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 21:22:37,463] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:37,464] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:37,465] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition alltools-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,525] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,569] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,569] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-20 21:22:37,957] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-20 21:22:38,513] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-20 21:22:37,965] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:38,782] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:38,798] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-20 21:22:38,798] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-20 21:22:38,814] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:38,814] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-20 21:22:38,829] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
