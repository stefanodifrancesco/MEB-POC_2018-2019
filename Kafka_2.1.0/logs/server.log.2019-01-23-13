[2019-01-22 11:52:37,565] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-22 11:52:37,577] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-22 11:52:37,577] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-22 11:52:37,577] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-22 11:52:37,577] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-22 11:52:37,629] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-22 11:52:37,633] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-22 11:52:37,665] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,665] INFO Server environment:host.name=ITdif.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,669] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,669] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,669] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,669] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,673] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,677] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,677] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,677] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,681] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,697] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,701] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,701] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,705] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,741] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,741] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,745] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:37,813] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-22 11:52:37,821] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 11:52:45,513] INFO Expiring session 0x1000ad0996e0008, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:52:45,517] INFO Processed session termination for sessionid: 0x1000ad0996e0008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:52:45,517] INFO Creating new log file: log.472 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-22 11:53:05,191] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-22 11:53:06,863] INFO starting (kafka.server.KafkaServer)
[2019-01-22 11:53:06,867] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-22 11:53:06,927] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:53:06,947] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,947] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,947] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,951] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,951] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,951] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,955] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,967] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,967] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,967] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,971] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,975] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,979] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,983] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,983] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:06,987] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:07,043] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:53:07,043] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:53:07,051] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:58294 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 11:53:07,051] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:53:07,067] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:58294 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:53:07,079] INFO Established session 0x1000f29e8100000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:58294 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:53:07,083] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000f29e8100000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:53:07,095] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:53:07,283] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x1 zxid:0x474 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,323] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x2 zxid:0x475 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,331] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x3 zxid:0x476 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,335] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x4 zxid:0x477 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,339] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x5 zxid:0x478 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,347] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x6 zxid:0x479 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,351] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x7 zxid:0x47a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,359] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x8 zxid:0x47b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,363] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0x9 zxid:0x47c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,371] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0xa zxid:0x47d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,375] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0xb zxid:0x47e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,383] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0xc zxid:0x47f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,391] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:create cxid:0xd zxid:0x480 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:07,953] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-22 11:53:08,172] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-22 11:53:08,204] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-22 11:53:08,304] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:53:08,304] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:53:08,312] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:53:08,488] INFO Loading logs. (kafka.log.LogManager)
[2019-01-22 11:53:08,788] WARN [Log partition=alltools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:08,796] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:08,960] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:08,988] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:08,996] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,012] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,076] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,084] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,136] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 436 ms (kafka.log.Log)
[2019-01-22 11:53:09,200] WARN [Log partition=alltools-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:09,200] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,236] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,256] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,260] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,288] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,308] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,316] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,332] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 144 ms (kafka.log.Log)
[2019-01-22 11:53:09,380] WARN [Log partition=edited-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:09,384] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,412] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,416] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,420] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,436] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,460] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,464] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,468] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 100 ms (kafka.log.Log)
[2019-01-22 11:53:09,496] WARN [Log partition=edited-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:09,496] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,520] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,524] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,524] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,540] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,560] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,568] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,568] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 80 ms (kafka.log.Log)
[2019-01-22 11:53:09,600] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,600] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,612] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,636] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,640] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,644] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 56 ms (kafka.log.Log)
[2019-01-22 11:53:09,668] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,668] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,684] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,696] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,700] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-1\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,704] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 48 ms (kafka.log.Log)
[2019-01-22 11:53:09,732] WARN [Log partition=mytools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:09,732] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,756] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,760] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,760] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,776] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,796] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,800] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs1\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,804] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 84 ms (kafka.log.Log)
[2019-01-22 11:53:09,828] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,828] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,856] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,860] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-22 11:53:09,880] WARN [Log partition=tools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:09,884] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,896] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,900] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,900] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,916] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,936] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,944] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:09,944] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 72 ms (kafka.log.Log)
[2019-01-22 11:53:09,968] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:09,968] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,988] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:09,996] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:10,012] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,016] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,036] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,040] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:10,060] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,060] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,080] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,088] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:10,104] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,108] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,132] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,140] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-22 11:53:10,160] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,160] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,180] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,188] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:10,204] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,204] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,224] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,228] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:10,260] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,260] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,288] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,296] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-01-22 11:53:10,324] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,328] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,352] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,360] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-01-22 11:53:10,380] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,384] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,408] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,420] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-01-22 11:53:10,440] WARN [Log partition=tools5-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:10,440] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,460] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,464] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,476] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,496] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,520] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,528] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,528] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 100 ms (kafka.log.Log)
[2019-01-22 11:53:10,560] WARN [Log partition=tools5-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:10,560] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,592] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,596] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,600] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,620] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,640] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,648] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,648] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 104 ms (kafka.log.Log)
[2019-01-22 11:53:10,680] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,680] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,700] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,716] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,720] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,728] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 60 ms (kafka.log.Log)
[2019-01-22 11:53:10,752] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,756] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,768] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,792] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,800] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,816] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 72 ms (kafka.log.Log)
[2019-01-22 11:53:10,836] WARN [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994284686}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:10,836] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,852] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,860] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,860] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,880] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,904] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,908] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:10,912] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 84 ms (kafka.log.Log)
[2019-01-22 11:53:10,936] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,936] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,956] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:10,964] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:10,984] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:10,984] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,004] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,012] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:11,032] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,032] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,060] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,064] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:11,084] WARN [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547985284682}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:11,084] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,096] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,100] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,100] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,116] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,136] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,140] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-21\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,140] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-01-22 11:53:11,156] WARN [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991284687}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:11,156] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,168] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,172] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,172] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,184] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,200] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,208] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,208] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 60 ms (kafka.log.Log)
[2019-01-22 11:53:11,224] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,224] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,240] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,252] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:11,264] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,268] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,284] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,292] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:11,308] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,308] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,328] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,336] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:11,348] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,352] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,376] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,380] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:11,396] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,396] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,416] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,424] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:11,440] WARN [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548010498324}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:11,440] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,452] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,456] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,456] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,468] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,488] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,492] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-39\00000000000000000031.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:11,496] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 31 in 68 ms (kafka.log.Log)
[2019-01-22 11:53:11,520] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,520] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,536] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,544] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:11,560] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,564] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,580] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,588] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:11,604] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,604] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,628] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,636] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:11,656] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,656] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,676] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,680] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:11,696] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:11,696] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,716] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:11,724] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:11,736] INFO Logs loading complete in 3248 ms. (kafka.log.LogManager)
[2019-01-22 11:53:11,776] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-22 11:53:11,780] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-22 11:53:12,624] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-22 11:53:12,708] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-22 11:53:12,776] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:12,780] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:12,780] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:12,812] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-22 11:53:12,932] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-22 11:53:12,940] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-22 11:53:12,944] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-22 11:53:13,084] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:13,096] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:13,096] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:13,176] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:53:13,180] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:53:13,196] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:13,228] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-22 11:53:13,328] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-22 11:53:13,336] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-22 11:53:13,336] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-22 11:53:13,464] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-22 11:53:13,548] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-22 11:53:13,564] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-22 11:53:13,564] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-22 11:53:13,572] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-22 11:53:13,812] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, tools1-1, __consumer_offsets-30, tools2-2, tools-2, __consumer_offsets-21, edited6-0, __consumer_offsets-27, __consumer_offsets-9, tools3-0, tools4-1, alltools-2, tools5-2, __consumer_offsets-33, tools1-2, edited-1, mytools-0, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, tools5-1, __consumer_offsets-15, __consumer_offsets-24, tools6-2, alltools-0, __consumer_offsets-48, tools-0, __consumer_offsets-6, edited-0, tools3-2, edited6-1, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, mytools-2, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:53:13,850] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:13,886] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:13,942] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:13,942] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:13,942] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:13,966] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:13,966] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:13,970] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:13,986] INFO Replica loaded for partition edited6-1 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-22 11:53:13,990] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:13,990] INFO [Partition edited6-1 broker=1] edited6-1 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,002] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,002] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,010] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:multi cxid:0x108 zxid:0x485 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:14,022] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:53:14,022] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,026] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,038] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100000 type:multi cxid:0x10c zxid:0x486 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:14,042] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,046] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,058] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,062] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,062] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,078] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-22 11:53:14,078] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,082] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 3 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,098] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,098] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,102] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,114] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,118] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,130] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:53:14,130] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,130] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,146] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 31 (kafka.cluster.Replica)
[2019-01-22 11:53:14,146] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 1 from offset 31. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,158] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,158] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,174] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,174] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,186] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,186] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,190] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,202] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,202] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,214] INFO Replica loaded for partition edited-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-22 11:53:14,214] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,214] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 9 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,230] INFO Replica loaded for partition alltools-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-22 11:53:14,234] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,234] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 10 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,250] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,250] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,262] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,262] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,270] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,282] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:14,286] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,298] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,298] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,298] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,310] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:14,314] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,326] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,326] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,338] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,338] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,342] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,354] INFO Replica loaded for partition tools5-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-22 11:53:14,358] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,362] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 9 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,374] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,378] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,378] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,390] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,390] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,406] INFO Replica loaded for partition tools6-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-22 11:53:14,406] INFO Replica loaded for partition tools6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,410] INFO [Partition tools6-2 broker=1] tools6-2 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,426] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,430] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,442] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-22 11:53:14,442] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,442] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 3 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,454] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,454] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,470] INFO Replica loaded for partition edited6-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-22 11:53:14,470] INFO Replica loaded for partition edited6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,470] INFO [Partition edited6-0 broker=1] edited6-0 starts at Leader Epoch 5 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,482] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,486] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,486] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,498] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-22 11:53:14,498] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,502] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 4 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,522] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,522] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,534] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,534] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,558] INFO Replica loaded for partition tools6-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-22 11:53:14,562] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:53:14,590] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,594] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,598] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,602] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,610] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,618] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,618] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,618] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,622] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,622] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,622] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,626] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,626] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,634] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,638] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,638] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,638] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,702] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools6-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:53:14,706] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:14,710] INFO [Partition tools6-0 broker=1] tools6-0 starts at Leader Epoch 3 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:14,790] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 196 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,794] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,798] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,798] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,802] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,814] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,826] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,826] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,830] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,862] INFO [GroupCoordinator 1]: Loading group metadata for group2 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:53:14,866] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 32 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,866] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,870] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,874] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,874] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,874] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:14,882] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:27,811] INFO [Partition edited-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,823] INFO [Partition tools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,831] INFO [Partition alltools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,835] INFO [Partition tools4-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,843] INFO [Partition mytools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,847] INFO [Partition tools1-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,855] INFO [Partition tools2-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,859] INFO [Partition edited6-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,863] INFO [Partition tools3-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:27,871] INFO [Partition tools5-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-22 11:53:42,918] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-22 11:53:44,695] INFO starting (kafka.server.KafkaServer)
[2019-01-22 11:53:44,699] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-22 11:53:44,755] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:53:44,771] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,771] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,771] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,771] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,771] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,775] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,779] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,787] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,791] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,795] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,795] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,799] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,803] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,807] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,807] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,815] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:53:44,867] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:53:44,871] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:53:44,875] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:58311 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 11:53:44,875] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:53:44,883] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:58311 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:53:44,887] INFO Established session 0x1000f29e8100001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:58311 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:53:44,891] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000f29e8100001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:53:44,903] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:53:45,027] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x1 zxid:0x494 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,063] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x2 zxid:0x495 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,071] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x3 zxid:0x496 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,079] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x4 zxid:0x497 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,083] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x5 zxid:0x498 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,091] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x6 zxid:0x499 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,095] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x7 zxid:0x49a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,103] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x8 zxid:0x49b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,107] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0x9 zxid:0x49c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,111] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0xa zxid:0x49d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,123] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0xb zxid:0x49e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,127] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0xc zxid:0x49f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,131] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100001 type:create cxid:0xd zxid:0x4a0 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:53:45,611] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-22 11:53:45,811] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-22 11:53:45,843] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-22 11:53:45,923] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:53:45,927] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:53:45,935] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:53:46,063] INFO Loading logs. (kafka.log.LogManager)
[2019-01-22 11:53:46,235] WARN [Log partition=alltools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:46,243] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,367] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,383] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:46,387] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,403] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,451] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,459] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,491] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 324 ms (kafka.log.Log)
[2019-01-22 11:53:46,539] WARN [Log partition=alltools-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:46,539] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,559] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,563] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:46,563] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,579] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,611] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,615] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,619] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 88 ms (kafka.log.Log)
[2019-01-22 11:53:46,643] WARN [Log partition=edited-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:46,643] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,659] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,663] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:46,663] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,687] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,699] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,707] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,707] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 72 ms (kafka.log.Log)
[2019-01-22 11:53:46,727] WARN [Log partition=edited-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:46,727] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,752] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,760] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:46,760] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,776] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,792] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,800] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,800] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 81 ms (kafka.log.Log)
[2019-01-22 11:53:46,832] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:46,832] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,848] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,860] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,864] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-1\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,864] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 48 ms (kafka.log.Log)
[2019-01-22 11:53:46,888] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:46,888] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,900] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,916] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,920] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:46,920] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:46,944] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:46,944] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,964] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:46,968] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-22 11:53:46,996] WARN [Log partition=mytools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:46,996] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,008] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,012] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,012] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,024] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,036] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,044] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs2\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,044] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 56 ms (kafka.log.Log)
[2019-01-22 11:53:47,064] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,064] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,081] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,089] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-01-22 11:53:47,105] WARN [Log partition=tools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:47,109] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,121] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,125] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,125] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,137] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,150] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,153] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,157] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 60 ms (kafka.log.Log)
[2019-01-22 11:53:47,177] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,181] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,201] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,209] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:47,225] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,229] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,245] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,253] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:47,269] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,269] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,281] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,289] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-01-22 11:53:47,305] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,309] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,317] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,325] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-01-22 11:53:47,345] WARN [Log partition=tools2-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:47,345] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,361] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,365] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,365] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,381] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,397] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,405] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,409] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 72 ms (kafka.log.Log)
[2019-01-22 11:53:47,429] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,429] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,441] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,449] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-01-22 11:53:47,465] WARN [Log partition=tools3-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:47,469] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,493] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,497] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,497] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,513] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,533] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,541] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,541] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 84 ms (kafka.log.Log)
[2019-01-22 11:53:47,557] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,561] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,573] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,581] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:47,601] WARN [Log partition=tools4-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:47,601] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,613] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,617] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,621] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,637] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,661] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,665] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,665] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 72 ms (kafka.log.Log)
[2019-01-22 11:53:47,689] WARN [Log partition=tools5-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:47,689] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,713] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,717] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,721] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,737] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,753] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,757] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,761] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 80 ms (kafka.log.Log)
[2019-01-22 11:53:47,777] WARN [Log partition=tools5-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:47,777] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,797] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,797] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,801] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,825] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,837] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,845] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,845] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 76 ms (kafka.log.Log)
[2019-01-22 11:53:47,865] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,865] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,877] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,889] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,893] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,897] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 44 ms (kafka.log.Log)
[2019-01-22 11:53:47,913] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,913] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,925] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,941] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,945] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:47,949] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 44 ms (kafka.log.Log)
[2019-01-22 11:53:47,969] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:47,969] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,989] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:47,993] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:48,013] WARN [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979865822}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:48,013] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,033] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 40 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,037] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,041] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,057] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 40 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,081] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 40 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,085] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-10\00000000000000000040.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,089] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 40 in 84 ms (kafka.log.Log)
[2019-01-22 11:53:48,109] WARN [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991901592}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:48,109] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,125] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,125] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,129] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,141] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,157] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,165] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,165] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-01-22 11:53:48,181] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,185] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,201] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,209] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:48,225] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,225] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,237] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,249] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,257] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-19\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,257] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 40 ms (kafka.log.Log)
[2019-01-22 11:53:48,273] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,273] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,297] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,301] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:48,317] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,321] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,341] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,345] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:48,361] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,365] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,385] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,389] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:48,409] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,409] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,429] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,433] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:48,449] WARN [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993101595}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:48,449] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,461] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,461] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,465] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,477] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,493] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,497] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,497] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 56 ms (kafka.log.Log)
[2019-01-22 11:53:48,513] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,513] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,537] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,541] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:48,557] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,557] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,577] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,581] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:48,593] WARN [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994301596}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:48,597] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,609] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,613] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,613] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,629] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,645] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,649] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-40\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,653] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-01-22 11:53:48,665] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,665] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,681] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,689] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:53:48,705] WARN [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993701594}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:53:48,705] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,717] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,717] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,721] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,733] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,753] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,761] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:53:48,761] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-01-22 11:53:48,777] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,781] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,797] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,801] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-01-22 11:53:48,821] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:53:48,825] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,841] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:53:48,849] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:53:48,857] INFO Logs loading complete in 2790 ms. (kafka.log.LogManager)
[2019-01-22 11:53:48,905] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-22 11:53:48,909] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-22 11:53:49,735] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-22 11:53:49,815] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-22 11:53:49,879] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:49,883] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:49,883] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:49,919] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-22 11:53:50,079] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-22 11:53:50,083] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-22 11:53:50,087] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-22 11:53:50,299] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:50,303] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:50,303] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:53:50,359] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:53:50,363] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:53:50,375] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:50,411] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-22 11:53:50,479] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-22 11:53:50,483] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-22 11:53:50,483] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-22 11:53:50,599] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-22 11:53:50,680] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-22 11:53:50,691] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-22 11:53:50,691] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-22 11:53:50,695] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-22 11:53:50,915] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, tools1-0, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, mytools-1, my-example-topic-0, edited-2, tools4-2, tools3-1, __consumer_offsets-19, tools6-1, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, tools2-1, alltools-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:53:50,952] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 40 (kafka.cluster.Replica)
[2019-01-22 11:53:50,959] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 8 from offset 40. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,003] INFO Replica loaded for partition alltools-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-22 11:53:51,007] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,007] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 14 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,027] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,027] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,043] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,043] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,059] INFO Replica loaded for partition edited-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-22 11:53:51,059] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,064] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 11 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,079] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,083] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,083] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,103] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,103] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,119] INFO Replica loaded for partition tools6-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:51,119] INFO Replica loaded for partition tools6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,123] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,139] INFO Replica loaded for partition tools5-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-22 11:53:51,139] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,143] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 11 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,159] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,159] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,171] INFO Replica loaded for partition edited6-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:51,171] INFO Replica loaded for partition edited6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,176] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,196] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:51,196] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,206] INFO Replica loaded for partition tools3-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:53:51,210] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,212] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 11 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,226] INFO Replica loaded for partition tools4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:53:51,226] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,226] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 11 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,246] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,246] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,260] INFO Replica loaded for partition my-example-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,260] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,277] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,277] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,277] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,293] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:51,293] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,309] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,309] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,321] INFO Replica loaded for partition tools2-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:53:51,321] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,325] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 11 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,341] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,341] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,341] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,357] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-22 11:53:51,357] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 8 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,369] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,373] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,393] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-22 11:53:51,397] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 8 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,401] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,405] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,417] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,421] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,433] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,437] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,449] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,449] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,465] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:53:51,465] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:53:51,485] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,493] INFO Replica loaded for partition edited6-1 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-22 11:53:51,497] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,501] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:53:51,501] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,509] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,509] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,517] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-22 11:53:51,517] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,525] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,525] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,529] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:53:51,537] INFO Replica loaded for partition tools6-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-22 11:53:51,537] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,541] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,549] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,549] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,553] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,557] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,561] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-22 11:53:51,561] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:53:51,565] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-22 11:53:51,569] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0, edited6-1, mytools-0, tools1-2, tools5-2, tools2-0, tools4-1, tools-0, edited-1, tools6-0, tools3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:53:51,645] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:53:51,685] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools3-0 -> (offset=0, leaderEpoch=3), tools4-1 -> (offset=0, leaderEpoch=3), tools5-2 -> (offset=8, leaderEpoch=3), tools1-2 -> (offset=0, leaderEpoch=3), edited-1 -> (offset=9, leaderEpoch=3), mytools-0 -> (offset=1, leaderEpoch=3), alltools-0 -> (offset=4, leaderEpoch=4), tools-0 -> (offset=1, leaderEpoch=3), edited6-1 -> (offset=4, leaderEpoch=0), tools6-0 -> (offset=4, leaderEpoch=3), tools2-0 -> (offset=0, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:53:51,705] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,713] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,725] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,733] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,733] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,737] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,741] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,745] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,749] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,753] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,757] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,757] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,761] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,773] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,773] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,785] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-22 11:53:51,801] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:53:51,801] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:53:51,805] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 11:53:51,805] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-22 11:53:51,805] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 11:53:51,809] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 96 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,809] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:53:51,817] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,829] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:53:51,829] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,829] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-22 11:53:51,833] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,837] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:53:51,841] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:53:51,841] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:53:51,845] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:53:51,845] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-22 11:53:51,853] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-22 11:53:51,865] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, tools1-0, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, mytools-1, my-example-topic-0, edited-2, tools4-2, tools3-1, __consumer_offsets-19, tools6-1, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, tools2-1, alltools-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:53:51,869] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 9 from offset 40. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:51,869] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=9, startOffset=40) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=40)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,881] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 15 from offset 6. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-22 11:53:51,881] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=15, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,889] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:51,889] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,897] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:51,897] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,909] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 12 from offset 8. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:51,909] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=12, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,921] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:51,921] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,933] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:51,933] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 96 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,937] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,937] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,945] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-22 11:53:51,949] WARN [LeaderEpochCache tools6-1] New epoch entry EpochEntry(epoch=5, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=3)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,961] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 12 from offset 10. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:51,965] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=12, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,973] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,977] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,977] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:51,977] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,981] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:51,985] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,989] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:51,993] INFO [Partition tools3-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:51,993] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-22 11:53:52,001] WARN [LeaderEpochCache edited6-2] New epoch entry EpochEntry(epoch=5, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,009] INFO [Partition tools4-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,013] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 9 from offset 3. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,013] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=9, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,017] INFO [Partition tools5-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,029] INFO [Partition tools1-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,025] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 12 from offset 1. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:52,033] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=12, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,037] INFO [Partition edited-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,041] INFO [GroupCoordinator 2]: Loading group metadata for KafkaExampleConsumer with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:53:52,045] INFO [Partition mytools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,045] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 12 from offset 1. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:52,049] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 60 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:52,053] INFO [Partition alltools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,049] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=12, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,065] INFO [Partition tools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,069] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,073] INFO [Partition edited6-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,069] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,085] INFO [Partition tools6-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,081] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 28 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:52,097] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:52,097] INFO [Partition tools2-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-22 11:53:52,097] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-22 11:53:52,109] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=7, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,121] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-46729 with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:53:52,125] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 28 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:53:52,125] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:52,129] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,139] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 9 from offset 3. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,143] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=9, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,155] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,155] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,166] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 12 from offset 1. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:52,166] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=12, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,178] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-22 11:53:52,182] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,190] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 9 from offset 6. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,192] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=9, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,200] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,200] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,206] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 9 from offset 6. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,216] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,216] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,226] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,226] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,241] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,241] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,249] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,253] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:53:52,265] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 9 from offset 3. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-22 11:53:52,265] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=9, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 11:54:07,177] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-22 11:54:08,893] INFO starting (kafka.server.KafkaServer)
[2019-01-22 11:54:08,897] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-22 11:54:08,953] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:54:08,969] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,969] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,969] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,973] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,973] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,973] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,977] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,985] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,985] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,989] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,989] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,993] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:08,997] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:09,005] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:09,005] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:09,009] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 11:54:09,065] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:54:09,065] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:54:09,069] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:58331 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 11:54:09,073] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:54:09,077] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:58331 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:54:09,089] INFO Established session 0x1000f29e8100002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:58331 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:54:09,093] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000f29e8100002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 11:54:09,105] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 11:54:09,229] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x1 zxid:0x4ce txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,265] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x2 zxid:0x4cf txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,269] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x3 zxid:0x4d0 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,277] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x4 zxid:0x4d1 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,281] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x5 zxid:0x4d2 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,285] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x6 zxid:0x4d3 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,289] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x7 zxid:0x4d4 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,297] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x8 zxid:0x4d5 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,301] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0x9 zxid:0x4d6 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,305] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0xa zxid:0x4d7 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,309] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0xb zxid:0x4d8 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,318] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0xc zxid:0x4d9 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,321] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100002 type:create cxid:0xd zxid:0x4da txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:09,828] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-22 11:54:10,028] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-22 11:54:10,064] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-22 11:54:10,152] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:54:10,152] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:54:10,160] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-22 11:54:10,298] INFO Loading logs. (kafka.log.LogManager)
[2019-01-22 11:54:10,466] WARN [Log partition=alltools-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:10,470] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,586] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,606] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:10,606] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,622] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,682] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,690] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,722] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 324 ms (kafka.log.Log)
[2019-01-22 11:54:10,762] WARN [Log partition=alltools-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:10,766] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,778] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,782] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:10,782] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,798] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,818] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,826] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,826] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 72 ms (kafka.log.Log)
[2019-01-22 11:54:10,846] WARN [Log partition=edited-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:10,846] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,862] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,866] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:10,866] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,878] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,898] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,902] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,906] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 68 ms (kafka.log.Log)
[2019-01-22 11:54:10,926] WARN [Log partition=edited-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:10,926] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,942] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,946] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:10,946] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,958] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,978] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:10,986] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:10,986] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 68 ms (kafka.log.Log)
[2019-01-22 11:54:11,014] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,014] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,026] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,038] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,042] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,046] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 44 ms (kafka.log.Log)
[2019-01-22 11:54:11,062] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,066] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,078] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,090] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,094] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,098] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 44 ms (kafka.log.Log)
[2019-01-22 11:54:11,118] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,118] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,142] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,146] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:54:11,166] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,170] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,190] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,194] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:54:11,214] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,218] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,238] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,246] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:54:11,266] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,266] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,286] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,294] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:54:11,310] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,310] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,330] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,334] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:11,354] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,354] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,374] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,378] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:11,398] WARN [Log partition=tools2-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:11,398] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,410] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,414] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,414] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,426] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,442] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,450] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,450] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 60 ms (kafka.log.Log)
[2019-01-22 11:54:11,470] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,470] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,490] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,494] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:11,514] WARN [Log partition=tools3-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:11,514] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,534] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,538] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,538] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,554] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,574] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,578] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,582] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 76 ms (kafka.log.Log)
[2019-01-22 11:54:11,602] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,602] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,630] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,638] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-22 11:54:11,666] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,670] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,718] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,726] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-01-22 11:54:11,758] WARN [Log partition=tools4-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:11,762] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,786] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,790] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,794] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,810] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,830] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,838] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,842] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 100 ms (kafka.log.Log)
[2019-01-22 11:54:11,862] WARN [Log partition=tools5-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:11,866] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,890] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,894] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,898] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,914] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,930] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,938] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,938] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 84 ms (kafka.log.Log)
[2019-01-22 11:54:11,958] WARN [Log partition=tools5-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:11,962] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,982] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:11,982] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:11,986] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:11,998] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,018] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,022] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,026] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 76 ms (kafka.log.Log)
[2019-01-22 11:54:12,046] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,046] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,062] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,074] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,078] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,082] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 48 ms (kafka.log.Log)
[2019-01-22 11:54:12,110] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,110] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,122] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,134] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,142] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,146] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 48 ms (kafka.log.Log)
[2019-01-22 11:54:12,170] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,170] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,202] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,210] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-01-22 11:54:12,230] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,230] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,254] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,262] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-22 11:54:12,282] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,282] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,310] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,314] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-22 11:54:12,334] WARN [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547989834290}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:12,338] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,370] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,374] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,374] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,402] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,418] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,422] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,426] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 100 ms (kafka.log.Log)
[2019-01-22 11:54:12,446] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,450] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,474] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,482] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-22 11:54:12,498] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,498] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,514] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,522] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:12,538] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,538] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,554] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,562] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:12,582] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,582] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,606] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,610] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:54:12,630] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,630] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,650] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,658] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:54:12,682] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,682] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,698] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,706] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:54:12,722] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,726] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,742] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,750] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-22 11:54:12,766] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,766] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,782] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,790] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:12,806] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,806] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,826] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,830] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:12,846] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992512270}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-22 11:54:12,846] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,858] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,862] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,866] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,882] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,898] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,906] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-22 11:54:12,906] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 68 ms (kafka.log.Log)
[2019-01-22 11:54:12,922] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,922] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,942] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,946] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-22 11:54:12,958] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-22 11:54:12,962] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,982] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:12,990] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-22 11:54:12,998] INFO Logs loading complete in 2700 ms. (kafka.log.LogManager)
[2019-01-22 11:54:13,030] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-22 11:54:13,034] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-22 11:54:14,234] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-22 11:54:14,314] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-22 11:54:14,378] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:54:14,382] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:54:14,386] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:54:14,418] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-22 11:54:14,578] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-22 11:54:14,586] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-22 11:54:14,590] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-22 11:54:14,770] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:54:14,778] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:54:14,782] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-22 11:54:14,842] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:54:14,842] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:54:14,854] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:14,886] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-22 11:54:14,942] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-22 11:54:14,950] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-22 11:54:14,950] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-22 11:54:15,074] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-22 11:54:15,154] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-22 11:54:15,166] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-22 11:54:15,166] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-22 11:54:15,174] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-22 11:54:15,418] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,418] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,434] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,434] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,446] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,454] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,458] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,466] INFO Replica loaded for partition alltools-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-22 11:54:15,474] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,474] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,482] INFO Replica loaded for partition edited-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-22 11:54:15,482] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,494] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,502] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,510] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,518] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,526] INFO Replica loaded for partition tools6-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:54:15,526] INFO Replica loaded for partition tools6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,530] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,534] INFO Replica loaded for partition tools5-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-22 11:54:15,542] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,542] INFO Replica loaded for partition edited6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,550] INFO Replica loaded for partition edited6-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:54:15,554] INFO Replica loaded for partition edited-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-22 11:54:15,558] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,562] INFO Replica loaded for partition alltools-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-22 11:54:15,562] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,566] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,574] INFO Replica loaded for partition tools3-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:54:15,574] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,582] INFO Replica loaded for partition tools4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:54:15,586] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,594] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,594] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,602] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,610] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,610] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,618] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 111 (kafka.cluster.Replica)
[2019-01-22 11:54:15,622] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,626] INFO Replica loaded for partition tools2-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-22 11:54:15,634] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,634] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,638] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,646] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,650] INFO Replica loaded for partition tools5-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-22 11:54:15,650] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,662] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,662] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,662] INFO Replica loaded for partition tools6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,670] INFO Replica loaded for partition tools6-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-22 11:54:15,678] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-22 11:54:15,682] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,690] INFO Replica loaded for partition edited6-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-22 11:54:15,690] INFO Replica loaded for partition edited6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,694] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,694] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,702] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,710] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,714] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,718] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:15,726] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools-1, edited-2, tools2-2, tools3-2, tools5-1, tools4-2, tools1-0, tools6-1, edited6-0, alltools-1, tools-2, tools6-2, mytools-1, edited-0, tools1-1, alltools-2, tools2-1, tools4-0, tools3-1, tools5-0, mytools-2, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:15,814] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,826] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=9), tools1-1 -> (offset=0, leaderEpoch=9), tools2-2 -> (offset=0, leaderEpoch=9), tools-2 -> (offset=0, leaderEpoch=9), edited6-0 -> (offset=2, leaderEpoch=5), alltools-2 -> (offset=5, leaderEpoch=10), tools5-1 -> (offset=5, leaderEpoch=9), tools6-2 -> (offset=2, leaderEpoch=1), edited-0 -> (offset=8, leaderEpoch=9), tools3-2 -> (offset=0, leaderEpoch=9), mytools-2 -> (offset=0, leaderEpoch=9)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:15,834] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=12), mytools-1 -> (offset=0, leaderEpoch=12), edited-2 -> (offset=8, leaderEpoch=12), tools4-2 -> (offset=1, leaderEpoch=12), tools3-1 -> (offset=1, leaderEpoch=12), tools6-1 -> (offset=3, leaderEpoch=5), tools5-0 -> (offset=10, leaderEpoch=12), edited6-2 -> (offset=3, leaderEpoch=5), tools-1 -> (offset=0, leaderEpoch=12), tools2-1 -> (offset=1, leaderEpoch=12), alltools-1 -> (offset=6, leaderEpoch=15)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:15,834] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,878] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,894] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-22 11:54:15,894] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,898] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,898] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 11:54:15,902] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,906] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,902] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,910] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,914] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,914] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-22 11:54:15,914] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,918] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,918] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,922] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,930] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-22 11:54:15,930] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-22 11:54:15,930] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-22 11:54:15,934] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 11:54:15,934] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-22 11:54:15,942] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 11:54:15,942] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,942] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-22 11:54:15,946] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,946] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,950] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-22 11:54:15,954] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:15,958] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-22 11:54:15,958] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-22 11:54:15,958] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:15,962] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:16,006] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:16,014] INFO [Partition tools4-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,022] INFO [Partition tools1-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,026] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,030] INFO [Partition tools2-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,038] INFO [Partition tools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,046] INFO [Partition edited6-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,050] INFO [Partition alltools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,054] INFO [Partition tools5-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,062] INFO [Partition tools6-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,066] INFO [Partition edited-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,070] INFO [Partition tools3-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,078] INFO [Partition mytools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,086] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,098] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,110] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,118] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,122] INFO [Partition tools1-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,126] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,138] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,146] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,154] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,162] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 9 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,170] INFO [Partition mytools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,174] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 9 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,174] INFO [Partition edited-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,182] INFO [Partition tools4-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,182] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,190] INFO [Partition tools3-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,194] INFO [Partition tools6-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,194] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,202] INFO [Partition tools5-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,206] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,210] INFO [Partition edited6-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,214] INFO [Partition tools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,214] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,222] INFO [Partition tools2-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,226] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:16,230] INFO [Partition alltools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-22 11:54:16,270] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,278] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,282] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,286] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,294] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,298] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,310] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,322] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,326] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,326] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,338] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,346] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,346] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,354] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,354] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,358] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,490] INFO [GroupCoordinator 3]: Loading group metadata for alltoolsStream with generation 41 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:54:16,506] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 224 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,510] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,510] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,510] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,514] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,514] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,518] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,526] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,526] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,530] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,534] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,538] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,542] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,542] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,546] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:16,558] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-47 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 11:54:26,509] INFO [GroupCoordinator 3]: Member alltoolsStream-002460b4-94ad-4f20-9b26-38b8af9b8ab6-StreamThread-1-consumer-1319f548-3d95-4ce3-8b6e-7d0ffc3e5df2 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:54:26,517] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 41 (__consumer_offsets-2) (reason: removing member alltoolsStream-002460b4-94ad-4f20-9b26-38b8af9b8ab6-StreamThread-1-consumer-1319f548-3d95-4ce3-8b6e-7d0ffc3e5df2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:54:26,525] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 42 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:54:34,960] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:58356 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 11:54:34,968] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:58356 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:54:34,974] INFO Established session 0x1000f29e8100003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:58356 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 11:54:35,694] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100003 type:setData cxid:0x6 zxid:0x508 txntype:-1 reqpath:n/a Error Path:/config/topics/tools7 Error:KeeperErrorCode = NoNode for /config/topics/tools7 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:35,802] INFO Processed session termination for sessionid: 0x1000f29e8100003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 11:54:35,810] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:58356 which had sessionid 0x1000f29e8100003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 11:54:35,846] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools7-1) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:35,846] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools7-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:35,850] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools7-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:35,870] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:35,874] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:35,878] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-01-22 11:54:35,878] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:35,882] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-01-22 11:54:35,882] INFO Created log for partition tools7-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-22 11:54:35,886] INFO Created log for partition tools7-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-22 11:54:35,890] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-01-22 11:54:35,890] INFO [Partition tools7-1 broker=2] No checkpointed highwatermark is found for partition tools7-1 (kafka.cluster.Partition)
[2019-01-22 11:54:35,898] INFO Created log for partition tools7-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-22 11:54:35,894] INFO [Partition tools7-0 broker=1] No checkpointed highwatermark is found for partition tools7-0 (kafka.cluster.Partition)
[2019-01-22 11:54:35,902] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,906] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,906] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,906] INFO [Partition tools7-2 broker=3] No checkpointed highwatermark is found for partition tools7-2 (kafka.cluster.Partition)
[2019-01-22 11:54:35,914] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:35,918] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,914] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,926] INFO [Partition tools7-0 broker=1] tools7-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:35,926] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,934] INFO [Partition tools7-2 broker=3] tools7-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-22 11:54:35,942] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,950] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,958] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,962] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:35,974] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-01-22 11:54:35,974] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:35,978] INFO Created log for partition tools7-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-22 11:54:35,982] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-22 11:54:35,982] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-01-22 11:54:35,990] INFO [Partition tools7-0 broker=2] No checkpointed highwatermark is found for partition tools7-0 (kafka.cluster.Partition)
[2019-01-22 11:54:35,994] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-01-22 11:54:35,990] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:35,990] INFO Created log for partition tools7-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-22 11:54:35,998] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools7-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:36,002] INFO [Partition tools7-2 broker=1] No checkpointed highwatermark is found for partition tools7-2 (kafka.cluster.Partition)
[2019-01-22 11:54:35,998] INFO Created log for partition tools7-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-22 11:54:36,010] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools7-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:36,014] INFO [Partition tools7-1 broker=3] No checkpointed highwatermark is found for partition tools7-1 (kafka.cluster.Partition)
[2019-01-22 11:54:36,010] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:36,030] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools7-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:36,022] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-22 11:54:36,034] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools7-1) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:36,046] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools7-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:36,111] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:36,127] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools7-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:54:36,139] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools7-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:36,147] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:36,294] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools7-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:36,294] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:54:36,501] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools7-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:54:36,505] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:55:22,282] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-4523 in state PreparingRebalance with old generation 0 (__consumer_offsets-33) (reason: Adding new member consumer-1-38dfcf02-650d-4ff2-b41f-c114ce37eb5f) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:55:22,306] INFO [GroupCoordinator 1]: Stabilized group console-consumer-4523 generation 1 (__consumer_offsets-33) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:55:22,338] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-4523 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 11:58:19,118] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools6-1) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:58:19,122] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools2-2, edited-0, tools1-1, tools3-2, alltools-2, tools5-1, tools4-0, edited6-0, tools-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:58:19,126] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, tools5-1, tools6-1, edited-0, tools3-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:58:19,130] INFO [Partition tools1-1 broker=3] tools1-1 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,146] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=10), tools1-1 -> (offset=0, leaderEpoch=10), tools2-2 -> (offset=0, leaderEpoch=10), tools-2 -> (offset=0, leaderEpoch=10), edited6-0 -> (offset=2, leaderEpoch=6), alltools-2 -> (offset=5, leaderEpoch=11), tools5-1 -> (offset=5, leaderEpoch=10), edited-0 -> (offset=8, leaderEpoch=10), tools3-2 -> (offset=0, leaderEpoch=10), mytools-2 -> (offset=0, leaderEpoch=10)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:58:19,150] INFO [Partition tools2-2 broker=3] tools2-2 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,154] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools6-1 -> (offset=3, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 11:58:19,154] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-22 11:58:19,162] INFO [Partition tools6-1 broker=3] tools6-1 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-22 11:58:19,178] INFO [Partition edited-0 broker=3] edited-0 starts at Leader Epoch 10 from offset 8. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,182] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-22 11:58:19,186] INFO [Partition alltools-2 broker=3] alltools-2 starts at Leader Epoch 11 from offset 5. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-22 11:58:19,194] INFO [Partition mytools-2 broker=3] mytools-2 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,206] INFO [Partition tools3-2 broker=3] tools3-2 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,214] INFO [Partition tools5-1 broker=3] tools5-1 starts at Leader Epoch 10 from offset 5. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,222] INFO [Partition tools4-0 broker=3] tools4-0 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,230] INFO [Partition edited6-0 broker=3] edited6-0 starts at Leader Epoch 6 from offset 2. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-22 11:58:19,238] INFO [Partition tools-2 broker=3] tools-2 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 11:58:19,510] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:58:19,514] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:58:19,514] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:58:19,518] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-22 11:58:19,518] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:58:19,522] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-22 11:58:19,522] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:58:19,526] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-22 11:58:19,530] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 11:58:19,530] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-22 12:03:13,196] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:03:50,369] INFO [GroupMetadataManager brokerId=2] Group console-consumer-46729 transitioned to Dead in generation 6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:03:50,433] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 68 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:04:14,863] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:13:13,184] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:13:50,366] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:14:14,848] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:19:49,945] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-4523 in state PreparingRebalance with old generation 1 (__consumer_offsets-33) (reason: removing member consumer-1-38dfcf02-650d-4ff2-b41f-c114ce37eb5f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:19:49,949] INFO [GroupCoordinator 1]: Group console-consumer-4523 with generation 2 is now empty (__consumer_offsets-33) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:20:05,981] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-74190 in state PreparingRebalance with old generation 0 (__consumer_offsets-42) (reason: Adding new member consumer-1-e19cbca2-8c85-4b26-a0bd-67f0390561e6) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:20:05,981] INFO [GroupCoordinator 1]: Stabilized group console-consumer-74190 generation 1 (__consumer_offsets-42) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:20:05,993] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-74190 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:20:10,124] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 42 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-62b29322-165b-41ed-8737-9f5011c3c8e4-StreamThread-1-consumer-d7734214-5368-4473-858c-a15835588217) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:20:10,136] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 43 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:20:10,180] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 43 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:21:56,823] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-74190 in state PreparingRebalance with old generation 1 (__consumer_offsets-42) (reason: removing member consumer-1-e19cbca2-8c85-4b26-a0bd-67f0390561e6 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:21:56,823] INFO [GroupCoordinator 1]: Group console-consumer-74190 with generation 2 is now empty (__consumer_offsets-42) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:06,952] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-22318 in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member consumer-1-623ed27b-4225-4b71-8be9-890201a4daa5) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:06,964] INFO [GroupCoordinator 2]: Stabilized group console-consumer-22318 generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:06,988] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-22318 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:36,688] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 43 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-60ec1ec8-bda0-4502-895e-b081385bf64d-StreamThread-1-consumer-220131b8-596e-4b13-956d-40fcc1a9d80d) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:38,275] INFO [GroupCoordinator 3]: Member alltoolsStream-62b29322-165b-41ed-8737-9f5011c3c8e4-StreamThread-1-consumer-d7734214-5368-4473-858c-a15835588217 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:38,279] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 44 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:38,319] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 44 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:22:51,818] WARN [LeaderEpochCache tools6-1] New epoch entry EpochEntry(epoch=6, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=3)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 12:23:03,445] INFO [GroupCoordinator 3]: Member alltoolsStream-60ec1ec8-bda0-4502-895e-b081385bf64d-StreamThread-1-consumer-220131b8-596e-4b13-956d-40fcc1a9d80d in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:23:03,445] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 44 (__consumer_offsets-2) (reason: removing member alltoolsStream-60ec1ec8-bda0-4502-895e-b081385bf64d-StreamThread-1-consumer-220131b8-596e-4b13-956d-40fcc1a9d80d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:23:03,449] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 45 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:23:13,182] INFO [GroupMetadataManager brokerId=1] Group console-consumer-4523 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:23:13,185] INFO [GroupMetadataManager brokerId=1] Group console-consumer-74190 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:23:13,185] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:23:50,365] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:24:14,846] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:33:13,180] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:33:50,367] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:34:14,855] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:34:59,801] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 45 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-49134050-8578-47bc-8802-1f6c09d86315-StreamThread-1-consumer-bc3bdea1-c514-4c6b-8b2d-77e42ce20ca7) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:34:59,801] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 46 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:34:59,823] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 46 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:38:04,297] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 46 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-1189b56e-2023-4845-9a75-8198636b8da1-StreamThread-1-consumer-e7976048-96c6-4fc8-9448-edfe784c454c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:38:04,461] INFO [GroupCoordinator 3]: Member alltoolsStream-49134050-8578-47bc-8802-1f6c09d86315-StreamThread-1-consumer-bc3bdea1-c514-4c6b-8b2d-77e42ce20ca7 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:38:04,461] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 47 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:38:04,482] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 47 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:43:13,188] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:43:50,370] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:44:14,856] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:53:13,185] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:53:50,378] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:54:14,847] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 12:58:05,377] INFO [GroupCoordinator 3]: Member alltoolsStream-1189b56e-2023-4845-9a75-8198636b8da1-StreamThread-1-consumer-e7976048-96c6-4fc8-9448-edfe784c454c in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:58:05,377] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 47 (__consumer_offsets-2) (reason: removing member alltoolsStream-1189b56e-2023-4845-9a75-8198636b8da1-StreamThread-1-consumer-e7976048-96c6-4fc8-9448-edfe784c454c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:58:05,377] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 48 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:58:05,895] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 48 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-92f79f11-ea19-4259-b65b-8b5f11cc8e93-StreamThread-1-consumer-36a79b47-ccb1-4d00-9fdf-d5062058ca94) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:58:05,895] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 49 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:58:05,910] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 49 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 12:58:22,956] WARN [LeaderEpochCache edited6-0] New epoch entry EpochEntry(epoch=6, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=2)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 13:03:13,193] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 13:03:50,375] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 13:04:14,848] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:39:22,500] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:58449-1 (kafka.network.Processor)
[2019-01-22 16:39:23,092] WARN Client session timed out, have not heard from server in 12441347ms for sessionid 0x1000f29e8100002 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:22,546] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:58544-2 (kafka.network.Processor)
[2019-01-22 16:39:22,514] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=2066949818, epoch=9253) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-22 16:39:23,325] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=2066949818, epoch=9253)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-22 16:39:22,500] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1448638607, epoch=9240) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-22 16:39:23,299] INFO Client session timed out, have not heard from server in 12441347ms for sessionid 0x1000f29e8100002, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:23,359] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1448638607, epoch=9240)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-22 16:39:23,359] WARN Unable to read additional data from client sessionid 0x1000f29e8100002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:23,375] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:58331 which had sessionid 0x1000f29e8100002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:22,514] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:58350-0 (kafka.network.Processor)
[2019-01-22 16:39:22,514] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:58349-0 (kafka.network.Processor)
[2019-01-22 16:39:22,514] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:58543-4 (kafka.network.Processor)
[2019-01-22 16:39:23,375] WARN Client session timed out, have not heard from server in 12441350ms for sessionid 0x1000f29e8100001 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:23,510] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:58908-9 (kafka.network.Processor)
[2019-01-22 16:39:23,510] INFO Client session timed out, have not heard from server in 12441350ms for sessionid 0x1000f29e8100001, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:23,752] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:58327-0 (kafka.network.Processor)
[2019-01-22 16:39:23,875] WARN Unable to read additional data from client sessionid 0x1000f29e8100001, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:24,253] WARN Client session timed out, have not heard from server in 12441348ms for sessionid 0x1000f29e8100000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:22,733] INFO [GroupCoordinator 2]: Member consumer-1-623ed27b-4225-4b71-8be9-890201a4daa5 in group console-consumer-22318 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:22,514] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1696198229, epoch=9289) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-22 16:39:22,514] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:58542-2 (kafka.network.Processor)
[2019-01-22 16:39:22,514] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=403076477, epoch=8771) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-22 16:39:24,023] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:58311 which had sessionid 0x1000f29e8100001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:25,069] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1696198229, epoch=9289)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-22 16:39:24,656] INFO Client session timed out, have not heard from server in 12441348ms for sessionid 0x1000f29e8100000, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:25,334] WARN Unable to read additional data from client sessionid 0x1000f29e8100000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:25,006] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-22318 in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: removing member consumer-1-623ed27b-4225-4b71-8be9-890201a4daa5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:25,444] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:58294 which had sessionid 0x1000f29e8100000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:25,084] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=403076477, epoch=8771)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-22 16:39:25,647] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:25,022] INFO Expiring session 0x1000f29e8100002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:26,127] INFO Accepted socket connection from /127.0.0.1:59062 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 16:39:26,207] INFO Expiring session 0x1000f29e8100000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:26,216] INFO Expiring session 0x1000f29e8100001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:26,221] INFO Processed session termination for sessionid: 0x1000f29e8100002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 16:39:26,226] INFO Processed session termination for sessionid: 0x1000f29e8100000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 16:39:26,228] INFO Processed session termination for sessionid: 0x1000f29e8100001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 16:39:26,135] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:25,740] INFO [GroupCoordinator 2]: Group console-consumer-22318 with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:26,366] INFO Client attempting to renew session 0x1000f29e8100002 at /127.0.0.1:59062 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:26,457] WARN Unable to reconnect to ZooKeeper service, session 0x1000f29e8100002 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:26,466] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-22318 in state PreparingRebalance with old generation 2 (__consumer_offsets-37) (reason: Adding new member consumer-1-e69a5297-ffd5-41d4-bf6d-d3a47e6c3834) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:26,458] INFO Invalid session 0x1000f29e8100002 for client /127.0.0.1:59062, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:26,461] INFO EventThread shut down for session: 0x1000f29e8100002 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:26,664] INFO [GroupCoordinator 2]: Stabilized group console-consumer-22318 generation 3 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:26,739] INFO Closed socket connection for client /127.0.0.1:59062 which had sessionid 0x1000f29e8100002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:26,524] INFO Unable to reconnect to ZooKeeper service, session 0x1000f29e8100002 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:26,766] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 16:39:26,984] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 16:39:27,016] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 16:39:26,875] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,047] INFO Accepted socket connection from /127.0.0.1:59086 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 16:39:27,016] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-22318 in state PreparingRebalance with old generation 3 (__consumer_offsets-37) (reason: Adding new member consumer-1-8b7d0bf5-f2ba-4ba6-b18e-4ec449895c29) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:27,047] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,172] INFO Client attempting to renew session 0x1000f29e8100001 at /127.0.0.1:59086 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:27,172] INFO Invalid session 0x1000f29e8100001 for client /127.0.0.1:59086, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:27,172] WARN Unable to reconnect to ZooKeeper service, session 0x1000f29e8100001 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,172] INFO Closed socket connection for client /127.0.0.1:59086 which had sessionid 0x1000f29e8100001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:27,172] INFO Unable to reconnect to ZooKeeper service, session 0x1000f29e8100001 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,172] INFO EventThread shut down for session: 0x1000f29e8100001 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,203] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 16:39:27,266] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 16:39:27,219] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,359] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:59087 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 16:39:27,359] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 16:39:27,359] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,234] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:27,547] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:59087 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:27,562] INFO Established session 0x1000f29e8100004 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:59087 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:27,562] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000f29e8100004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,609] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:27,625] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:27,890] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:27,906] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:28,078] INFO Accepted socket connection from /127.0.0.1:59092 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 16:39:28,187] INFO Accepted socket connection from /127.0.0.1:59093 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 16:39:28,187] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:28,312] INFO Client attempting to renew session 0x1000f29e8100000 at /127.0.0.1:59093 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:28,406] WARN Unable to reconnect to ZooKeeper service, session 0x1000f29e8100000 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:28,265] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:28,406] INFO Invalid session 0x1000f29e8100000 for client /127.0.0.1:59093, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:28,422] INFO EventThread shut down for session: 0x1000f29e8100000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:28,582] INFO Closed socket connection for client /127.0.0.1:59093 which had sessionid 0x1000f29e8100000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-22 16:39:28,422] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:28,437] INFO Unable to reconnect to ZooKeeper service, session 0x1000f29e8100000 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:28,766] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 16:39:29,047] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-22 16:39:29,053] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-22 16:39:28,835] INFO Client attempting to establish new session at /127.0.0.1:59092 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:29,136] INFO Established session 0x1000f29e8100005 with negotiated timeout 6000 for client /127.0.0.1:59092 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:29,136] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000f29e8100005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:29,189] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:29,190] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:29,347] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:29,375] INFO Accepted socket connection from /127.0.0.1:59096 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-22 16:39:29,376] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:29,487] INFO Client attempting to establish new session at /127.0.0.1:59096 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:29,507] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000f29e8100006, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-22 16:39:29,508] INFO Established session 0x1000f29e8100006 with negotiated timeout 6000 for client /127.0.0.1:59096 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-22 16:39:29,728] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:29,850] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:29,862] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-22 16:39:31,229] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools1-0, tools6-2, mytools-1, edited-2, tools4-2, tools3-1, tools5-0, edited6-2, tools-1, tools2-1, alltools-1, tools7-1) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:31,348] INFO [Partition alltools-1 broker=3] alltools-1 starts at Leader Epoch 16 from offset 6. Previous Leader Epoch was: 15 (kafka.cluster.Partition)
[2019-01-22 16:39:31,417] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100004 type:multi cxid:0xed zxid:0x534 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 16:39:31,432] INFO [Partition edited-2 broker=3] edited-2 starts at Leader Epoch 13 from offset 8. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,445] INFO [Partition mytools-1 broker=3] mytools-1 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,453] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100004 type:multi cxid:0xef zxid:0x535 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-22 16:39:31,458] INFO [Partition tools5-0 broker=3] tools5-0 starts at Leader Epoch 13 from offset 10. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,475] INFO [Partition edited6-2 broker=3] edited6-2 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-22 16:39:31,503] INFO [Partition tools4-2 broker=3] tools4-2 starts at Leader Epoch 13 from offset 1. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,529] INFO [Partition tools3-1 broker=3] tools3-1 starts at Leader Epoch 13 from offset 1. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,541] INFO [Partition tools-1 broker=3] tools-1 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,553] INFO [Partition tools2-1 broker=3] tools2-1 starts at Leader Epoch 13 from offset 1. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,574] INFO [Partition tools1-0 broker=3] tools1-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-22 16:39:31,604] INFO [Partition tools6-2 broker=3] tools6-2 starts at Leader Epoch 2 from offset 3. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:31,667] INFO [Partition tools7-1 broker=3] tools7-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-22 16:39:31,891] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:32,044] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:32,044] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:32,211] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:32,131] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools-1, edited-2, mytools-1, tools2-1, tools4-2, tools1-0, tools3-1, alltools-1, tools5-0, tools7-1, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:32,289] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:32,300] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=13), mytools-1 -> (offset=0, leaderEpoch=13), edited-2 -> (offset=8, leaderEpoch=13), tools4-2 -> (offset=1, leaderEpoch=13), tools3-1 -> (offset=1, leaderEpoch=13), tools5-0 -> (offset=10, leaderEpoch=13), edited6-2 -> (offset=3, leaderEpoch=6), tools-1 -> (offset=0, leaderEpoch=13), tools2-1 -> (offset=1, leaderEpoch=13), alltools-1 -> (offset=6, leaderEpoch=16), tools7-1 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:32,311] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools6-2 -> (offset=3, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:32,417] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, tools7-0, __consumer_offsets-27, __consumer_offsets-9, tools3-0, tools4-1, tools5-2, __consumer_offsets-33, tools1-2, edited-1, mytools-0, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, alltools-0, __consumer_offsets-48, tools-0, __consumer_offsets-6, edited6-1, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:32,430] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 2 from offset 3. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,432] WARN [LeaderEpochCache __consumer_offsets-0] New epoch entry EpochEntry(epoch=2, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,444] INFO [Partition edited6-1 broker=1] edited6-1 starts at Leader Epoch 1 from offset 6. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-22 16:39:32,456] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,458] WARN [LeaderEpochCache __consumer_offsets-48] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,468] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:32,469] WARN [LeaderEpochCache mytools-0] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,325] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:32,325] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:32,490] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,492] WARN [LeaderEpochCache __consumer_offsets-45] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,503] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 4 from offset 8. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:32,506] WARN [LeaderEpochCache tools5-2] New epoch entry EpochEntry(epoch=4, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,520] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:32,524] WARN [LeaderEpochCache tools4-1] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,512] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, my-example-topic-0, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, tools6-0, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:32,603] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:32,647] WARN [LeaderEpochCache tools3-0] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,676] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 2 from offset 3. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,698] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:32,627] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 10 from offset 40. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:32,705] WARN [LeaderEpochCache tools-0] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,724] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 2 from offset 31. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,737] WARN [LeaderEpochCache __consumer_offsets-39] New epoch entry EpochEntry(epoch=2, startOffset=31) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=31)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,766] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,769] WARN [LeaderEpochCache __consumer_offsets-36] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,714] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=10, startOffset=40) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=40)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,781] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 2 from offset 3. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,791] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,792] WARN [LeaderEpochCache __consumer_offsets-30] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,802] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-22 16:39:32,810] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:32,808] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-22 16:39:32,814] WARN [LeaderEpochCache tools1-2] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,816] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:32,818] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:32,819] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:32,820] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-22 16:39:32,821] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:32,822] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:32,823] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-22 16:39:32,824] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:32,824] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:32,826] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-22 16:39:32,823] INFO [Partition tools6-2 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-22 16:39:32,831] INFO [Partition tools1-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:32,917] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:32,965] INFO [Partition mytools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:32,972] INFO [Partition edited-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:32,956] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:32,992] INFO [Partition tools4-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:32,972] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,017] WARN [LeaderEpochCache __consumer_offsets-27] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,019] INFO [Partition tools3-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:33,026] INFO [Partition tools5-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:33,032] INFO [Partition edited6-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:33,035] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:33,036] WARN [LeaderEpochCache tools2-0] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,039] INFO [Partition tools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:33,049] INFO [Partition tools2-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:33,047] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 2 from offset 3. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,058] INFO [Partition alltools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:33,055] WARN [LeaderEpochCache __consumer_offsets-24] New epoch entry EpochEntry(epoch=2, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,066] INFO [Partition tools7-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-22 16:39:33,025] INFO [Partition tools6-0 broker=2] tools6-0 starts at Leader Epoch 4 from offset 4. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:33,074] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 2 from offset 3. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,075] WARN [LeaderEpochCache __consumer_offsets-21] New epoch entry EpochEntry(epoch=2, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,086] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,086] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,089] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,091] WARN [LeaderEpochCache __consumer_offsets-18] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,102] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,102] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,104] WARN [LeaderEpochCache __consumer_offsets-15] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,106] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,115] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 4 from offset 9. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-22 16:39:33,116] WARN [LeaderEpochCache edited-1] New epoch entry EpochEntry(epoch=4, startOffset=9) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=9)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,118] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,122] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,127] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,128] WARN [LeaderEpochCache __consumer_offsets-12] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,134] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 10 from offset 3. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,136] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=10, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,138] INFO [Partition tools7-0 broker=1] tools7-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-22 16:39:33,139] WARN [LeaderEpochCache tools7-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,149] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,150] WARN [LeaderEpochCache __consumer_offsets-9] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,149] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,159] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 5 from offset 4. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-22 16:39:33,160] WARN [LeaderEpochCache alltools-0] New epoch entry EpochEntry(epoch=5, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,157] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,171] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,173] WARN [LeaderEpochCache __consumer_offsets-6] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,177] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-22 16:39:33,179] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=8, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,182] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:33,183] WARN [LeaderEpochCache __consumer_offsets-3] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,191] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 10 from offset 3. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,194] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools6-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:33,195] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=10, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,208] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools6-0 -> (offset=4, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:33,254] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 10 from offset 2. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,280] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 10 from offset 6. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,284] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=10, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,297] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,301] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,316] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 10 from offset 7. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,325] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,330] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,342] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,343] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,354] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,354] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,364] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,365] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,375] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 10 from offset 3. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-22 16:39:33,376] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=10, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:33,385] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:33,397] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0, tools7-0, edited6-1, mytools-0, tools1-2, tools5-2, tools2-0, tools4-1, tools-0, edited-1, tools3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:33,401] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-22 16:39:33,403] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools7-0 -> (offset=0, leaderEpoch=1), tools3-0 -> (offset=0, leaderEpoch=4), tools4-1 -> (offset=0, leaderEpoch=4), tools5-2 -> (offset=8, leaderEpoch=4), tools1-2 -> (offset=0, leaderEpoch=4), edited-1 -> (offset=9, leaderEpoch=4), mytools-0 -> (offset=1, leaderEpoch=4), alltools-0 -> (offset=4, leaderEpoch=5), tools-0 -> (offset=1, leaderEpoch=4), edited6-1 -> (offset=6, leaderEpoch=1), tools2-0 -> (offset=0, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:33,484] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-22 16:39:33,485] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:33,487] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:33,489] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:33,491] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-22 16:39:33,492] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:33,493] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:33,496] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:33,497] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-22 16:39:33,498] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:33,502] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:33,502] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:33,504] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:33,508] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-22 16:39:33,510] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools7-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:33,514] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:36,581] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools-1, edited-2, mytools-1, tools2-1, tools4-2, tools1-0, tools3-1, alltools-1, tools5-0, tools7-1, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:36,581] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools1-0, mytools-1, edited-2, tools4-2, tools3-1, tools5-0, edited6-2, tools-1, tools2-1, alltools-1, tools7-1) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:36,628] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 17 from offset 6. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-22 16:39:36,644] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=17, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=15, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,628] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=14), mytools-1 -> (offset=0, leaderEpoch=14), edited-2 -> (offset=8, leaderEpoch=14), tools4-2 -> (offset=1, leaderEpoch=14), tools3-1 -> (offset=1, leaderEpoch=14), tools5-0 -> (offset=10, leaderEpoch=14), edited6-2 -> (offset=3, leaderEpoch=7), tools-1 -> (offset=0, leaderEpoch=14), tools2-1 -> (offset=1, leaderEpoch=14), alltools-1 -> (offset=6, leaderEpoch=17), tools7-1 -> (offset=0, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-01-22 16:39:36,644] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 14 from offset 8. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,659] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=14, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,675] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,690] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=14, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,706] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 14 from offset 10. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,706] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=14, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,722] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 7 from offset 3. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-22 16:39:36,724] WARN [LeaderEpochCache edited6-2] New epoch entry EpochEntry(epoch=7, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,659] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:36,727] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 14 from offset 1. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,727] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=14, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,742] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 14 from offset 1. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,742] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=14, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,758] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,758] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=14, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,742] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-22 16:39:36,758] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools1-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:36,758] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 14 from offset 1. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,758] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools2-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:36,758] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=14, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,773] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:36,773] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-22 16:39:36,773] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:36,773] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-22 16:39:36,773] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:36,773] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-22 16:39:36,773] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=14, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,789] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:36,789] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools7-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-22 16:39:36,789] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-22 16:39:36,789] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-22 16:39:36,805] WARN [LeaderEpochCache tools7-1] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 16:39:36,898] INFO [GroupCoordinator 2]: Member consumer-1-e69a5297-ffd5-41d4-bf6d-d3a47e6c3834 in group console-consumer-22318 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:36,930] INFO [GroupCoordinator 2]: Stabilized group console-consumer-22318 generation 4 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:36,961] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-22318 for generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:39:37,914] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:37,929] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:37,945] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-22 16:39:37,945] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:39:37,945] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-22 16:40:27,719] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,719] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,720] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,721] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,722] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,722] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,723] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,724] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,724] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,725] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,725] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,726] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:40:27,727] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,900] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,901] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,901] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,902] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,902] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,902] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,903] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,903] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,904] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,904] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,905] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,905] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,906] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,906] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,907] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,908] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,908] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,909] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,909] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,910] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:04,911] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:41:29,392] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:42:39,023] INFO [GroupCoordinator 3]: Member alltoolsStream-92f79f11-ea19-4259-b65b-8b5f11cc8e93-StreamThread-1-consumer-36a79b47-ccb1-4d00-9fdf-d5062058ca94 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:42:39,023] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 49 (__consumer_offsets-2) (reason: removing member alltoolsStream-92f79f11-ea19-4259-b65b-8b5f11cc8e93-StreamThread-1-consumer-36a79b47-ccb1-4d00-9fdf-d5062058ca94 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:42:39,023] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 50 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 16:43:08,383] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:43:45,569] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:44:10,041] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:53:08,386] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:53:45,576] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 16:54:10,042] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:03:08,389] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:03:45,567] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:04:10,044] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:05:30,286] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-22318 in state PreparingRebalance with old generation 4 (__consumer_offsets-37) (reason: removing member consumer-1-8b7d0bf5-f2ba-4ba6-b18e-4ec449895c29 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:05:30,286] INFO [GroupCoordinator 2]: Group console-consumer-22318 with generation 5 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:05:45,552] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-63495 in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member consumer-1-d48c06be-ed71-400c-a71e-8d49ec5e8d1c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:05:45,552] INFO [GroupCoordinator 1]: Stabilized group console-consumer-63495 generation 1 (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:05:45,568] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-63495 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:13:08,380] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:13:45,567] INFO [GroupMetadataManager brokerId=2] Group console-consumer-22318 transitioned to Dead in generation 5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:13:45,567] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:14:10,045] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:23:08,381] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:23:45,567] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:24:10,047] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:33:08,384] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:33:45,569] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:34:10,051] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:38:33,301] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 50 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-8848a3f3-8888-4420-9322-5cb053d3351c-StreamThread-1-consumer-f6428904-efe8-4bc6-879b-8c437ff8e0ac) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:38:33,304] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 51 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:38:33,314] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 51 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:38:43,319] INFO [GroupCoordinator 3]: Member alltoolsStream-8848a3f3-8888-4420-9322-5cb053d3351c-StreamThread-1-consumer-f6428904-efe8-4bc6-879b-8c437ff8e0ac in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:38:43,320] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 51 (__consumer_offsets-2) (reason: removing member alltoolsStream-8848a3f3-8888-4420-9322-5cb053d3351c-StreamThread-1-consumer-f6428904-efe8-4bc6-879b-8c437ff8e0ac on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:38:43,320] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 52 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 17:43:08,385] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:43:45,565] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:44:10,054] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:53:08,387] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:53:45,567] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 17:54:10,051] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:03:08,377] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:03:45,567] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:04:10,053] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:05:36,599] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-63495 in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: removing member consumer-1-d48c06be-ed71-400c-a71e-8d49ec5e8d1c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:05:36,599] INFO [GroupCoordinator 1]: Group console-consumer-63495 with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:05:43,036] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-9211 in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-1-fdbdcbfd-5b09-4a08-bf5f-367aa69db90b) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:05:43,036] INFO [GroupCoordinator 2]: Stabilized group console-consumer-9211 generation 1 (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:05:43,052] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-9211 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:06:06,674] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 52 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-2cc3e487-875c-4a59-8f00-5d5c3989f18d-StreamThread-1-consumer-3fde7947-3061-4093-8118-de9f62fdedc4) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:06:06,674] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 53 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:06:06,690] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 53 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:06:13,693] WARN [LeaderEpochCache tools6-0] New epoch entry EpochEntry(epoch=4, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=4)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 18:06:22,708] INFO [GroupCoordinator 3]: Member alltoolsStream-2cc3e487-875c-4a59-8f00-5d5c3989f18d-StreamThread-1-consumer-3fde7947-3061-4093-8118-de9f62fdedc4 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:06:22,708] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 53 (__consumer_offsets-2) (reason: removing member alltoolsStream-2cc3e487-875c-4a59-8f00-5d5c3989f18d-StreamThread-1-consumer-3fde7947-3061-4093-8118-de9f62fdedc4 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:06:22,709] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 54 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:07:24,838] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 54 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-f5080764-d106-43e2-816b-1f2ba2f724a2-StreamThread-1-consumer-cdc97216-0ddb-412e-97ad-c057e1003347) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:07:24,838] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 55 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:07:24,838] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 55 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:07:34,867] INFO [GroupCoordinator 3]: Member alltoolsStream-f5080764-d106-43e2-816b-1f2ba2f724a2-StreamThread-1-consumer-cdc97216-0ddb-412e-97ad-c057e1003347 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:07:34,867] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 55 (__consumer_offsets-2) (reason: removing member alltoolsStream-f5080764-d106-43e2-816b-1f2ba2f724a2-StreamThread-1-consumer-cdc97216-0ddb-412e-97ad-c057e1003347 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:07:34,867] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 56 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:09:12,752] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 56 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-de8bf9df-9374-40f4-b0b4-0c83f05becd2-StreamThread-1-consumer-f5965456-2437-4002-8640-ce4c640a6b62) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:09:12,753] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 57 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:09:12,762] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 57 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:09:22,766] INFO [GroupCoordinator 3]: Member alltoolsStream-de8bf9df-9374-40f4-b0b4-0c83f05becd2-StreamThread-1-consumer-f5965456-2437-4002-8640-ce4c640a6b62 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:09:22,766] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 57 (__consumer_offsets-2) (reason: removing member alltoolsStream-de8bf9df-9374-40f4-b0b4-0c83f05becd2-StreamThread-1-consumer-f5965456-2437-4002-8640-ce4c640a6b62 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:09:22,768] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 58 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:13:08,378] INFO [GroupMetadataManager brokerId=1] Group console-consumer-63495 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:13:08,379] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:13:45,563] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:14:00,664] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 58 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-d8cdd78d-4bed-4e56-99f5-4bd276a83cca-StreamThread-1-consumer-06eac25c-ce67-4120-b023-0e4f7ff2801c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:14:00,665] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 59 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:14:00,674] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 59 (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:14:01,361] WARN [LeaderEpochCache edited6-2] New epoch entry EpochEntry(epoch=7, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-22 18:14:10,042] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:23:08,377] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:23:45,562] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:24:10,042] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:33:08,378] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:33:45,561] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:34:10,041] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:43:08,384] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:43:45,571] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:44:10,043] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:53:08,378] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:53:45,561] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:54:10,050] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 18:54:42,766] INFO [GroupCoordinator 3]: Member alltoolsStream-d8cdd78d-4bed-4e56-99f5-4bd276a83cca-StreamThread-1-consumer-06eac25c-ce67-4120-b023-0e4f7ff2801c in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:54:42,767] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 59 (__consumer_offsets-2) (reason: removing member alltoolsStream-d8cdd78d-4bed-4e56-99f5-4bd276a83cca-StreamThread-1-consumer-06eac25c-ce67-4120-b023-0e4f7ff2801c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 18:54:42,767] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 60 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-22 19:03:08,379] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:03:45,562] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:04:10,041] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:13:08,383] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:13:45,561] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:14:10,043] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:23:08,382] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:23:45,561] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-22 19:24:10,053] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:21:23,500] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:60138-10 (kafka.network.Processor)
[2019-01-23 04:21:23,500] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1483230000, epoch=20448) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-23 04:21:23,500] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:59091-8 (kafka.network.Processor)
[2019-01-23 04:21:23,593] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:60137-16 (kafka.network.Processor)
[2019-01-23 04:21:23,593] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:59090-12 (kafka.network.Processor)
[2019-01-23 04:21:23,593] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=530772949, epoch=20438) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-23 04:21:23,624] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=530772949, epoch=20438)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-23 04:21:23,546] INFO [GroupCoordinator 2]: Member consumer-1-fdbdcbfd-5b09-4a08-bf5f-367aa69db90b in group console-consumer-9211 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-23 04:21:23,671] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-9211 in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-1-fdbdcbfd-5b09-4a08-bf5f-367aa69db90b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-23 04:21:23,515] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:60136-13 (kafka.network.Processor)
[2019-01-23 04:21:23,733] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=132326030, epoch=20419) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-23 04:21:23,749] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=132326030, epoch=20419)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-23 04:21:23,515] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:59118-11 (kafka.network.Processor)
[2019-01-23 04:21:23,702] INFO [GroupCoordinator 2]: Group console-consumer-9211 with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2019-01-23 04:21:23,608] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1483230000, epoch=20448)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-23 04:21:23,796] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-9211 in state PreparingRebalance with old generation 2 (__consumer_offsets-22) (reason: Adding new member consumer-1-37901ef0-d5e5-429d-9235-edd59c93bc31) (kafka.coordinator.group.GroupCoordinator)
[2019-01-23 04:21:23,827] INFO [GroupCoordinator 2]: Stabilized group console-consumer-9211 generation 3 (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2019-01-23 04:21:23,843] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-9211 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-23 04:21:23,983] INFO Expiring session 0x1000f29e8100005, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:23,999] INFO Expiring session 0x1000f29e8100006, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:23,999] INFO Expiring session 0x1000f29e8100004, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:24,015] INFO Processed session termination for sessionid: 0x1000f29e8100005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-23 04:21:24,015] INFO Processed session termination for sessionid: 0x1000f29e8100006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-23 04:21:24,015] INFO Processed session termination for sessionid: 0x1000f29e8100004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-23 04:21:24,046] WARN Client session timed out, have not heard from server in 31764208ms for sessionid 0x1000f29e8100005 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:24,046] INFO Client session timed out, have not heard from server in 31764208ms for sessionid 0x1000f29e8100005, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:24,046] WARN Unable to read additional data from client sessionid 0x1000f29e8100005, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:24,046] INFO Closed socket connection for client /127.0.0.1:59092 which had sessionid 0x1000f29e8100005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:24,233] WARN Client session timed out, have not heard from server in 31764211ms for sessionid 0x1000f29e8100006 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:24,233] INFO Client session timed out, have not heard from server in 31764211ms for sessionid 0x1000f29e8100006, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:24,233] WARN Unable to read additional data from client sessionid 0x1000f29e8100006, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:24,233] INFO Closed socket connection for client /127.0.0.1:59096 which had sessionid 0x1000f29e8100006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:24,465] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1149297722, epoch=20441) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-23 04:21:24,536] WARN Client session timed out, have not heard from server in 31763539ms for sessionid 0x1000f29e8100004 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:24,624] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1149297722, epoch=20441)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-23 04:21:24,539] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:59087 which had sessionid 0x1000f29e8100004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:24,661] INFO Client session timed out, have not heard from server in 31763539ms for sessionid 0x1000f29e8100004, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:24,465] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1434859886, epoch=29639) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-23 04:21:24,949] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1434859886, epoch=29639)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-23 04:21:25,824] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:25,902] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61179 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-23 04:21:25,902] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:25,933] INFO Client attempting to renew session 0x1000f29e8100006 at /0:0:0:0:0:0:0:1:61179 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:25,949] INFO Invalid session 0x1000f29e8100006 for client /0:0:0:0:0:0:0:1:61179, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:25,949] WARN Unable to reconnect to ZooKeeper service, session 0x1000f29e8100006 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:25,949] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-23 04:21:25,965] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61179 which had sessionid 0x1000f29e8100006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:25,949] INFO EventThread shut down for session: 0x1000f29e8100006 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:25,980] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-23 04:21:25,965] INFO Unable to reconnect to ZooKeeper service, session 0x1000f29e8100006 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:25,980] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-23 04:21:25,996] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,090] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,105] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,105] INFO Accepted socket connection from /127.0.0.1:61184 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-23 04:21:26,105] INFO Client attempting to establish new session at /127.0.0.1:61184 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,121] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000f29e8100007, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,121] INFO Established session 0x1000f29e8100007 with negotiated timeout 6000 for client /127.0.0.1:61184 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,136] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,136] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,168] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,215] INFO Accepted socket connection from /127.0.0.1:61187 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-23 04:21:26,183] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,246] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61188 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-23 04:21:26,215] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,246] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,324] INFO Client attempting to renew session 0x1000f29e8100005 at /127.0.0.1:61187 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,402] WARN Unable to reconnect to ZooKeeper service, session 0x1000f29e8100005 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,402] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-23 04:21:26,402] INFO EventThread shut down for session: 0x1000f29e8100005 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,402] INFO Invalid session 0x1000f29e8100005 for client /127.0.0.1:61187, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,480] INFO Client attempting to renew session 0x1000f29e8100004 at /0:0:0:0:0:0:0:1:61188 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,558] WARN Unable to reconnect to ZooKeeper service, session 0x1000f29e8100004 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,605] INFO Unable to reconnect to ZooKeeper service, session 0x1000f29e8100004 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,558] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-23 04:21:26,558] INFO EventThread shut down for session: 0x1000f29e8100004 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,636] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-23 04:21:26,652] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-23 04:21:26,558] INFO Invalid session 0x1000f29e8100004 for client /0:0:0:0:0:0:0:1:61188, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,464] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-23 04:21:26,449] INFO Unable to reconnect to ZooKeeper service, session 0x1000f29e8100005 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,699] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@470f1802 (org.apache.zookeeper.ZooKeeper)
[2019-01-23 04:21:26,699] INFO Closed socket connection for client /127.0.0.1:61187 which had sessionid 0x1000f29e8100005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:26,730] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61188 which had sessionid 0x1000f29e8100004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-23 04:21:26,808] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,808] INFO Accepted socket connection from /127.0.0.1:61194 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-23 04:21:26,808] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,808] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,808] INFO Client attempting to establish new session at /127.0.0.1:61194 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,761] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,761] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,824] INFO Accepted socket connection from /127.0.0.1:61195 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-23 04:21:26,824] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000f29e8100008, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,824] INFO Established session 0x1000f29e8100008 with negotiated timeout 6000 for client /127.0.0.1:61194 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,824] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,839] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,839] INFO Client attempting to establish new session at /127.0.0.1:61195 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,855] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,855] INFO Established session 0x1000f29e8100009 with negotiated timeout 6000 for client /127.0.0.1:61195 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-23 04:21:26,855] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000f29e8100009, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-23 04:21:26,871] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:26,871] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-23 04:21:27,214] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100007 type:multi cxid:0xed zxid:0x595 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-23 04:21:27,214] INFO Got user-level KeeperException when processing sessionid:0x1000f29e8100007 type:multi cxid:0xef zxid:0x596 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-23 04:21:27,214] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, tools5-1, tools6-2, tools7-2, edited-0, tools3-2, mytools-2, tools6-0) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,230] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,230] WARN [LeaderEpochCache tools1-1] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,246] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,246] WARN [LeaderEpochCache tools2-2] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,261] INFO [Partition tools6-0 broker=1] tools6-0 starts at Leader Epoch 5 from offset 5. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-23 04:21:27,277] INFO [Partition tools7-2 broker=1] tools7-2 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-23 04:21:27,277] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 11 from offset 8. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,277] WARN [LeaderEpochCache edited-0] New epoch entry EpochEntry(epoch=11, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,292] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 12 from offset 5. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:27,292] WARN [LeaderEpochCache alltools-2] New epoch entry EpochEntry(epoch=12, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,292] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools6-0) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,308] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,308] WARN [LeaderEpochCache mytools-2] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,308] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools6-0 -> (offset=5, leaderEpoch=5)) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,308] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,308] WARN [LeaderEpochCache tools3-2] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,324] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 11 from offset 5. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,324] WARN [LeaderEpochCache tools5-1] New epoch entry EpochEntry(epoch=11, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=5)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,371] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,386] WARN [LeaderEpochCache tools4-0] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,386] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools2-2, edited-0, tools1-1, tools3-2, alltools-2, tools5-1, tools7-2, tools4-0, edited6-0, tools-2, mytools-2, tools6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,386] INFO [Partition tools6-2 broker=1] tools6-2 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-23 04:21:27,402] INFO [Partition edited6-0 broker=1] edited6-0 starts at Leader Epoch 7 from offset 3. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-23 04:21:27,402] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=11), tools1-1 -> (offset=0, leaderEpoch=11), tools2-2 -> (offset=0, leaderEpoch=11), tools-2 -> (offset=0, leaderEpoch=11), edited6-0 -> (offset=3, leaderEpoch=7), alltools-2 -> (offset=5, leaderEpoch=12), tools5-1 -> (offset=5, leaderEpoch=11), tools6-2 -> (offset=3, leaderEpoch=3), tools7-2 -> (offset=1, leaderEpoch=1), edited-0 -> (offset=8, leaderEpoch=11), tools3-2 -> (offset=0, leaderEpoch=11), mytools-2 -> (offset=0, leaderEpoch=11)) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,417] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,433] WARN [LeaderEpochCache tools-2] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,417] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:27,433] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:27,449] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:27,449] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:27,449] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:27,449] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:27,464] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:27,464] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:27,464] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-23 04:21:27,480] INFO [Partition tools4-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,480] INFO [Partition tools1-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,495] INFO [Partition tools2-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,495] INFO [Partition tools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,495] INFO [Partition edited6-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,495] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, tools1-0, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, mytools-1, my-example-topic-0, edited-2, tools4-2, tools3-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, tools2-1, alltools-1, tools7-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,495] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 11 from offset 40. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,495] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, tools6-1, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,495] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=11, startOffset=40) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=40)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,511] INFO [Partition alltools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,495] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,511] WARN [LeaderEpochCache __consumer_offsets-29] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,511] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 18 from offset 6. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-23 04:21:27,511] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=18, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,511] INFO [Partition tools5-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,527] INFO [Partition tools6-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,527] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,527] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,527] INFO [Partition tools7-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,527] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,527] WARN [LeaderEpochCache __consumer_offsets-26] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,527] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,527] INFO [Partition edited-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,527] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,542] INFO [Partition tools3-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,542] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 15 from offset 8. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,542] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=15, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,542] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,542] WARN [LeaderEpochCache __consumer_offsets-23] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,542] INFO [Partition mytools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-23 04:21:27,558] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,558] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=15, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,558] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,558] WARN [LeaderEpochCache __consumer_offsets-20] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,574] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,574] WARN [LeaderEpochCache __consumer_offsets-17] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,574] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,574] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,574] INFO [Partition tools6-1 broker=3] tools6-1 starts at Leader Epoch 7 from offset 5. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-23 04:21:27,589] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 15 from offset 10. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,589] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,589] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-23 04:21:27,589] WARN [LeaderEpochCache __consumer_offsets-14] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,589] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=15, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,589] INFO [Partition tools6-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-23 04:21:27,605] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,605] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,605] WARN [LeaderEpochCache __consumer_offsets-11] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,605] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,605] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,605] WARN [LeaderEpochCache __consumer_offsets-8] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,620] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 8 from offset 4. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-23 04:21:27,620] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,639] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 11 from offset 3. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,620] WARN [LeaderEpochCache __consumer_offsets-5] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,639] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=11, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,639] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 15 from offset 1. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,639] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=15, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,652] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 10 from offset 134. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,652] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 15 from offset 1. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,652] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=15, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,652] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 10 from offset 3. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,667] WARN [LeaderEpochCache __consumer_offsets-47] New epoch entry EpochEntry(epoch=10, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,667] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,667] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,667] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,745] WARN [LeaderEpochCache __consumer_offsets-38] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,761] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-23 04:21:27,761] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,761] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,761] WARN [LeaderEpochCache __consumer_offsets-35] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,777] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,777] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,777] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=15, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,777] WARN [LeaderEpochCache __consumer_offsets-44] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,792] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 11 from offset 3. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,792] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=11, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,792] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,792] WARN [LeaderEpochCache __consumer_offsets-41] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,808] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 11 from offset 5. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,808] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-23 04:21:27,808] WARN [LeaderEpochCache __consumer_offsets-32] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,824] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 15 from offset 1. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,824] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=15, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,824] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools-1, edited-2, mytools-1, tools2-1, tools4-2, tools1-0, tools3-1, alltools-1, tools5-0, tools7-1, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,824] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=15), mytools-1 -> (offset=0, leaderEpoch=15), edited-2 -> (offset=8, leaderEpoch=15), tools4-2 -> (offset=1, leaderEpoch=15), tools3-1 -> (offset=1, leaderEpoch=15), tools5-0 -> (offset=10, leaderEpoch=15), edited6-2 -> (offset=4, leaderEpoch=8), tools-1 -> (offset=0, leaderEpoch=15), tools2-1 -> (offset=1, leaderEpoch=15), alltools-1 -> (offset=6, leaderEpoch=18), tools7-1 -> (offset=0, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:27,839] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-23 04:21:27,839] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=15, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,839] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 11 from offset 6. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,839] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=11, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,855] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,855] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,870] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 11 from offset 7. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,870] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=11, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=7)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,886] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,902] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,902] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,917] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,917] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,917] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=11, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,933] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 11 from offset 3. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,964] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-23 04:21:27,964] WARN [LeaderEpochCache tools7-1] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:27,995] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 11 from offset 3. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-01-23 04:21:27,995] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=11, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:28,011] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools6-1) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:28,011] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools6-1 -> (offset=5, leaderEpoch=7)) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:28,058] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-23 04:21:28,073] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:28,089] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-23 04:21:28,089] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:28,089] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-23 04:21:28,089] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-23 04:21:28,089] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-23 04:21:28,089] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-23 04:21:28,089] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:28,105] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:28,183] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-23 04:21:28,136] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-23 04:21:32,257] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools2-2, edited-0, tools1-1, tools3-2, alltools-2, tools5-1, tools7-2, tools4-0, edited6-0, tools-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:32,257] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, tools5-1, tools7-2, edited-0, tools3-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:32,257] INFO [Partition tools1-1 broker=3] tools1-1 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,257] WARN [LeaderEpochCache tools1-1] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,273] INFO [Partition tools2-2 broker=3] tools2-2 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,273] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=12), tools1-1 -> (offset=0, leaderEpoch=12), tools2-2 -> (offset=0, leaderEpoch=12), tools-2 -> (offset=0, leaderEpoch=12), edited6-0 -> (offset=3, leaderEpoch=8), alltools-2 -> (offset=5, leaderEpoch=13), tools5-1 -> (offset=5, leaderEpoch=12), tools7-2 -> (offset=1, leaderEpoch=2), edited-0 -> (offset=8, leaderEpoch=12), tools3-2 -> (offset=0, leaderEpoch=12), mytools-2 -> (offset=0, leaderEpoch=12)) (kafka.server.ReplicaFetcherManager)
[2019-01-23 04:21:32,273] WARN [LeaderEpochCache tools2-2] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,273] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,288] INFO [Partition tools7-2 broker=3] tools7-2 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-23 04:21:32,304] INFO [Partition edited-0 broker=3] edited-0 starts at Leader Epoch 12 from offset 8. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,304] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:32,304] WARN [LeaderEpochCache edited-0] New epoch entry EpochEntry(epoch=12, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,304] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools3-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition edited-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition mytools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools5-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools4-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition edited6-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,304] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition alltools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-23 04:21:32,320] INFO [Partition alltools-2 broker=3] alltools-2 starts at Leader Epoch 13 from offset 5. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-23 04:21:32,320] WARN [LeaderEpochCache alltools-2] New epoch entry EpochEntry(epoch=13, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,320] INFO [Partition mytools-2 broker=3] mytools-2 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,320] WARN [LeaderEpochCache mytools-2] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,335] INFO [Partition tools3-2 broker=3] tools3-2 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,335] WARN [LeaderEpochCache tools3-2] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,335] INFO [Partition tools5-1 broker=3] tools5-1 starts at Leader Epoch 12 from offset 5. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,335] WARN [LeaderEpochCache tools5-1] New epoch entry EpochEntry(epoch=12, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=5)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,351] INFO [Partition tools4-0 broker=3] tools4-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,351] WARN [LeaderEpochCache tools4-0] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:32,351] INFO [Partition edited6-0 broker=3] edited6-0 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-23 04:21:32,366] INFO [Partition tools-2 broker=3] tools-2 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-23 04:21:32,366] WARN [LeaderEpochCache tools-2] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-23 04:21:33,337] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:33,337] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-23 04:21:33,337] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:33,337] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-23 04:21:33,337] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:33,337] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-23 04:21:33,337] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-23 04:21:33,337] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,668] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,668] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:22:24,668] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,825] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,826] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,826] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,827] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,827] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,828] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,828] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,828] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,829] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,829] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,830] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,830] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,830] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,831] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,831] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,831] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,832] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,832] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,832] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,832] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,833] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,833] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,833] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,834] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,834] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,834] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,834] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,835] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,835] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,836] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,836] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,836] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,836] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,837] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,837] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,837] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,838] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,838] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,838] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:01,839] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,309] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:26,325] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:23:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:24:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:33:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:33:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:34:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:43:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:43:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:44:04,111] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:53:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:53:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 04:54:04,109] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:03:02,447] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:03:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:04:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:13:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:13:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:14:04,116] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:23:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:23:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:24:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:33:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:33:39,644] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:34:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:43:02,455] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:43:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:44:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:53:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:53:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 05:54:04,109] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:03:02,455] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:03:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:04:04,113] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:13:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:13:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:14:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:23:02,455] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:23:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:24:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:33:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:33:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:34:04,109] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:43:02,448] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:43:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:44:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:53:02,450] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:53:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 06:54:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:03:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:03:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:04:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:13:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:13:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:14:04,124] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:23:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:23:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:24:04,109] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:33:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:33:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:34:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:43:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:43:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:44:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:53:02,454] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:53:39,633] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 07:54:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:03:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:03:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:04:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:13:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:13:39,639] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:14:04,123] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:23:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:23:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:24:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:33:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:33:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:34:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:43:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:43:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:44:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:53:02,450] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:53:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 08:54:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:03:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:03:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:04:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:13:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:13:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:14:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:23:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:23:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:24:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:33:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:33:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:34:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:43:02,450] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:43:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:44:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:53:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:53:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 09:54:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:03:02,451] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:03:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:04:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:13:02,450] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:13:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:14:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:23:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:23:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:24:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:33:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:33:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:34:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:43:02,450] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:43:39,639] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:44:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:53:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:53:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 10:54:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:03:02,451] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:03:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:04:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:13:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:13:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:14:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:23:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:23:39,637] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:24:04,122] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:33:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:33:39,638] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:34:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:43:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:43:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:44:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:53:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:53:39,634] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 11:54:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:03:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:03:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:04:04,111] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:13:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:13:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:14:04,112] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:23:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:23:39,632] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:24:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:33:02,451] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:33:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:34:04,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:43:02,449] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:43:39,636] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:44:04,115] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:53:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:53:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 12:54:04,126] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:03:02,447] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:03:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:04:04,111] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:13:02,447] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:13:39,630] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:14:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:23:02,445] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:23:39,631] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:24:04,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:33:02,446] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:33:39,629] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:34:04,109] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-23 13:41:01,183] WARN Session 0x1000f29e8100007 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connessione in corso interrotta forzatamente dall'host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1145)
[2019-01-23 13:41:01,183] WARN Session 0x1000f29e8100008 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connessione in corso interrotta forzatamente dall'host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1145)
[2019-01-23 13:41:01,183] WARN Session 0x1000f29e8100009 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connessione in corso interrotta forzatamente dall'host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1145)
[2019-01-23 13:41:02,492] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
