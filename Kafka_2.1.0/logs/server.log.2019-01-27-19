[2019-01-27 16:40:32,171] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-27 16:40:32,171] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-27 16:40:32,171] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-27 16:40:32,171] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-27 16:40:32,171] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-27 16:40:32,203] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-27 16:40:32,203] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-27 16:40:32,218] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:host.name=ITdif.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,218] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,234] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,234] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,234] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:32,265] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-27 16:40:32,281] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:40:41,247] INFO Expiring session 0x1000aa9390f0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:41,247] INFO Expiring session 0x1000aa9390f0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:41,247] INFO Expiring session 0x1000aa9390f0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:41,247] INFO Processed session termination for sessionid: 0x1000aa9390f0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:41,247] INFO Processed session termination for sessionid: 0x1000aa9390f0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:41,247] INFO Creating new log file: log.ea (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-27 16:40:41,247] INFO Processed session termination for sessionid: 0x1000aa9390f0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:46,461] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-27 16:40:47,211] INFO starting (kafka.server.KafkaServer)
[2019-01-27 16:40:47,211] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-27 16:40:47,242] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:40:47,242] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,258] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:40:47,273] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:40:47,273] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:40:47,289] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51455 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:40:47,289] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:40:47,289] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51455 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:47,289] INFO Established session 0x100018d4b890000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51455 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:40:47,289] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100018d4b890000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:40:47,305] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:40:47,383] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x1 zxid:0xee txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,398] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x2 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,398] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x3 zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,398] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x4 zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,414] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x5 zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,414] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x6 zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,414] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x7 zxid:0xf4 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,414] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x8 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,414] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0x9 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,414] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0xa zxid:0xf7 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,430] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0xb zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,430] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0xc zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,430] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:create cxid:0xd zxid:0xfa txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:47,664] INFO Cluster ID = 5GfY6w8PQ1yVBYvzG2VTdQ (kafka.server.KafkaServer)
[2019-01-27 16:40:47,758] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-27 16:40:47,773] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-27 16:40:47,820] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:40:47,820] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:40:47,820] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:40:47,883] INFO Loading logs. (kafka.log.LogManager)
[2019-01-27 16:40:47,961] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:47,961] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,023] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,039] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,054] INFO [ProducerStateManager partition=aggregateddata-1] Loading producer state from snapshot file 'C:\tmp\logs1\aggregateddata-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,070] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 141 ms (kafka.log.Log)
[2019-01-27 16:40:48,086] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,086] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,086] INFO [ProducerStateManager partition=aggregateddata-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,101] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,101] INFO [ProducerStateManager partition=aggregateddata-2] Loading producer state from snapshot file 'C:\tmp\logs1\aggregateddata-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,101] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-01-27 16:40:48,117] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\globalTableHoldON-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\globalTableHoldON-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548534417964}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:40:48,117] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,133] INFO [ProducerStateManager partition=globalTableHoldON-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,133] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,133] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,148] INFO [ProducerStateManager partition=globalTableHoldON-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,148] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,148] INFO [ProducerStateManager partition=globalTableHoldON-0] Loading producer state from snapshot file 'C:\tmp\logs1\globalTableHoldON-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,164] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-27 16:40:48,164] WARN [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\globalTableHoldON-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\globalTableHoldON-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548534226695}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:40:48,164] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,179] INFO [ProducerStateManager partition=globalTableHoldON-2] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,179] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,179] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,195] INFO [ProducerStateManager partition=globalTableHoldON-2] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,195] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,195] INFO [ProducerStateManager partition=globalTableHoldON-2] Loading producer state from snapshot file 'C:\tmp\logs1\globalTableHoldON-2\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,195] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 31 ms (kafka.log.Log)
[2019-01-27 16:40:48,211] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,211] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,226] INFO [ProducerStateManager partition=toolsEvents-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,226] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,226] INFO [ProducerStateManager partition=toolsEvents-0] Loading producer state from snapshot file 'C:\tmp\logs1\toolsEvents-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,226] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 15 ms (kafka.log.Log)
[2019-01-27 16:40:48,242] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,242] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,257] INFO [ProducerStateManager partition=toolsEvents-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,257] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,257] INFO [ProducerStateManager partition=toolsEvents-2] Loading producer state from snapshot file 'C:\tmp\logs1\toolsEvents-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,257] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 15 ms (kafka.log.Log)
[2019-01-27 16:40:48,273] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,273] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,289] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,289] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:40:48,304] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,304] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,304] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,304] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:40:48,320] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,320] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,320] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,336] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,336] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,336] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-01-27 16:40:48,351] WARN [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548533999948}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:40:48,351] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,367] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 23 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,367] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,367] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,382] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 23 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,382] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,382] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-2\00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,382] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 31 ms (kafka.log.Log)
[2019-01-27 16:40:48,398] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,398] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,414] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,414] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:40:48,429] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,429] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,445] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,445] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:40:48,461] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,461] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,476] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,476] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:40:48,492] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,492] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,507] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,507] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:40:48,523] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,523] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,539] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,539] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:40:48,554] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,554] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,570] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,586] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs1] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,586] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-35\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:40:48,586] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 32 ms (kafka.log.Log)
[2019-01-27 16:40:48,601] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,601] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,601] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,617] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:40:48,617] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,617] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,632] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,632] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:40:48,648] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,648] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,648] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,648] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:40:48,664] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,664] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,679] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,679] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:40:48,679] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,679] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,695] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,710] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:40:48,710] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:40:48,710] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,726] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:40:48,726] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:40:48,742] INFO Logs loading complete in 859 ms. (kafka.log.LogManager)
[2019-01-27 16:40:48,757] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-27 16:40:48,757] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-27 16:40:49,101] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-27 16:40:49,132] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-27 16:40:49,179] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:40:49,179] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:40:49,179] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:40:49,195] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-27 16:40:49,257] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-27 16:40:49,257] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-27 16:40:49,273] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-27 16:40:49,335] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:40:49,335] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:40:49,335] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:40:49,382] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:40:49,382] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:40:49,382] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:49,413] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-27 16:40:49,460] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-27 16:40:49,460] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-27 16:40:49,460] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-27 16:40:49,523] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-27 16:40:49,523] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-27 16:40:49,538] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-27 16:40:49,538] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs1] retention.ms for topic toolsEvents is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:40:49,538] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] retention.ms for topic globalTableHoldON is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:40:49,538] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-27 16:40:49,554] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-27 16:40:49,554] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs1] retention.ms for topic toolsEvents is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:40:49,554] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-27 16:40:49,570] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-27 16:40:49,570] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs1] retention.ms for topic toolsEvents is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:40:49,570] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-27 16:40:49,570] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-27 16:40:49,585] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-27 16:40:49,585] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] retention.ms for topic globalTableHoldON is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:40:49,585] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-27 16:40:49,601] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-27 16:40:49,601] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] retention.ms for topic globalTableHoldON is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:40:49,695] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, toolsEvents-0, aggregateddata-2, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, globalTableHoldON-2, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:40:49,710] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,726] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,726] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:multi cxid:0xe3 zxid:0x107 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:49,742] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890000 type:multi cxid:0xe5 zxid:0x108 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:40:49,757] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,757] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,773] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-27 16:40:49,773] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,773] INFO [Partition globalTableHoldON-2 broker=1] globalTableHoldON-2 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,788] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,788] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,788] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,804] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,804] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:40:49,804] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,820] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,820] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,820] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,820] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,835] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,835] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,851] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,851] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,851] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 23 (kafka.cluster.Replica)
[2019-01-27 16:40:49,851] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 23. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,866] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-27 16:40:49,866] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,866] INFO [Partition toolsEvents-0 broker=1] toolsEvents-0 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,866] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:40:49,866] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,882] INFO [Partition aggregateddata-2 broker=1] aggregateddata-2 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,882] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,882] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,898] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,898] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,898] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-27 16:40:49,898] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,913] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,913] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,929] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,929] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,945] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:49,945] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:49,960] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:40:49,960] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-27 16:40:49,976] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-27 16:40:49,976] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:40:49,991] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:49,991] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:49,991] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,023] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,023] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,023] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,023] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,023] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,023] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,038] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,038] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,070] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata-1, toolsEvents-2, globalTableHoldON-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:40:50,070] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:50,070] INFO [Partition aggregateddata-1 broker=1] aggregateddata-1 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:50,085] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:50,085] INFO [Partition toolsEvents-2 broker=1] toolsEvents-2 starts at Leader Epoch 1 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:50,101] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:40:50,101] INFO [Partition globalTableHoldON-0 broker=1] globalTableHoldON-0 starts at Leader Epoch 1 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:40:50,101] INFO [GroupCoordinator 1]: Loading group metadata for alltoolsStream with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:40:50,116] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 125 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,116] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,116] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,116] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,132] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,148] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,148] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,148] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,148] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,148] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,148] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,163] INFO [GroupCoordinator 1]: Loading group metadata for connect-test-sink with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:40:50,163] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,163] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,163] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,163] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:40:50,179] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:00,177] INFO [GroupCoordinator 1]: Member consumer-1-4bf605d2-0ded-438d-832f-8c0f22489baa in group connect-test-sink has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:41:00,177] INFO [GroupCoordinator 1]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-4bf605d2-0ded-438d-832f-8c0f22489baa on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:41:00,192] INFO [GroupCoordinator 1]: Group connect-test-sink with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:41:04,207] INFO [Partition toolsEvents-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-27 16:41:04,223] INFO [Partition aggregateddata-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-27 16:41:04,223] INFO [Partition globalTableHoldON-2 broker=1] Shrinking ISR from 1,3 to 1 (kafka.cluster.Partition)
[2019-01-27 16:41:14,931] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-27 16:41:15,587] INFO starting (kafka.server.KafkaServer)
[2019-01-27 16:41:15,587] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-27 16:41:15,618] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:41:15,618] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,618] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:15,649] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:41:15,649] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:41:15,649] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51472 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:41:15,649] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:41:15,649] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51472 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:41:15,649] INFO Established session 0x100018d4b890001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51472 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:41:15,649] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100018d4b890001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:41:15,665] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:41:15,712] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x1 zxid:0x10f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,727] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x2 zxid:0x110 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,727] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x3 zxid:0x111 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,727] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x4 zxid:0x112 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,743] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x5 zxid:0x113 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,743] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x6 zxid:0x114 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,743] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x7 zxid:0x115 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,743] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x8 zxid:0x116 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,743] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0x9 zxid:0x117 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,743] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0xa zxid:0x118 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,743] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0xb zxid:0x119 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,759] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0xc zxid:0x11a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,759] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890001 type:create cxid:0xd zxid:0x11b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:15,931] INFO Cluster ID = 5GfY6w8PQ1yVBYvzG2VTdQ (kafka.server.KafkaServer)
[2019-01-27 16:41:16,024] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-27 16:41:16,040] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-27 16:41:16,087] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:41:16,087] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:41:16,087] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:41:16,134] INFO Loading logs. (kafka.log.LogManager)
[2019-01-27 16:41:16,212] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,212] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,259] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,274] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2019-01-27 16:41:16,290] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,290] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,305] INFO [ProducerStateManager partition=aggregateddata-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,321] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,321] INFO [ProducerStateManager partition=aggregateddata-2] Loading producer state from snapshot file 'C:\tmp\logs2\aggregateddata-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,337] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 63 ms (kafka.log.Log)
[2019-01-27 16:41:16,352] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\globalTableHoldON-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\globalTableHoldON-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548534417964}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:41:16,352] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,368] INFO [ProducerStateManager partition=globalTableHoldON-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,368] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,368] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,384] INFO [ProducerStateManager partition=globalTableHoldON-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,384] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,384] INFO [ProducerStateManager partition=globalTableHoldON-0] Loading producer state from snapshot file 'C:\tmp\logs2\globalTableHoldON-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,384] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 32 ms (kafka.log.Log)
[2019-01-27 16:41:16,399] WARN [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\globalTableHoldON-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\globalTableHoldON-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548528662676}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:41:16,399] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,415] INFO [ProducerStateManager partition=globalTableHoldON-1] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,415] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,415] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,430] INFO [ProducerStateManager partition=globalTableHoldON-1] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,430] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,446] INFO [ProducerStateManager partition=globalTableHoldON-1] Loading producer state from snapshot file 'C:\tmp\logs2\globalTableHoldON-1\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,446] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-27 16:41:16,446] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,446] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,462] INFO [ProducerStateManager partition=toolsEvents-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,462] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,462] INFO [ProducerStateManager partition=toolsEvents-0] Loading producer state from snapshot file 'C:\tmp\logs2\toolsEvents-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,462] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,477] WARN [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\toolsEvents-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\toolsEvents-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548534415954}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:41:16,477] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,477] INFO [ProducerStateManager partition=toolsEvents-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,493] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,493] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,493] INFO [ProducerStateManager partition=toolsEvents-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,509] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,509] INFO [ProducerStateManager partition=toolsEvents-1] Loading producer state from snapshot file 'C:\tmp\logs2\toolsEvents-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,509] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 32 ms (kafka.log.Log)
[2019-01-27 16:41:16,524] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,524] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,524] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,540] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,540] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:16,540] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,555] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,555] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,571] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,571] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,587] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,587] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,602] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,602] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:41:16,618] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,618] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,634] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,634] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,649] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,649] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,665] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,665] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,680] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,680] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,696] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,696] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,712] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,712] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,727] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,743] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:16,743] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,743] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,758] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,758] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:41:16,774] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,774] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,790] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,790] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,790] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,790] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,805] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,805] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:41:16,821] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,821] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,821] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,837] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,837] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,837] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,852] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,852] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:41:16,868] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,868] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,883] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,883] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:16,899] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,899] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,915] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,915] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,930] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,930] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,946] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,946] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:16,962] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,962] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,977] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,977] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:41:16,993] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:16,993] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:16,993] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:17,008] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:17,008] INFO Logs loading complete in 874 ms. (kafka.log.LogManager)
[2019-01-27 16:41:17,024] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-27 16:41:17,024] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-27 16:41:17,321] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-27 16:41:17,352] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-27 16:41:17,383] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:17,399] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:17,399] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:17,399] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-27 16:41:17,477] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-27 16:41:17,477] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-27 16:41:17,477] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-27 16:41:17,555] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:17,555] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:17,555] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:17,586] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:41:17,586] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:41:17,602] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:17,618] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-27 16:41:17,633] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-27 16:41:17,649] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-27 16:41:17,649] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-27 16:41:17,696] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-27 16:41:17,711] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs2] retention.ms for topic toolsEvents is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:41:17,711] WARN [Log partition=aggregateddata-0, dir=C:\tmp\logs2] retention.ms for topic aggregateddata is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:41:17,711] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] retention.ms for topic globalTableHoldON is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:41:17,727] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-27 16:41:17,743] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-27 16:41:17,743] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-27 16:41:17,743] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-27 16:41:17,821] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, toolsEvents-1, __consumer_offsets-6, aggregateddata-0, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:17,836] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:41:17,836] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,868] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,868] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,883] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,883] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,899] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-27 16:41:17,899] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,899] INFO [Partition toolsEvents-1 broker=2] toolsEvents-1 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,914] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,914] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,930] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,930] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,946] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,946] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,946] INFO [Partition aggregateddata-0 broker=2] aggregateddata-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,961] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,961] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,961] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,977] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,977] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,977] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:17,993] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:17,993] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,008] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,008] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,008] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,008] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,024] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,024] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,039] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,039] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,039] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,039] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,055] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,055] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,071] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,071] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,071] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,071] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:18,086] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-27 16:41:18,086] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,086] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,102] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-27 16:41:18,102] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,102] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:41:18,118] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-27 16:41:18,118] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata-2, toolsEvents-0, globalTableHoldON-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:18,149] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:41:18,164] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(aggregateddata-2 -> (offset=3, leaderEpoch=0), globalTableHoldON-0 -> (offset=6, leaderEpoch=1), toolsEvents-0 -> (offset=5, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:18,164] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,164] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,164] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,164] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,180] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,180] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,196] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-27 16:41:18,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,211] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,211] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-27 16:41:18,211] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,211] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-27 16:41:18,211] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,227] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,227] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,227] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,227] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,242] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 78 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,242] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,258] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,258] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, globalTableHoldON-1, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, toolsEvents-1, __consumer_offsets-6, aggregateddata-0, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:18,258] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,258] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,258] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,274] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,274] INFO [Partition aggregateddata-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-27 16:41:18,274] INFO [Partition globalTableHoldON-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-27 16:41:18,274] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,274] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,274] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,289] INFO [Partition toolsEvents-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-27 16:41:18,289] WARN [LeaderEpochCache __consumer_offsets-48] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,289] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,289] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,289] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,289] WARN [LeaderEpochCache __consumer_offsets-45] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,289] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,305] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,305] INFO [Partition toolsEvents-1 broker=2] toolsEvents-1 starts at Leader Epoch 1 from offset 6. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,305] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,305] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,305] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,321] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,321] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:18,321] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,321] WARN [LeaderEpochCache __consumer_offsets-42] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,336] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,336] WARN [LeaderEpochCache __consumer_offsets-39] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,336] INFO [Partition aggregateddata-0 broker=2] aggregateddata-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,336] WARN [LeaderEpochCache aggregateddata-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,352] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,352] WARN [LeaderEpochCache __consumer_offsets-36] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,352] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,352] WARN [LeaderEpochCache __consumer_offsets-33] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,352] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,352] WARN [LeaderEpochCache __consumer_offsets-30] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,367] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,367] WARN [LeaderEpochCache __consumer_offsets-27] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,367] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,367] WARN [LeaderEpochCache __consumer_offsets-24] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,383] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,383] WARN [LeaderEpochCache __consumer_offsets-21] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,383] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,383] WARN [LeaderEpochCache __consumer_offsets-18] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,383] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,383] WARN [LeaderEpochCache __consumer_offsets-15] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,399] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,399] WARN [LeaderEpochCache __consumer_offsets-12] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,414] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,414] WARN [LeaderEpochCache __consumer_offsets-9] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,414] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,414] WARN [LeaderEpochCache __consumer_offsets-6] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,430] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:18,430] WARN [LeaderEpochCache __consumer_offsets-3] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:18,446] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:18,446] INFO [Partition globalTableHoldON-1 broker=2] globalTableHoldON-1 starts at Leader Epoch 1 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:30,762] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-27 16:41:31,418] INFO starting (kafka.server.KafkaServer)
[2019-01-27 16:41:31,418] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-27 16:41:31,449] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:41:31,449] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,449] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,465] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,465] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,465] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,465] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-27 16:41:31,496] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:41:31,496] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:41:31,496] INFO Accepted socket connection from /127.0.0.1:51492 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:41:31,496] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:41:31,496] INFO Client attempting to establish new session at /127.0.0.1:51492 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:41:31,496] INFO Established session 0x100018d4b890002 with negotiated timeout 6000 for client /127.0.0.1:51492 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:41:31,496] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100018d4b890002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-27 16:41:31,512] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-27 16:41:31,559] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x1 zxid:0x138 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,574] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x2 zxid:0x139 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,574] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x3 zxid:0x13a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,590] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x4 zxid:0x13b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,590] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x5 zxid:0x13c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,590] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x6 zxid:0x13d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,590] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x7 zxid:0x13e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,590] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x8 zxid:0x13f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,590] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0x9 zxid:0x140 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,605] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0xa zxid:0x141 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,605] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0xb zxid:0x142 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,605] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0xc zxid:0x143 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,605] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890002 type:create cxid:0xd zxid:0x144 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:41:31,793] INFO Cluster ID = 5GfY6w8PQ1yVBYvzG2VTdQ (kafka.server.KafkaServer)
[2019-01-27 16:41:31,887] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-27 16:41:31,902] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-27 16:41:31,934] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:41:31,934] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:41:31,949] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-27 16:41:31,996] INFO Loading logs. (kafka.log.LogManager)
[2019-01-27 16:41:32,074] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,090] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,137] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,137] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2019-01-27 16:41:32,152] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,152] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,168] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,183] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,199] INFO [ProducerStateManager partition=aggregateddata-1] Loading producer state from snapshot file 'C:\tmp\logs3\aggregateddata-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,215] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 63 ms (kafka.log.Log)
[2019-01-27 16:41:32,230] WARN [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\globalTableHoldON-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\globalTableHoldON-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548528662676}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:41:32,230] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,246] INFO [ProducerStateManager partition=globalTableHoldON-1] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,246] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,246] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,262] INFO [ProducerStateManager partition=globalTableHoldON-1] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,262] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,262] INFO [ProducerStateManager partition=globalTableHoldON-1] Loading producer state from snapshot file 'C:\tmp\logs3\globalTableHoldON-1\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,277] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 62 ms (kafka.log.Log)
[2019-01-27 16:41:32,277] WARN [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\globalTableHoldON-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\globalTableHoldON-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548534226695}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:41:32,277] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,293] INFO [ProducerStateManager partition=globalTableHoldON-2] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,293] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,293] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,308] INFO [ProducerStateManager partition=globalTableHoldON-2] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,324] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,324] INFO [ProducerStateManager partition=globalTableHoldON-2] Loading producer state from snapshot file 'C:\tmp\logs3\globalTableHoldON-2\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,324] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 47 ms (kafka.log.Log)
[2019-01-27 16:41:32,340] WARN [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\toolsEvents-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\toolsEvents-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548534415954}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-27 16:41:32,340] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,340] INFO [ProducerStateManager partition=toolsEvents-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,355] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,355] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,355] INFO [ProducerStateManager partition=toolsEvents-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,371] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,371] INFO [ProducerStateManager partition=toolsEvents-1] Loading producer state from snapshot file 'C:\tmp\logs3\toolsEvents-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,371] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:32,387] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,387] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,402] INFO [ProducerStateManager partition=toolsEvents-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,418] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs3] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,418] INFO [ProducerStateManager partition=toolsEvents-2] Loading producer state from snapshot file 'C:\tmp\logs3\toolsEvents-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,418] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:32,433] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,433] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,449] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,449] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,465] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,465] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,480] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,480] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:32,496] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,496] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,512] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,512] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,512] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,512] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,527] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,527] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,543] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,543] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,543] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-16\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-27 16:41:32,543] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,558] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,558] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,574] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,574] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,590] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,590] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,590] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,605] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:32,605] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,605] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,621] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,621] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,637] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,637] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,637] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,652] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:32,652] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,652] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,668] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,668] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,683] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,683] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,683] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,699] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:32,699] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,699] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,715] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,715] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,730] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,730] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,746] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,746] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-27 16:41:32,761] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,761] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,777] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,777] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,793] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,793] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,808] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,808] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:41:32,824] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,824] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,840] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,840] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,855] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,855] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,871] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,871] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,886] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-27 16:41:32,902] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,902] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:41:32,902] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:41:32,918] INFO Logs loading complete in 922 ms. (kafka.log.LogManager)
[2019-01-27 16:41:32,933] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-27 16:41:32,933] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-27 16:41:33,230] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-27 16:41:33,277] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-27 16:41:33,324] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:33,324] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:33,324] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:33,339] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-27 16:41:33,402] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-27 16:41:33,418] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-27 16:41:33,418] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-27 16:41:33,496] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:33,496] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:33,511] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-27 16:41:33,527] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:41:33,527] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:41:33,543] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:33,558] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-27 16:41:33,574] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-27 16:41:33,589] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-27 16:41:33,589] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-27 16:41:33,636] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-27 16:41:33,652] WARN [Log partition=aggregateddata-0, dir=C:\tmp\logs3] retention.ms for topic aggregateddata is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-27 16:41:33,668] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-27 16:41:33,668] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-27 16:41:33,668] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-27 16:41:33,683] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-27 16:41:33,761] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:33,777] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,777] INFO [Partition __consumer_offsets-10 broker=3] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,793] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,793] INFO [Partition __consumer_offsets-7 broker=3] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,808] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,808] INFO [Partition __consumer_offsets-4 broker=3] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,824] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,824] INFO [Partition __consumer_offsets-1 broker=3] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,824] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,824] INFO [Partition __consumer_offsets-49 broker=3] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,839] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,839] INFO [Partition __consumer_offsets-46 broker=3] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,839] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,855] INFO [Partition __consumer_offsets-43 broker=3] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,855] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,855] INFO [Partition __consumer_offsets-40 broker=3] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,871] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,871] INFO [Partition __consumer_offsets-37 broker=3] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,871] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,886] INFO [Partition __consumer_offsets-34 broker=3] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,886] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,886] INFO [Partition __consumer_offsets-31 broker=3] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,902] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,902] INFO [Partition __consumer_offsets-19 broker=3] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,902] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,902] INFO [Partition __consumer_offsets-28 broker=3] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,917] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:41:33,917] INFO [Partition __consumer_offsets-16 broker=3] __consumer_offsets-16 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,917] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,917] INFO [Partition __consumer_offsets-25 broker=3] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,933] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,933] INFO [Partition __consumer_offsets-22 broker=3] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,949] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:41:33,949] INFO [Partition __consumer_offsets-13 broker=3] __consumer_offsets-13 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:41:33,949] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,949] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-27 16:41:33,964] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,964] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-27 16:41:33,964] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,964] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,980] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-27 16:41:33,980] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,980] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-27 16:41:33,980] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,996] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-27 16:41:33,996] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:41:33,996] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON-2, toolsEvents-1, globalTableHoldON-1, toolsEvents-2, aggregateddata-1, aggregateddata-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:34,027] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:41:34,042] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(toolsEvents-2 -> (offset=4, leaderEpoch=1), aggregateddata-1 -> (offset=3, leaderEpoch=1), globalTableHoldON-2 -> (offset=7, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:34,042] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(globalTableHoldON-1 -> (offset=8, leaderEpoch=1), toolsEvents-1 -> (offset=6, leaderEpoch=1), aggregateddata-0 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:34,042] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:41:34,058] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,058] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,058] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,058] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:41:34,074] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,074] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:41:34,074] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-01-27 16:41:34,089] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-27 16:41:34,074] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,089] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-27 16:41:34,089] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-27 16:41:34,089] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-22 in 31 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,105] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs3] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-27 16:41:34,089] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,105] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,105] INFO [Partition toolsEvents-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-27 16:41:34,105] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,105] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,121] INFO [Partition aggregateddata-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-27 16:41:34,121] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,121] INFO [Partition globalTableHoldON-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-27 16:41:34,121] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,121] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,136] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,136] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,136] INFO [Partition globalTableHoldON-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-27 16:41:34,136] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,136] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,136] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,152] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,152] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,152] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,152] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,167] INFO [Partition toolsEvents-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-27 16:41:34,152] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,167] INFO [Partition aggregateddata-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-27 16:41:34,167] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,167] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,167] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,167] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,167] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,167] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,183] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,199] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,199] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:41:34,199] INFO [Partition __consumer_offsets-10 broker=3] __consumer_offsets-10 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,214] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,214] INFO [Partition __consumer_offsets-7 broker=3] __consumer_offsets-7 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,214] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,230] INFO [Partition __consumer_offsets-4 broker=3] __consumer_offsets-4 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,230] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,230] INFO [Partition __consumer_offsets-1 broker=3] __consumer_offsets-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,230] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,230] INFO [Partition __consumer_offsets-49 broker=3] __consumer_offsets-49 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,246] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,246] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-13 in 47 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,246] INFO [Partition __consumer_offsets-46 broker=3] __consumer_offsets-46 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,246] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,261] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-16 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,261] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:41:34,261] INFO [Partition __consumer_offsets-43 broker=3] __consumer_offsets-43 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,261] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,261] INFO [Partition __consumer_offsets-40 broker=3] __consumer_offsets-40 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,261] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,277] INFO [Partition __consumer_offsets-37 broker=3] __consumer_offsets-37 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,277] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,292] INFO [Partition __consumer_offsets-34 broker=3] __consumer_offsets-34 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,292] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,292] INFO [Partition __consumer_offsets-31 broker=3] __consumer_offsets-31 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,292] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,308] INFO [Partition __consumer_offsets-19 broker=3] __consumer_offsets-19 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,308] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,324] INFO [Partition __consumer_offsets-28 broker=3] __consumer_offsets-28 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,324] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,324] INFO [Partition __consumer_offsets-25 broker=3] __consumer_offsets-25 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,324] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,339] INFO [Partition __consumer_offsets-16 broker=3] __consumer_offsets-16 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,339] INFO [Partition __consumer_offsets-22 broker=3] __consumer_offsets-22 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:41:34,339] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 16:41:34,355] INFO [Partition __consumer_offsets-13 broker=3] __consumer_offsets-13 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 16:43:18,266] INFO Accepted socket connection from /127.0.0.1:51524 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:43:18,266] INFO Client attempting to establish new session at /127.0.0.1:51524 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:43:18,266] INFO Established session 0x100018d4b890003 with negotiated timeout 30000 for client /127.0.0.1:51524 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:43:18,610] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890003 type:setData cxid:0x6 zxid:0x163 txntype:-1 reqpath:n/a Error Path:/config/topics/globalTableHoldON1 Error:KeeperErrorCode = NoNode for /config/topics/globalTableHoldON1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:43:18,657] INFO Processed session termination for sessionid: 0x100018d4b890003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:43:18,657] INFO Closed socket connection for client /127.0.0.1:51524 which had sessionid 0x100018d4b890003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 16:43:18,672] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,672] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,672] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,688] INFO [Log partition=globalTableHoldON1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:18,688] INFO [Log partition=globalTableHoldON1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:18,688] INFO [Log partition=globalTableHoldON1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:43:18,688] INFO [Log partition=globalTableHoldON1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:18,688] INFO Created log for partition globalTableHoldON1-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:18,704] INFO [Log partition=globalTableHoldON1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:43:18,704] INFO [Log partition=globalTableHoldON1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:43:18,704] INFO [Partition globalTableHoldON1-1 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON1-1 (kafka.cluster.Partition)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,704] INFO [Partition globalTableHoldON1-1 broker=1] globalTableHoldON1-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:43:18,704] INFO Created log for partition globalTableHoldON1-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:18,704] INFO Created log for partition globalTableHoldON1-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:18,704] INFO [Partition globalTableHoldON1-0 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON1-0 (kafka.cluster.Partition)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,704] INFO [Partition globalTableHoldON1-2 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON1-2 (kafka.cluster.Partition)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,704] INFO [Partition globalTableHoldON1-0 broker=3] globalTableHoldON1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,704] INFO [Partition globalTableHoldON1-2 broker=2] globalTableHoldON1-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,704] INFO Replica loaded for partition globalTableHoldON1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,719] INFO Replica loaded for partition globalTableHoldON1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,719] INFO [Log partition=globalTableHoldON1-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:18,719] INFO [Log partition=globalTableHoldON1-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:43:18,719] INFO [Log partition=globalTableHoldON1-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:18,719] INFO Created log for partition globalTableHoldON1-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:18,719] INFO [Partition globalTableHoldON1-0 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON1-0 (kafka.cluster.Partition)
[2019-01-27 16:43:18,719] INFO Replica loaded for partition globalTableHoldON1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,719] INFO [Log partition=globalTableHoldON1-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:18,719] INFO [Log partition=globalTableHoldON1-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:43:18,719] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,719] INFO Created log for partition globalTableHoldON1-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:18,719] INFO [Partition globalTableHoldON1-1 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON1-1 (kafka.cluster.Partition)
[2019-01-27 16:43:18,719] INFO Replica loaded for partition globalTableHoldON1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,719] INFO [Log partition=globalTableHoldON1-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:43:18,719] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,735] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(globalTableHoldON1-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,735] INFO Created log for partition globalTableHoldON1-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:18,735] INFO [Partition globalTableHoldON1-2 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON1-2 (kafka.cluster.Partition)
[2019-01-27 16:43:18,735] INFO Replica loaded for partition globalTableHoldON1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:18,735] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,735] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(globalTableHoldON1-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,750] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:18,750] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(globalTableHoldON1-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:18,766] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:18,766] INFO [Log partition=globalTableHoldON1-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:43:18,922] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:18,922] INFO [Log partition=globalTableHoldON1-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:43:18,969] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:18,969] INFO [Log partition=globalTableHoldON1-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:43:42,730] INFO Accepted socket connection from /127.0.0.1:51532 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:43:42,730] INFO Client attempting to establish new session at /127.0.0.1:51532 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:43:42,730] INFO Established session 0x100018d4b890004 with negotiated timeout 30000 for client /127.0.0.1:51532 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:43:43,074] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890004 type:setData cxid:0x6 zxid:0x16f txntype:-1 reqpath:n/a Error Path:/config/topics/toolsEvents1 Error:KeeperErrorCode = NoNode for /config/topics/toolsEvents1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:43:43,137] INFO Processed session termination for sessionid: 0x100018d4b890004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:43:43,137] INFO Closed socket connection for client /127.0.0.1:51532 which had sessionid 0x100018d4b890004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 16:43:43,137] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,137] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,137] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,152] INFO [Log partition=toolsEvents1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:43,152] INFO [Log partition=toolsEvents1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:43,152] INFO [Log partition=toolsEvents1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:43,152] INFO [Log partition=toolsEvents1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:43:43,152] INFO [Log partition=toolsEvents1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:43:43,152] INFO [Log partition=toolsEvents1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:43:43,152] INFO Created log for partition toolsEvents1-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:43,152] INFO Created log for partition toolsEvents1-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:43,152] INFO Created log for partition toolsEvents1-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:43,152] INFO [Partition toolsEvents1-0 broker=2] No checkpointed highwatermark is found for partition toolsEvents1-0 (kafka.cluster.Partition)
[2019-01-27 16:43:43,152] INFO [Partition toolsEvents1-2 broker=1] No checkpointed highwatermark is found for partition toolsEvents1-2 (kafka.cluster.Partition)
[2019-01-27 16:43:43,152] INFO [Partition toolsEvents1-1 broker=3] No checkpointed highwatermark is found for partition toolsEvents1-1 (kafka.cluster.Partition)
[2019-01-27 16:43:43,152] INFO Replica loaded for partition toolsEvents1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,152] INFO Replica loaded for partition toolsEvents1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,152] INFO Replica loaded for partition toolsEvents1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,152] INFO Replica loaded for partition toolsEvents1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,152] INFO Replica loaded for partition toolsEvents1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,152] INFO Replica loaded for partition toolsEvents1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,152] INFO [Partition toolsEvents1-0 broker=2] toolsEvents1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:43:43,152] INFO [Partition toolsEvents1-2 broker=1] toolsEvents1-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:43:43,168] INFO [Partition toolsEvents1-1 broker=3] toolsEvents1-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:43:43,168] INFO Replica loaded for partition toolsEvents1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,168] INFO Replica loaded for partition toolsEvents1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,168] INFO Replica loaded for partition toolsEvents1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,168] INFO [Log partition=toolsEvents1-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:43,168] INFO [Log partition=toolsEvents1-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:43,168] INFO [Log partition=toolsEvents1-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:43:43,168] INFO [Log partition=toolsEvents1-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:43:43,168] INFO [Log partition=toolsEvents1-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:43:43,183] INFO [Log partition=toolsEvents1-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:43:43,183] INFO Created log for partition toolsEvents1-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:43,183] INFO Created log for partition toolsEvents1-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:43,183] INFO Created log for partition toolsEvents1-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:43:43,183] INFO [Partition toolsEvents1-2 broker=3] No checkpointed highwatermark is found for partition toolsEvents1-2 (kafka.cluster.Partition)
[2019-01-27 16:43:43,183] INFO [Partition toolsEvents1-0 broker=1] No checkpointed highwatermark is found for partition toolsEvents1-0 (kafka.cluster.Partition)
[2019-01-27 16:43:43,183] INFO Replica loaded for partition toolsEvents1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,183] INFO Replica loaded for partition toolsEvents1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(toolsEvents1-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,183] INFO [Partition toolsEvents1-1 broker=2] No checkpointed highwatermark is found for partition toolsEvents1-1 (kafka.cluster.Partition)
[2019-01-27 16:43:43,183] INFO Replica loaded for partition toolsEvents1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(toolsEvents1-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:43,183] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(toolsEvents1-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:43:43,183] INFO [Log partition=toolsEvents1-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:43:43,183] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:43,199] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:43,199] INFO [Log partition=toolsEvents1-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:43:43,528] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:43:43,528] INFO [Log partition=toolsEvents1-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:44:06,331] INFO Accepted socket connection from /127.0.0.1:51542 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:44:06,331] INFO Client attempting to establish new session at /127.0.0.1:51542 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:44:06,331] INFO Established session 0x100018d4b890005 with negotiated timeout 30000 for client /127.0.0.1:51542 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:44:06,659] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890005 type:setData cxid:0x6 zxid:0x17b txntype:-1 reqpath:n/a Error Path:/config/topics/aggregateddata1 Error:KeeperErrorCode = NoNode for /config/topics/aggregateddata1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:44:06,722] INFO Processed session termination for sessionid: 0x100018d4b890005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:44:06,722] INFO Closed socket connection for client /127.0.0.1:51542 which had sessionid 0x100018d4b890005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 16:44:06,722] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,722] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,722] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,737] INFO [Log partition=aggregateddata1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:44:06,737] INFO [Log partition=aggregateddata1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:44:06,737] INFO [Log partition=aggregateddata1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:44:06,737] INFO [Log partition=aggregateddata1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:44:06,737] INFO [Log partition=aggregateddata1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:44:06,737] INFO [Log partition=aggregateddata1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:44:06,737] INFO Created log for partition aggregateddata1-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:44:06,737] INFO Created log for partition aggregateddata1-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:44:06,737] INFO Created log for partition aggregateddata1-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:44:06,737] INFO [Partition aggregateddata1-1 broker=1] No checkpointed highwatermark is found for partition aggregateddata1-1 (kafka.cluster.Partition)
[2019-01-27 16:44:06,737] INFO [Partition aggregateddata1-0 broker=3] No checkpointed highwatermark is found for partition aggregateddata1-0 (kafka.cluster.Partition)
[2019-01-27 16:44:06,737] INFO [Partition aggregateddata1-2 broker=2] No checkpointed highwatermark is found for partition aggregateddata1-2 (kafka.cluster.Partition)
[2019-01-27 16:44:06,737] INFO Replica loaded for partition aggregateddata1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,737] INFO Replica loaded for partition aggregateddata1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,737] INFO Replica loaded for partition aggregateddata1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,737] INFO Replica loaded for partition aggregateddata1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,737] INFO Replica loaded for partition aggregateddata1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,737] INFO Replica loaded for partition aggregateddata1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,753] INFO [Partition aggregateddata1-1 broker=1] aggregateddata1-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:44:06,753] INFO [Partition aggregateddata1-0 broker=3] aggregateddata1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:44:06,753] INFO [Partition aggregateddata1-2 broker=2] aggregateddata1-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:44:06,753] INFO Replica loaded for partition aggregateddata1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,753] INFO Replica loaded for partition aggregateddata1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,753] INFO Replica loaded for partition aggregateddata1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,753] INFO [Log partition=aggregateddata1-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:44:06,753] INFO [Log partition=aggregateddata1-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:44:06,768] INFO [Log partition=aggregateddata1-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:44:06,768] INFO [Log partition=aggregateddata1-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:44:06,768] INFO [Log partition=aggregateddata1-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:44:06,768] INFO [Log partition=aggregateddata1-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:44:06,768] INFO Created log for partition aggregateddata1-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:44:06,768] INFO Created log for partition aggregateddata1-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:44:06,768] INFO Created log for partition aggregateddata1-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:44:06,768] INFO [Partition aggregateddata1-1 broker=2] No checkpointed highwatermark is found for partition aggregateddata1-1 (kafka.cluster.Partition)
[2019-01-27 16:44:06,768] INFO [Partition aggregateddata1-0 broker=1] No checkpointed highwatermark is found for partition aggregateddata1-0 (kafka.cluster.Partition)
[2019-01-27 16:44:06,768] INFO [Partition aggregateddata1-2 broker=3] No checkpointed highwatermark is found for partition aggregateddata1-2 (kafka.cluster.Partition)
[2019-01-27 16:44:06,768] INFO Replica loaded for partition aggregateddata1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,768] INFO Replica loaded for partition aggregateddata1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,768] INFO Replica loaded for partition aggregateddata1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:44:06,768] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,768] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,768] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata1-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,768] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(aggregateddata1-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,768] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(aggregateddata1-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,768] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(aggregateddata1-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:44:06,831] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:44:06,831] INFO [Log partition=aggregateddata1-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:44:06,847] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:44:06,847] INFO [Log partition=aggregateddata1-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:44:06,909] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:44:06,909] INFO [Log partition=aggregateddata1-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:44:39,766] INFO [GroupCoordinator 1]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 2 (__consumer_offsets-35) (reason: Adding new member consumer-1-cb58c684-8d6d-4f81-802a-00198cd36913) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:44:39,766] INFO [GroupCoordinator 1]: Stabilized group connect-test-sink generation 3 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:44:39,782] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-test-sink for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:45:48,162] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-50747 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-1-a0a9434b-64ff-4a0e-8b74-50ea0dbf15c8) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:45:48,178] INFO [GroupCoordinator 3]: Stabilized group console-consumer-50747 generation 1 (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:45:48,178] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-50747 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:45:54,806] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:45:54,806] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents-2, aggregateddata-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:45:54,822] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata-1, toolsEvents-2, globalTableHoldON-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:45:54,822] INFO [Partition aggregateddata-1 broker=3] aggregateddata-1 starts at Leader Epoch 2 from offset 3. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-27 16:45:54,822] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(toolsEvents-2 -> (offset=4, leaderEpoch=2), aggregateddata-1 -> (offset=3, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:45:54,822] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(globalTableHoldON-1 -> (offset=8, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:45:54,822] INFO [Partition toolsEvents-2 broker=3] toolsEvents-2 starts at Leader Epoch 2 from offset 4. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-27 16:45:54,822] INFO [Partition globalTableHoldON-1 broker=3] globalTableHoldON-1 starts at Leader Epoch 2 from offset 8. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-27 16:45:55,088] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-27 16:45:55,088] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-27 16:45:55,088] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-27 16:46:17,238] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-47090 in state PreparingRebalance with old generation 0 (__consumer_offsets-41) (reason: Adding new member consumer-1-5b8a0f30-cab1-43f8-a87e-fece72c2d74a) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:46:17,238] INFO [GroupCoordinator 1]: Stabilized group console-consumer-47090 generation 1 (__consumer_offsets-41) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:46:17,238] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-47090 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:50:49,394] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:51:17,599] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:51:33,548] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 16:52:31,244] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-24118 in state PreparingRebalance with old generation 0 (__consumer_offsets-47) (reason: Adding new member consumer-1-b3fa28f4-de46-4fda-aa4a-dad651549de3) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:52:31,244] INFO [GroupCoordinator 1]: Stabilized group console-consumer-24118 generation 1 (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:52:31,244] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-24118 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:54:25,931] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-f13ecc9f-f697-4439-aa83-7a4daf10caf0-StreamThread-1-consumer-6ebed005-e06e-4fb4-8896-9da7b7d38d5e) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:54:25,931] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 3 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:54:25,947] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:15,097] INFO [GroupCoordinator 1]: Member alltoolsStream-f13ecc9f-f697-4439-aa83-7a4daf10caf0-StreamThread-1-consumer-6ebed005-e06e-4fb4-8896-9da7b7d38d5e in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:15,097] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: removing member alltoolsStream-f13ecc9f-f697-4439-aa83-7a4daf10caf0-StreamThread-1-consumer-6ebed005-e06e-4fb4-8896-9da7b7d38d5e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:15,097] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 4 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:24,703] INFO [GroupCoordinator 3]: Member consumer-1-a0a9434b-64ff-4a0e-8b74-50ea0dbf15c8 in group console-consumer-50747 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:24,703] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-50747 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: removing member consumer-1-a0a9434b-64ff-4a0e-8b74-50ea0dbf15c8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:24,703] INFO [GroupCoordinator 3]: Group console-consumer-50747 with generation 2 is now empty (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:35,951] INFO [GroupCoordinator 1]: Member consumer-1-b3fa28f4-de46-4fda-aa4a-dad651549de3 in group console-consumer-24118 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:35,951] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-24118 in state PreparingRebalance with old generation 1 (__consumer_offsets-47) (reason: removing member consumer-1-b3fa28f4-de46-4fda-aa4a-dad651549de3 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:55:35,951] INFO [GroupCoordinator 1]: Group console-consumer-24118 with generation 2 is now empty (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 16:57:28,028] INFO Accepted socket connection from /127.0.0.1:51652 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:57:28,043] INFO Client attempting to establish new session at /127.0.0.1:51652 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:57:28,043] INFO Established session 0x100018d4b890006 with negotiated timeout 30000 for client /127.0.0.1:51652 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:57:28,371] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890006 type:setData cxid:0x6 zxid:0x18a txntype:-1 reqpath:n/a Error Path:/config/topics/toolsEvents2 Error:KeeperErrorCode = NoNode for /config/topics/toolsEvents2 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:57:28,418] INFO Processed session termination for sessionid: 0x100018d4b890006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:57:28,434] INFO Closed socket connection for client /127.0.0.1:51652 which had sessionid 0x100018d4b890006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 16:57:28,434] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents2-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,434] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,434] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents2-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,449] INFO [Log partition=toolsEvents2-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:28,449] INFO [Log partition=toolsEvents2-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:28,449] INFO [Log partition=toolsEvents2-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:28,449] INFO [Log partition=toolsEvents2-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:57:28,449] INFO [Log partition=toolsEvents2-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:57:28,449] INFO [Log partition=toolsEvents2-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 16:57:28,449] INFO Created log for partition toolsEvents2-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:28,449] INFO Created log for partition toolsEvents2-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:28,449] INFO [Partition toolsEvents2-0 broker=3] No checkpointed highwatermark is found for partition toolsEvents2-0 (kafka.cluster.Partition)
[2019-01-27 16:57:28,449] INFO Created log for partition toolsEvents2-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:28,449] INFO [Partition toolsEvents2-1 broker=1] No checkpointed highwatermark is found for partition toolsEvents2-1 (kafka.cluster.Partition)
[2019-01-27 16:57:28,449] INFO Replica loaded for partition toolsEvents2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,449] INFO [Partition toolsEvents2-2 broker=2] No checkpointed highwatermark is found for partition toolsEvents2-2 (kafka.cluster.Partition)
[2019-01-27 16:57:28,449] INFO Replica loaded for partition toolsEvents2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,449] INFO Replica loaded for partition toolsEvents2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,449] INFO Replica loaded for partition toolsEvents2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,449] INFO Replica loaded for partition toolsEvents2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,449] INFO [Partition toolsEvents2-0 broker=3] toolsEvents2-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:57:28,449] INFO Replica loaded for partition toolsEvents2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,449] INFO [Partition toolsEvents2-1 broker=1] toolsEvents2-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:57:28,449] INFO [Partition toolsEvents2-2 broker=2] toolsEvents2-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:57:28,465] INFO Replica loaded for partition toolsEvents2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,465] INFO Replica loaded for partition toolsEvents2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,465] INFO Replica loaded for partition toolsEvents2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,465] INFO [Log partition=toolsEvents2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:28,465] INFO [Log partition=toolsEvents2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:28,465] INFO [Log partition=toolsEvents2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:57:28,465] INFO [Log partition=toolsEvents2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:28,465] INFO Created log for partition toolsEvents2-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:28,465] INFO [Log partition=toolsEvents2-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:57:28,465] INFO [Partition toolsEvents2-1 broker=3] No checkpointed highwatermark is found for partition toolsEvents2-1 (kafka.cluster.Partition)
[2019-01-27 16:57:28,465] INFO Replica loaded for partition toolsEvents2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,465] INFO Created log for partition toolsEvents2-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:28,465] INFO [Log partition=toolsEvents2-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:57:28,465] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents2-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,465] INFO [Partition toolsEvents2-2 broker=1] No checkpointed highwatermark is found for partition toolsEvents2-2 (kafka.cluster.Partition)
[2019-01-27 16:57:28,481] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(toolsEvents2-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,481] INFO Created log for partition toolsEvents2-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:28,481] INFO Replica loaded for partition toolsEvents2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,481] INFO [Partition toolsEvents2-0 broker=2] No checkpointed highwatermark is found for partition toolsEvents2-0 (kafka.cluster.Partition)
[2019-01-27 16:57:28,481] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents2-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,481] INFO Replica loaded for partition toolsEvents2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:28,481] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(toolsEvents2-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,481] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,481] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(toolsEvents2-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:28,652] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents2-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:57:28,652] INFO [Log partition=toolsEvents2-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:57:28,871] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:57:28,871] INFO [Log partition=toolsEvents2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:57:28,887] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents2-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:57:28,887] INFO [Log partition=toolsEvents2-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:57:41,694] INFO Accepted socket connection from /127.0.0.1:51660 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 16:57:41,710] INFO Client attempting to establish new session at /127.0.0.1:51660 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:57:41,710] INFO Established session 0x100018d4b890007 with negotiated timeout 30000 for client /127.0.0.1:51660 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 16:57:42,053] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890007 type:setData cxid:0x6 zxid:0x196 txntype:-1 reqpath:n/a Error Path:/config/topics/globalTableHoldON2 Error:KeeperErrorCode = NoNode for /config/topics/globalTableHoldON2 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:57:42,100] INFO Processed session termination for sessionid: 0x100018d4b890007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 16:57:42,116] INFO Closed socket connection for client /127.0.0.1:51660 which had sessionid 0x100018d4b890007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 16:57:42,116] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON2-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,116] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON2-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,116] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,132] INFO [Log partition=globalTableHoldON2-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:42,132] INFO [Log partition=globalTableHoldON2-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:42,132] INFO [Log partition=globalTableHoldON2-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:42,132] INFO [Log partition=globalTableHoldON2-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:57:42,132] INFO [Log partition=globalTableHoldON2-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:57:42,132] INFO [Log partition=globalTableHoldON2-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:57:42,132] INFO Created log for partition globalTableHoldON2-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:42,132] INFO Created log for partition globalTableHoldON2-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:42,132] INFO Created log for partition globalTableHoldON2-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:42,132] INFO [Partition globalTableHoldON2-1 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON2-1 (kafka.cluster.Partition)
[2019-01-27 16:57:42,132] INFO [Partition globalTableHoldON2-2 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON2-2 (kafka.cluster.Partition)
[2019-01-27 16:57:42,132] INFO [Partition globalTableHoldON2-0 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON2-0 (kafka.cluster.Partition)
[2019-01-27 16:57:42,132] INFO Replica loaded for partition globalTableHoldON2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,132] INFO Replica loaded for partition globalTableHoldON2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,132] INFO Replica loaded for partition globalTableHoldON2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,132] INFO Replica loaded for partition globalTableHoldON2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,132] INFO Replica loaded for partition globalTableHoldON2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,132] INFO Replica loaded for partition globalTableHoldON2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,132] INFO [Partition globalTableHoldON2-1 broker=1] globalTableHoldON2-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:57:42,132] INFO [Partition globalTableHoldON2-2 broker=2] globalTableHoldON2-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:57:42,132] INFO [Partition globalTableHoldON2-0 broker=3] globalTableHoldON2-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 16:57:42,147] INFO Replica loaded for partition globalTableHoldON2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,147] INFO Replica loaded for partition globalTableHoldON2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,147] INFO Replica loaded for partition globalTableHoldON2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,147] INFO [Log partition=globalTableHoldON2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:42,147] INFO [Log partition=globalTableHoldON2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:42,147] INFO [Log partition=globalTableHoldON2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 16:57:42,147] INFO [Log partition=globalTableHoldON2-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 16:57:42,163] INFO [Log partition=globalTableHoldON2-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:57:42,163] INFO Created log for partition globalTableHoldON2-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:42,163] INFO [Log partition=globalTableHoldON2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 16:57:42,163] INFO [Partition globalTableHoldON2-0 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON2-0 (kafka.cluster.Partition)
[2019-01-27 16:57:42,163] INFO Created log for partition globalTableHoldON2-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:42,163] INFO Replica loaded for partition globalTableHoldON2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,163] INFO [Partition globalTableHoldON2-1 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON2-1 (kafka.cluster.Partition)
[2019-01-27 16:57:42,163] INFO Created log for partition globalTableHoldON2-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 16:57:42,163] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,163] INFO Replica loaded for partition globalTableHoldON2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,163] INFO [Partition globalTableHoldON2-2 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON2-2 (kafka.cluster.Partition)
[2019-01-27 16:57:42,163] INFO Replica loaded for partition globalTableHoldON2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 16:57:42,163] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(globalTableHoldON2-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,163] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON2-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,163] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(globalTableHoldON2-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,163] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON2-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,163] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(globalTableHoldON2-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 16:57:42,194] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:57:42,194] INFO [Log partition=globalTableHoldON2-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:57:42,241] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON2-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:57:42,241] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON2-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 16:57:42,241] INFO [Log partition=globalTableHoldON2-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 16:57:42,241] INFO [Log partition=globalTableHoldON2-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:00:49,393] INFO [GroupMetadataManager brokerId=1] Group console-consumer-24118 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:00:49,393] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:01:17,606] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:01:25,274] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 4 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-4a4758d2-3261-4046-a326-d0c5eb37d7ed-StreamThread-1-consumer-7b42fe47-728d-400e-ad13-8ab9621b2f11) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:01:25,274] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 5 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:01:25,290] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:01:33,538] INFO [GroupMetadataManager brokerId=3] Group console-consumer-50747 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:01:33,538] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:01:46,535] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-72452 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member consumer-1-a77a2d87-8801-48de-947a-1df7c873ecbd) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:01:46,551] INFO [GroupCoordinator 2]: Stabilized group console-consumer-72452 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:01:46,551] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-72452 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:04:17,981] INFO [GroupCoordinator 1]: Member alltoolsStream-4a4758d2-3261-4046-a326-d0c5eb37d7ed-StreamThread-1-consumer-7b42fe47-728d-400e-ad13-8ab9621b2f11 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:04:17,981] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 5 (__consumer_offsets-2) (reason: removing member alltoolsStream-4a4758d2-3261-4046-a326-d0c5eb37d7ed-StreamThread-1-consumer-7b42fe47-728d-400e-ad13-8ab9621b2f11 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:04:17,981] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 6 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:10:49,403] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:11:17,600] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:11:33,549] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:14:42,988] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 6 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-b31466a9-478b-4e54-b107-4dd79efcf390-StreamThread-1-consumer-47481431-85c8-40fc-92f8-75208dea18c8) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:14:42,988] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 7 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:14:42,988] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:15:25,755] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-91558 in state PreparingRebalance with old generation 0 (__consumer_offsets-39) (reason: Adding new member consumer-1-2c78ec65-043d-4119-ac0d-fa44451fdc11) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:15:25,755] INFO [GroupCoordinator 2]: Stabilized group console-consumer-91558 generation 1 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:15:25,755] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-91558 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:20:49,392] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:21:17,603] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:21:33,549] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:22:51,569] INFO [GroupCoordinator 1]: Member alltoolsStream-b31466a9-478b-4e54-b107-4dd79efcf390-StreamThread-1-consumer-47481431-85c8-40fc-92f8-75208dea18c8 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:22:51,569] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 7 (__consumer_offsets-2) (reason: removing member alltoolsStream-b31466a9-478b-4e54-b107-4dd79efcf390-StreamThread-1-consumer-47481431-85c8-40fc-92f8-75208dea18c8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:22:51,569] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 8 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:30:49,390] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:31:17,600] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:31:33,540] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:32:08,607] INFO [GroupCoordinator 2]: Member consumer-1-a77a2d87-8801-48de-947a-1df7c873ecbd in group console-consumer-72452 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:08,607] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-72452 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: removing member consumer-1-a77a2d87-8801-48de-947a-1df7c873ecbd on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:08,607] INFO [GroupCoordinator 2]: Group console-consumer-72452 with generation 2 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:16,181] INFO [GroupCoordinator 1]: Member consumer-1-5b8a0f30-cab1-43f8-a87e-fece72c2d74a in group console-consumer-47090 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:16,181] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-47090 in state PreparingRebalance with old generation 1 (__consumer_offsets-41) (reason: removing member consumer-1-5b8a0f30-cab1-43f8-a87e-fece72c2d74a on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:16,181] INFO [GroupCoordinator 1]: Group console-consumer-47090 with generation 2 is now empty (__consumer_offsets-41) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:23,071] INFO [GroupCoordinator 2]: Member consumer-1-2c78ec65-043d-4119-ac0d-fa44451fdc11 in group console-consumer-91558 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:23,071] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-91558 in state PreparingRebalance with old generation 1 (__consumer_offsets-39) (reason: removing member consumer-1-2c78ec65-043d-4119-ac0d-fa44451fdc11 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:32:23,071] INFO [GroupCoordinator 2]: Group console-consumer-91558 with generation 2 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:33:26,030] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51945 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 17:33:26,030] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51945 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 17:33:26,045] INFO Established session 0x100018d4b890008 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:51945 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 17:33:26,374] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890008 type:setData cxid:0x6 zxid:0x1a2 txntype:-1 reqpath:n/a Error Path:/config/topics/toolsEvents3 Error:KeeperErrorCode = NoNode for /config/topics/toolsEvents3 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 17:33:26,426] INFO Processed session termination for sessionid: 0x100018d4b890008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 17:33:26,426] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51945 which had sessionid 0x100018d4b890008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 17:33:26,441] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,441] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,441] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,457] INFO [Log partition=toolsEvents3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:26,457] INFO [Log partition=toolsEvents3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:26,457] INFO [Log partition=toolsEvents3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:26,457] INFO [Log partition=toolsEvents3-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:33:26,457] INFO [Log partition=toolsEvents3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:33:26,457] INFO Created log for partition toolsEvents3-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:26,457] INFO Created log for partition toolsEvents3-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:26,457] INFO [Log partition=toolsEvents3-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:33:26,457] INFO [Partition toolsEvents3-0 broker=2] No checkpointed highwatermark is found for partition toolsEvents3-0 (kafka.cluster.Partition)
[2019-01-27 17:33:26,457] INFO Replica loaded for partition toolsEvents3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,457] INFO [Partition toolsEvents3-1 broker=3] No checkpointed highwatermark is found for partition toolsEvents3-1 (kafka.cluster.Partition)
[2019-01-27 17:33:26,457] INFO Replica loaded for partition toolsEvents3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,457] INFO Replica loaded for partition toolsEvents3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,457] INFO Created log for partition toolsEvents3-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:26,457] INFO Replica loaded for partition toolsEvents3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,457] INFO [Partition toolsEvents3-2 broker=1] No checkpointed highwatermark is found for partition toolsEvents3-2 (kafka.cluster.Partition)
[2019-01-27 17:33:26,457] INFO [Partition toolsEvents3-0 broker=2] toolsEvents3-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:33:26,457] INFO [Partition toolsEvents3-1 broker=3] toolsEvents3-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:33:26,457] INFO Replica loaded for partition toolsEvents3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,473] INFO Replica loaded for partition toolsEvents3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,473] INFO [Partition toolsEvents3-2 broker=1] toolsEvents3-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:33:26,473] INFO Replica loaded for partition toolsEvents3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,473] INFO Replica loaded for partition toolsEvents3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,473] INFO Replica loaded for partition toolsEvents3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,473] INFO [Log partition=toolsEvents3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:26,473] INFO [Log partition=toolsEvents3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:26,473] INFO [Log partition=toolsEvents3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:26,473] INFO [Log partition=toolsEvents3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:33:26,473] INFO [Log partition=toolsEvents3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:33:26,473] INFO Created log for partition toolsEvents3-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:26,488] INFO [Log partition=toolsEvents3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 17:33:26,488] INFO Created log for partition toolsEvents3-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:26,488] INFO [Partition toolsEvents3-2 broker=3] No checkpointed highwatermark is found for partition toolsEvents3-2 (kafka.cluster.Partition)
[2019-01-27 17:33:26,488] INFO [Partition toolsEvents3-1 broker=2] No checkpointed highwatermark is found for partition toolsEvents3-1 (kafka.cluster.Partition)
[2019-01-27 17:33:26,488] INFO Created log for partition toolsEvents3-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:26,488] INFO Replica loaded for partition toolsEvents3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,488] INFO Replica loaded for partition toolsEvents3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,488] INFO [Partition toolsEvents3-0 broker=1] No checkpointed highwatermark is found for partition toolsEvents3-0 (kafka.cluster.Partition)
[2019-01-27 17:33:26,488] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,488] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,488] INFO Replica loaded for partition toolsEvents3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:26,495] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(toolsEvents3-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,495] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(toolsEvents3-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,495] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,495] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(toolsEvents3-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:26,573] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents3-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:33:26,573] INFO [Log partition=toolsEvents3-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:33:26,605] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:33:26,605] INFO [Log partition=toolsEvents3-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:33:26,687] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents3-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:33:26,687] INFO [Log partition=toolsEvents3-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:33:36,621] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51952 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 17:33:36,636] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51952 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 17:33:36,636] INFO Established session 0x100018d4b890009 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:51952 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 17:33:36,959] INFO Got user-level KeeperException when processing sessionid:0x100018d4b890009 type:setData cxid:0x6 zxid:0x1ae txntype:-1 reqpath:n/a Error Path:/config/topics/globalTableHoldON3 Error:KeeperErrorCode = NoNode for /config/topics/globalTableHoldON3 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 17:33:37,022] INFO Processed session termination for sessionid: 0x100018d4b890009 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 17:33:37,022] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51952 which had sessionid 0x100018d4b890009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 17:33:37,022] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,022] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,022] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,037] INFO [Log partition=globalTableHoldON3-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:37,037] INFO [Log partition=globalTableHoldON3-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:37,037] INFO [Log partition=globalTableHoldON3-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:37,037] INFO [Log partition=globalTableHoldON3-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 17:33:37,037] INFO [Log partition=globalTableHoldON3-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 17:33:37,037] INFO Created log for partition globalTableHoldON3-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:37,037] INFO Created log for partition globalTableHoldON3-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:37,037] INFO [Partition globalTableHoldON3-1 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON3-1 (kafka.cluster.Partition)
[2019-01-27 17:33:37,037] INFO [Log partition=globalTableHoldON3-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 17:33:37,037] INFO [Partition globalTableHoldON3-0 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON3-0 (kafka.cluster.Partition)
[2019-01-27 17:33:37,037] INFO Replica loaded for partition globalTableHoldON3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,037] INFO Replica loaded for partition globalTableHoldON3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,037] INFO Replica loaded for partition globalTableHoldON3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,037] INFO Created log for partition globalTableHoldON3-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:37,037] INFO Replica loaded for partition globalTableHoldON3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,037] INFO [Partition globalTableHoldON3-1 broker=1] globalTableHoldON3-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:33:37,037] INFO [Partition globalTableHoldON3-2 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON3-2 (kafka.cluster.Partition)
[2019-01-27 17:33:37,037] INFO [Partition globalTableHoldON3-0 broker=3] globalTableHoldON3-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:33:37,037] INFO Replica loaded for partition globalTableHoldON3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,037] INFO Replica loaded for partition globalTableHoldON3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,037] INFO [Partition globalTableHoldON3-2 broker=2] globalTableHoldON3-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:33:37,037] INFO Replica loaded for partition globalTableHoldON3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,053] INFO Replica loaded for partition globalTableHoldON3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,053] INFO Replica loaded for partition globalTableHoldON3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,060] INFO [Log partition=globalTableHoldON3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:37,060] INFO [Log partition=globalTableHoldON3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:37,060] INFO [Log partition=globalTableHoldON3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-27 17:33:37,060] INFO [Log partition=globalTableHoldON3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-27 17:33:37,060] INFO Created log for partition globalTableHoldON3-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:37,060] INFO Created log for partition globalTableHoldON3-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:37,060] INFO [Partition globalTableHoldON3-2 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON3-2 (kafka.cluster.Partition)
[2019-01-27 17:33:37,060] INFO [Partition globalTableHoldON3-1 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON3-1 (kafka.cluster.Partition)
[2019-01-27 17:33:37,060] INFO Replica loaded for partition globalTableHoldON3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,060] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,060] INFO Replica loaded for partition globalTableHoldON3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,060] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,060] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(globalTableHoldON3-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,060] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(globalTableHoldON3-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,060] INFO [Log partition=globalTableHoldON3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:33:37,075] INFO [Log partition=globalTableHoldON3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-27 17:33:37,075] INFO Created log for partition globalTableHoldON3-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:33:37,075] INFO [Partition globalTableHoldON3-0 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON3-0 (kafka.cluster.Partition)
[2019-01-27 17:33:37,075] INFO Replica loaded for partition globalTableHoldON3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:33:37,075] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,075] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(globalTableHoldON3-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:33:37,191] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:33:37,191] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON3-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:33:37,191] INFO [Log partition=globalTableHoldON3-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:33:37,191] INFO [Log partition=globalTableHoldON3-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:33:37,392] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON3-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:33:37,392] INFO [Log partition=globalTableHoldON3-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:33:54,464] INFO [GroupCoordinator 1]: Member consumer-1-cb58c684-8d6d-4f81-802a-00198cd36913 in group connect-test-sink has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:33:54,464] INFO [GroupCoordinator 1]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 3 (__consumer_offsets-35) (reason: removing member consumer-1-cb58c684-8d6d-4f81-802a-00198cd36913 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:33:54,464] INFO [GroupCoordinator 1]: Group connect-test-sink with generation 4 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:08,582] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51956 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-27 17:34:08,582] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51956 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 17:34:08,598] INFO Established session 0x100018d4b89000a with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:51956 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 17:34:08,914] INFO Got user-level KeeperException when processing sessionid:0x100018d4b89000a type:setData cxid:0x6 zxid:0x1ba txntype:-1 reqpath:n/a Error Path:/config/topics/aggregateddata3 Error:KeeperErrorCode = NoNode for /config/topics/aggregateddata3 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 17:34:08,968] INFO Processed session termination for sessionid: 0x100018d4b89000a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 17:34:08,968] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51956 which had sessionid 0x100018d4b89000a (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 17:34:08,983] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:08,983] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:08,983] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:08,983] INFO [Log partition=aggregateddata3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:34:08,983] INFO [Log partition=aggregateddata3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:34:08,983] INFO [Log partition=aggregateddata3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:34:08,999] INFO [Log partition=aggregateddata3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 17:34:08,999] INFO [Log partition=aggregateddata3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 17:34:08,999] INFO [Log partition=aggregateddata3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-27 17:34:08,999] INFO Created log for partition aggregateddata3-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:34:08,999] INFO Created log for partition aggregateddata3-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:34:08,999] INFO Created log for partition aggregateddata3-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:34:08,999] INFO [Partition aggregateddata3-0 broker=1] No checkpointed highwatermark is found for partition aggregateddata3-0 (kafka.cluster.Partition)
[2019-01-27 17:34:08,999] INFO [Partition aggregateddata3-1 broker=2] No checkpointed highwatermark is found for partition aggregateddata3-1 (kafka.cluster.Partition)
[2019-01-27 17:34:08,999] INFO [Partition aggregateddata3-2 broker=3] No checkpointed highwatermark is found for partition aggregateddata3-2 (kafka.cluster.Partition)
[2019-01-27 17:34:08,999] INFO Replica loaded for partition aggregateddata3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:08,999] INFO Replica loaded for partition aggregateddata3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:08,999] INFO Replica loaded for partition aggregateddata3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:08,999] INFO Replica loaded for partition aggregateddata3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:08,999] INFO Replica loaded for partition aggregateddata3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:08,999] INFO Replica loaded for partition aggregateddata3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:08,999] INFO [Partition aggregateddata3-0 broker=1] aggregateddata3-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:34:08,999] INFO [Partition aggregateddata3-1 broker=2] aggregateddata3-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:34:08,999] INFO [Partition aggregateddata3-2 broker=3] aggregateddata3-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-27 17:34:09,014] INFO Replica loaded for partition aggregateddata3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:09,014] INFO Replica loaded for partition aggregateddata3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:09,014] INFO Replica loaded for partition aggregateddata3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:09,014] INFO [Log partition=aggregateddata3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:34:09,014] INFO [Log partition=aggregateddata3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:34:09,014] INFO [Log partition=aggregateddata3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-27 17:34:09,014] INFO [Log partition=aggregateddata3-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:34:09,014] INFO [Log partition=aggregateddata3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:34:09,014] INFO [Log partition=aggregateddata3-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-27 17:34:09,014] INFO Created log for partition aggregateddata3-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:34:09,014] INFO Created log for partition aggregateddata3-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:34:09,030] INFO Created log for partition aggregateddata3-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-27 17:34:09,030] INFO [Partition aggregateddata3-0 broker=2] No checkpointed highwatermark is found for partition aggregateddata3-0 (kafka.cluster.Partition)
[2019-01-27 17:34:09,030] INFO [Partition aggregateddata3-1 broker=3] No checkpointed highwatermark is found for partition aggregateddata3-1 (kafka.cluster.Partition)
[2019-01-27 17:34:09,030] INFO [Partition aggregateddata3-2 broker=1] No checkpointed highwatermark is found for partition aggregateddata3-2 (kafka.cluster.Partition)
[2019-01-27 17:34:09,030] INFO Replica loaded for partition aggregateddata3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:09,030] INFO Replica loaded for partition aggregateddata3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:09,030] INFO Replica loaded for partition aggregateddata3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-27 17:34:09,030] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata3-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:09,030] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata3-0) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:09,030] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:09,030] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(aggregateddata3-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:09,030] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(aggregateddata3-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:09,030] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(aggregateddata3-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-27 17:34:09,162] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:34:09,162] INFO [Log partition=aggregateddata3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:34:09,463] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata3-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:34:09,463] INFO [Log partition=aggregateddata3-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:34:09,516] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata3-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-27 17:34:09,516] INFO [Log partition=aggregateddata3-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-27 17:34:20,335] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-15107 in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-143a73a8-105e-4255-9c27-6b68dd1b8506) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:20,335] INFO [GroupCoordinator 1]: Stabilized group console-consumer-15107 generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:20,335] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-15107 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:32,544] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-531 in state PreparingRebalance with old generation 0 (__consumer_offsets-20) (reason: Adding new member consumer-1-9176ae72-f3fb-4700-bdb5-9b38d449b840) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:32,544] INFO [GroupCoordinator 1]: Stabilized group console-consumer-531 generation 1 (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:32,544] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-531 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:52,738] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-67369 in state PreparingRebalance with old generation 0 (__consumer_offsets-32) (reason: Adding new member consumer-1-07772925-0f6e-4ae2-b473-c448b7ace67c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:52,738] INFO [GroupCoordinator 1]: Stabilized group console-consumer-67369 generation 1 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:34:52,754] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-67369 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:38:59,575] INFO [GroupCoordinator 1]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 4 (__consumer_offsets-35) (reason: Adding new member consumer-1-5761de40-f6c0-46e2-b19b-55cfc97d4e06) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:38:59,575] INFO [GroupCoordinator 1]: Stabilized group connect-test-sink generation 5 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:38:59,585] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-test-sink for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:39:13,957] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 8 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-c73285d0-803f-43f3-bd28-ae4f960113c9-StreamThread-1-consumer-0cb056c0-0804-4deb-8295-c456eb11699e) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:39:13,957] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 9 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:39:13,973] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:40:06,143] INFO [GroupCoordinator 1]: Member alltoolsStream-c73285d0-803f-43f3-bd28-ae4f960113c9-StreamThread-1-consumer-0cb056c0-0804-4deb-8295-c456eb11699e in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:40:06,143] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 9 (__consumer_offsets-2) (reason: removing member alltoolsStream-c73285d0-803f-43f3-bd28-ae4f960113c9-StreamThread-1-consumer-0cb056c0-0804-4deb-8295-c456eb11699e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:40:06,143] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 10 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:40:49,404] INFO [GroupMetadataManager brokerId=1] Group console-consumer-47090 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:40:49,404] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:41:17,603] INFO [GroupMetadataManager brokerId=2] Group console-consumer-72452 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:41:17,603] INFO [GroupMetadataManager brokerId=2] Group console-consumer-91558 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:41:17,603] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:41:33,553] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:41:50,385] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 10 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-129cbcca-b82f-427a-9087-c4b2613ce437-StreamThread-1-consumer-35977488-f78b-44c1-96e0-de2683b2ef59) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:41:50,385] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 11 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:41:50,385] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:42:21,462] INFO [GroupCoordinator 1]: Member alltoolsStream-129cbcca-b82f-427a-9087-c4b2613ce437-StreamThread-1-consumer-35977488-f78b-44c1-96e0-de2683b2ef59 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:42:21,462] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 11 (__consumer_offsets-2) (reason: removing member alltoolsStream-129cbcca-b82f-427a-9087-c4b2613ce437-StreamThread-1-consumer-35977488-f78b-44c1-96e0-de2683b2ef59 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:42:21,462] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 12 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:43:08,152] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 12 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-4bc4d417-8d5b-4ace-8da3-135bffca152f-StreamThread-1-consumer-b5f3c48d-3fd0-455a-9d7e-4131c2def31d) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:43:08,168] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 13 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:43:08,168] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 13 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:44:45,480] INFO [GroupCoordinator 1]: Member alltoolsStream-4bc4d417-8d5b-4ace-8da3-135bffca152f-StreamThread-1-consumer-b5f3c48d-3fd0-455a-9d7e-4131c2def31d in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:44:45,480] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 13 (__consumer_offsets-2) (reason: removing member alltoolsStream-4bc4d417-8d5b-4ace-8da3-135bffca152f-StreamThread-1-consumer-b5f3c48d-3fd0-455a-9d7e-4131c2def31d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:44:45,480] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 14 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:47:57,340] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 14 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-7eda3333-7d05-48d4-a8be-d8011b146f2a-StreamThread-1-consumer-93cf5572-3fc8-46a9-b6ba-f775657c5080) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:47:57,356] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 15 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:47:57,362] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 15 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:48:52,528] INFO [GroupCoordinator 1]: Member alltoolsStream-7eda3333-7d05-48d4-a8be-d8011b146f2a-StreamThread-1-consumer-93cf5572-3fc8-46a9-b6ba-f775657c5080 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:48:52,528] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 15 (__consumer_offsets-2) (reason: removing member alltoolsStream-7eda3333-7d05-48d4-a8be-d8011b146f2a-StreamThread-1-consumer-93cf5572-3fc8-46a9-b6ba-f775657c5080 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:48:52,528] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 16 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:50:49,393] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:51:17,603] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:51:33,536] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 17:56:54,195] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 16 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-629498b1-7195-471d-bb66-04c3e7693c5c-StreamThread-1-consumer-e516ce9a-e73b-44fa-bdb5-53fa6b7cbeee) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:56:54,195] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 17 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:56:54,201] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 17 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:57:22,271] INFO [GroupCoordinator 1]: Member alltoolsStream-629498b1-7195-471d-bb66-04c3e7693c5c-StreamThread-1-consumer-e516ce9a-e73b-44fa-bdb5-53fa6b7cbeee in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:57:22,271] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 17 (__consumer_offsets-2) (reason: removing member alltoolsStream-629498b1-7195-471d-bb66-04c3e7693c5c-StreamThread-1-consumer-e516ce9a-e73b-44fa-bdb5-53fa6b7cbeee on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 17:57:22,271] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 18 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:00:25,475] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 18 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-a9c0882e-3309-434b-ad90-28fe1e332ede-StreamThread-1-consumer-a0dcf131-c19c-4859-8835-48ce941e73d2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:00:25,475] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 19 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:00:25,490] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 19 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:00:49,399] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:01:17,614] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:01:33,554] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:02:41,956] INFO [GroupCoordinator 1]: Member alltoolsStream-a9c0882e-3309-434b-ad90-28fe1e332ede-StreamThread-1-consumer-a0dcf131-c19c-4859-8835-48ce941e73d2 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:02:41,956] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 19 (__consumer_offsets-2) (reason: removing member alltoolsStream-a9c0882e-3309-434b-ad90-28fe1e332ede-StreamThread-1-consumer-a0dcf131-c19c-4859-8835-48ce941e73d2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:02:41,956] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 20 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:07:15,387] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 20 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-6080c05d-fa38-4073-b40f-4af75a812473-StreamThread-1-consumer-5e768852-c577-45e5-bcdb-5ce91ead935c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:07:15,387] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 21 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:07:15,387] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 21 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:08:16,603] INFO [GroupCoordinator 1]: Member alltoolsStream-6080c05d-fa38-4073-b40f-4af75a812473-StreamThread-1-consumer-5e768852-c577-45e5-bcdb-5ce91ead935c in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:08:16,603] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 21 (__consumer_offsets-2) (reason: removing member alltoolsStream-6080c05d-fa38-4073-b40f-4af75a812473-StreamThread-1-consumer-5e768852-c577-45e5-bcdb-5ce91ead935c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:08:16,603] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 22 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:10:49,389] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:11:17,610] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:11:33,536] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:20:49,394] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:21:17,612] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:21:33,545] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:30:49,400] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:31:17,606] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:31:33,540] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:40:49,392] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:41:17,611] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:41:33,541] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:43:32,400] INFO [GroupCoordinator 2]: Preparing to rebalance group MEBKafkaStreamCluster in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member MEBKafkaStreamCluster-508769fd-7d2f-4aaa-ba56-39d1ccdffcc7-StreamThread-1-consumer-6daa0c58-feea-4f63-b870-4ad381cb2389) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:43:32,400] INFO [GroupCoordinator 2]: Stabilized group MEBKafkaStreamCluster generation 1 (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:43:32,416] INFO [GroupCoordinator 2]: Assignment received from leader for group MEBKafkaStreamCluster for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:43:32,921] WARN [LeaderEpochCache globalTableHoldON-1] New epoch entry EpochEntry(epoch=2, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 18:43:32,921] WARN [LeaderEpochCache aggregateddata-1] New epoch entry EpochEntry(epoch=2, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 18:44:03,480] INFO [GroupCoordinator 2]: Member MEBKafkaStreamCluster-508769fd-7d2f-4aaa-ba56-39d1ccdffcc7-StreamThread-1-consumer-6daa0c58-feea-4f63-b870-4ad381cb2389 in group MEBKafkaStreamCluster has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:44:03,480] INFO [GroupCoordinator 2]: Preparing to rebalance group MEBKafkaStreamCluster in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: removing member MEBKafkaStreamCluster-508769fd-7d2f-4aaa-ba56-39d1ccdffcc7-StreamThread-1-consumer-6daa0c58-feea-4f63-b870-4ad381cb2389 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:44:03,480] INFO [GroupCoordinator 2]: Group MEBKafkaStreamCluster with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 18:50:49,393] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:51:17,612] INFO [GroupMetadataManager brokerId=2] Group MEBKafkaStreamCluster transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:51:17,612] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 18:51:33,546] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 19:00:49,392] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 19:01:17,599] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 19:01:33,537] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 19:10:49,390] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-27 19:10:53,731] INFO [GroupCoordinator 1]: Member consumer-1-07772925-0f6e-4ae2-b473-c448b7ace67c in group console-consumer-67369 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:10:53,732] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-67369 in state PreparingRebalance with old generation 1 (__consumer_offsets-32) (reason: removing member consumer-1-07772925-0f6e-4ae2-b473-c448b7ace67c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:10:53,733] INFO [GroupCoordinator 1]: Group console-consumer-67369 with generation 2 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:10:59,587] INFO [GroupCoordinator 1]: Member consumer-1-5761de40-f6c0-46e2-b19b-55cfc97d4e06 in group connect-test-sink has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:10:59,588] INFO [GroupCoordinator 1]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 5 (__consumer_offsets-35) (reason: removing member consumer-1-5761de40-f6c0-46e2-b19b-55cfc97d4e06 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:10:59,589] INFO [GroupCoordinator 1]: Group connect-test-sink with generation 6 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:11:02,318] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=233031176, epoch=17415) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-27 19:11:02,321] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=233031176, epoch=17415)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-27 19:11:02,314] WARN Exception causing close of session 0x100018d4b890002: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 19:11:02,325] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1379925880, epoch=17373) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-27 19:11:02,332] INFO Closed socket connection for client /127.0.0.1:51492 which had sessionid 0x100018d4b890002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 19:11:02,328] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1379925880, epoch=17373)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-27 19:11:03,507] INFO [GroupCoordinator 1]: Member consumer-1-143a73a8-105e-4255-9c27-6b68dd1b8506 in group console-consumer-15107 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:11:03,508] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-15107 in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-143a73a8-105e-4255-9c27-6b68dd1b8506 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:11:03,510] INFO [GroupCoordinator 1]: Group console-consumer-15107 with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:11:05,345] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-27 19:11:05,347] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=233031176, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-27 19:11:05,350] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-27 19:11:05,351] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={aggregateddata3-2=(offset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), globalTableHoldON1-0=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), toolsEvents-2=(offset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), aggregateddata-1=(offset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), aggregateddata1-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), globalTableHoldON2-0=(offset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), globalTableHoldON3-0=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=233031176, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-27 19:11:05,351] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1379925880, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-27 19:11:05,361] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={toolsEvents1-1=(offset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), globalTableHoldON-1=(offset=11, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), toolsEvents3-1=(offset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), toolsEvents2-0=(offset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1379925880, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-27 19:11:06,607] INFO [GroupCoordinator 1]: Member consumer-1-9176ae72-f3fb-4700-bdb5-9b38d449b840 in group console-consumer-531 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:11:06,607] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-531 in state PreparingRebalance with old generation 1 (__consumer_offsets-20) (reason: removing member consumer-1-9176ae72-f3fb-4700-bdb5-9b38d449b840 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:11:06,608] INFO [GroupCoordinator 1]: Group console-consumer-531 with generation 2 is now empty (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-01-27 19:11:07,287] WARN Exception causing close of session 0x100018d4b890001: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 19:11:07,287] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51472 which had sessionid 0x100018d4b890001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 19:11:07,289] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1258228563, epoch=17383) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-27 19:11:07,290] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1258228563, epoch=17383)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-27 19:11:08,240] INFO Expiring session 0x100018d4b890002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 19:11:08,245] INFO Processed session termination for sessionid: 0x100018d4b890002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-27 19:11:08,352] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON2-0, aggregateddata1-0, aggregateddata3-2, toolsEvents-2, globalTableHoldON3-0, globalTableHoldON1-0, aggregateddata-1) (kafka.server.ReplicaFetcherManager)
[2019-01-27 19:11:08,352] INFO [Partition globalTableHoldON3-0 broker=1] globalTableHoldON3-0 starts at Leader Epoch 1 from offset 5. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,356] INFO [Partition aggregateddata-1 broker=1] aggregateddata-1 starts at Leader Epoch 3 from offset 6. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-27 19:11:08,361] INFO [Partition toolsEvents-2 broker=1] toolsEvents-2 starts at Leader Epoch 3 from offset 4. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-27 19:11:08,361] WARN [LeaderEpochCache toolsEvents-2] New epoch entry EpochEntry(epoch=3, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=4)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 19:11:08,365] INFO [Partition aggregateddata3-2 broker=1] aggregateddata3-2 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,369] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-27 19:11:08,369] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=233031176, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-27 19:11:08,370] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={aggregateddata3-2=(offset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), globalTableHoldON1-0=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), toolsEvents-2=(offset=4, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), aggregateddata-1=(offset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), aggregateddata1-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), globalTableHoldON2-0=(offset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), globalTableHoldON3-0=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=233031176, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-27 19:11:08,370] INFO [Partition globalTableHoldON2-0 broker=1] globalTableHoldON2-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,375] INFO [Partition aggregateddata1-0 broker=1] aggregateddata1-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,379] INFO [Partition globalTableHoldON1-0 broker=1] globalTableHoldON1-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,384] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-27 19:11:08,387] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-27 19:11:08,387] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-27 19:11:08,396] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents2-1, globalTableHoldON-2, toolsEvents1-2, toolsEvents3-2) (kafka.server.ReplicaFetcherManager)
[2019-01-27 19:11:08,396] INFO [Partition toolsEvents2-1 broker=1] toolsEvents2-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,401] INFO [Partition globalTableHoldON-2 broker=1] globalTableHoldON-2 starts at Leader Epoch 1 from offset 10. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,404] INFO [Partition toolsEvents1-2 broker=1] toolsEvents1-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,404] WARN [LeaderEpochCache toolsEvents1-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 19:11:08,407] INFO [Partition toolsEvents3-2 broker=1] toolsEvents3-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-27 19:11:08,408] WARN [LeaderEpochCache toolsEvents3-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-27 19:11:09,347] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-27 19:11:10,306] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-27 19:11:10,307] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1258228563, epoch=INITIAL) to node 2: java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-27 19:11:10,312] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={toolsEvents2-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), toolsEvents3-0=(offset=14, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), toolsEvents1-0=(offset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1258228563, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-27 19:11:10,451] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-27 19:11:11,121] WARN Exception causing close of session 0x100018d4b890000: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 19:11:11,121] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51455 which had sessionid 0x100018d4b890000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-27 19:11:14,241] INFO Expiring session 0x100018d4b890001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-27 19:11:14,241] INFO Processed session termination for sessionid: 0x100018d4b890001 (org.apache.zookeeper.server.PrepRequestProcessor)
